{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Задача поиска схожих по смыслу предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача ранжирования(Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $X$ - множество объектов\n",
    "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
    "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
    "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
    "### Задача:\n",
    "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
    "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
    "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin\", binary=True)\n",
    "# wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin?download=1\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как пользоваться этими векторами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примере одного слова, что из себя представляет embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71915245 -1.542663   -0.69895816  0.1544462  -1.2378534   0.265825\n",
      "  0.65233576 -2.1376913   1.5001364  -0.16768844 -0.71720433  1.6013266\n",
      " -3.577465   -2.1195807   1.0495411   1.7895333  -1.0391432  -0.3420887\n",
      "  0.31547526  1.1174009   1.2566462  -2.4243934  -0.8998013   0.10239235\n",
      "  0.3956912  -0.39445704 -0.30281302 -1.8980318  -0.898579   -0.9394918\n",
      "  0.15756415  1.1858691  -0.40680015 -2.57257     0.6659513  -1.3002656\n",
      "  0.7096     -0.0382328  -0.95050263  1.2861551   0.33719563 -1.7006972\n",
      " -1.3042057  -0.02094089 -1.160755   -0.905893   -0.39668226  0.8157642\n",
      " -0.2383732   0.4569941   0.996064    0.5717084  -2.1317208  -0.10221571\n",
      " -1.4585396   0.54236513  0.8941682  -0.9808877   0.9992245   1.1498358\n",
      "  0.34307456 -0.97934765 -1.0703176   0.13549381  1.6083974  -1.650749\n",
      " -0.9470516  -0.7484174   0.783067   -1.0349045  -1.5558331  -1.9985139\n",
      " -1.5584247  -1.9947437   1.677691    0.80027777 -0.11727657  1.0046765\n",
      " -1.5823939  -0.17658693 -0.74325824 -0.59861195  1.2277637   0.9314538\n",
      "  1.7851094  -0.6622601   1.2059362   1.6233172  -2.0946274  -0.65378034\n",
      " -1.0348548  -2.9950035   0.6232046  -0.7803712  -0.02439314  0.24627402\n",
      " -0.6572641   1.6109873   1.0002007  -0.45712122 -0.9289038  -0.7851508\n",
      " -1.2042036   1.6417075  -2.062653    1.1239882   0.5475801   0.07329568\n",
      " -1.128264   -1.7790279  -0.00789989 -1.4941639   0.8983379  -1.6846293\n",
      "  0.2614029  -0.0750076  -1.7032906   0.38658255  2.5906367  -0.8526129\n",
      "  0.7255648  -0.5983927  -0.14658462  2.0336826   0.92287123 -1.9994345\n",
      " -1.3363256   0.79072106 -1.8597356  -0.7381024  -0.84648645 -0.9843619\n",
      "  0.47617173 -1.3043061  -0.17835413 -2.854961    0.94607943 -1.231004\n",
      "  1.8338903   1.3013896  -0.35322648  0.8962776   0.97410715  0.11386268\n",
      "  1.1253104   0.41263318  2.7715003  -1.346934    1.204982   -0.01670979\n",
      " -0.8669396  -1.0308735  -0.5844789   0.57534117 -0.41338485 -0.3636708\n",
      " -1.7987003  -1.0684701  -1.7527993  -0.23222889  0.38671398 -0.7563939\n",
      " -2.6288023   0.31214795 -1.0111287  -0.82584405  0.6313762  -0.06947021\n",
      "  0.33279362 -1.014108    0.4834512  -0.8353998  -3.05015     0.18083014\n",
      "  0.9232949  -0.5345982  -1.7460634  -0.60928285  1.3242307  -0.40261996\n",
      "  0.08907793 -1.6861676   1.0402287  -0.6403309   0.01863923 -0.02392901\n",
      " -0.6080688  -1.5451736  -0.75956327 -3.8619454  -0.78160954  0.17197208\n",
      " -0.0061596  -1.2189773   0.9384584  -2.4180996  -0.7229557   0.34693366\n",
      "  2.0731425  -3.0019922 ]\n",
      "float32 (200,)\n"
     ]
    }
   ],
   "source": [
    "word = 'dogs'\n",
    "if word in wv_embeddings:\n",
    "    print(wv_embeddings[word])\n",
    "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of words: 1787145\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Num of words: {len(wv_embeddings.index2word)}\")\n",
    "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use', 'code', 'using', 'like', 'will', 'want', 'need', 'get', 'file', 'one']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_embeddings.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем наиболее близкие слова к слову `dog`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animal', 0.8564180135726929),\n",
       " ('dogs', 0.7880866527557373),\n",
       " ('mammal', 0.7623804211616516),\n",
       " ('cats', 0.7621253728866577),\n",
       " ('animals', 0.760793924331665)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_embeddings.most_similar(\"dog\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 1:\n",
    "* Входит ли слов `cat` топ-5 близких слов к слову `dog`? Какое место?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ\n",
    "* Входит слово \"cats\" и стоит на 4м месте, а единственное число \"cat\" - не входит в топ 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "# from nltk.tokenize import WordPunctTokenizer\n",
    "# you can use your tokenizer\n",
    "# for example, from nltk.tokenize import WordPunctTokenizer\n",
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        return re.findall('\\w+', text)\n",
    "tokenizer = MyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([5,10,-3])\n",
    "a, b\n",
    "c = a+b\n",
    "c, c/2\n",
    "np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        embeddings: наше векторное представление\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "\n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\"\n",
    "    word_tokens = tokenizer.tokenize(question)\n",
    "    count_word = 0\n",
    "    question_embedding = np.zeros(200)\n",
    "    for word in word_tokens:\n",
    "        if word in embeddings:\n",
    "            question_embedding += embeddings[word]\n",
    "            count_word += 1\n",
    "    if count_word != 0:\n",
    "        question_embedding = question_embedding/count_word\n",
    "    return question_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 2:\n",
    "* Какая третья(с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = question_to_vec(\"I love neural networks\", wv_embeddings, tokenizer, dim=200)\n",
    "round(question_embedding[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями.\n",
    "\n",
    "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
    "* $\\begin{equation*}\n",
    "[x < 0 ] \\equiv\n",
    " \\begin{cases}\n",
    "   1, &x < 0\\\\\n",
    "   0, &x \\geq 0\n",
    " \\end{cases}\n",
    "\\end{equation*}$ - индикаторная функция\n",
    "* $q_i$ - $i$-ый вопрос\n",
    "* $q_i^{'}$ - его дубликат\n",
    "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
    "С такой метрикой модель штрафуется за большой ранк корректного ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 3:\n",
    "* Максимум `Hits@47 - DCG@1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера.\n",
    "Пусть\n",
    "* $N = 1$, $R = 3$\n",
    "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
    "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
    "\n",
    "Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. \"Как изучить с++?\"\n",
    "2. <font color='red'>\"Что такое язык python?\"</font>\n",
    "3. \"Хочу учить Java\"\n",
    "4. \"Не понимаю Tensorflow\"\n",
    "\n",
    "$\\Rightarrow rank\\_q_i^{'} = 2$\n",
    "\n",
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1)] = 0$\n",
    "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
    "\n",
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 4:\n",
    "* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ:\n",
    "- [K = 10] $\\text{DCG@10} = \\frac{1}{\\log_2(1+9)}\\cdot[9 \\le 10] = \\frac{1}{\\log_2{10}}$ = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "dcg10 = 1/math.log2(10)\n",
    "print(round(dcg10,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HITS\\_COUNT и DCG\\_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$. $dup\\_ranks$ является списком, который содержит рейтинги дубликатов(их позиции в ранжированном списке). Например, $dup\\_ranks = [2]$ для примера, описанного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть  Hits@k\n",
    "    \"\"\"\n",
    "    hits_value = 0\n",
    "    for rank in dup_ranks:\n",
    "        hits_value += 1 if rank <= k else 0\n",
    "    hits_value = hits_value/len(dup_ranks)\n",
    "    return hits_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть DCG@k\n",
    "    \"\"\"\n",
    "    dcg_value = 0\n",
    "    for rank in dup_ranks:\n",
    "        dcg_value += 1/math.log2(1 + rank) if rank <= k else 0\n",
    "    dcg_value = dcg_value/len(dup_ranks)\n",
    "    return dcg_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
      "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
     ]
    }
   ],
   "source": [
    "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
    "\n",
    "# наги кандидаты\n",
    "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                       \"NSLog array description not memory address\",\n",
    "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
    "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
    "dup_ranks = [2]\n",
    "\n",
    "# вычисляем метрику для разных k\n",
    "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
    "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HITS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2        3        4\n",
       "HITS  0  1.00000  1.00000  1.00000\n",
       "DCG   0  0.63093  0.63093  0.63093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct_answers - метрика для разных k\n",
    "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
    "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
    "\n",
    "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
    "\n",
    "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip stackoverflow_similar_questions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.split(\"\\t\"))\n",
    "    return data\n",
    "validation_data = read_corpus('./stackoverflow_similar_questions/data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам понадобиться только файл validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validation_data = read_corpus('./stackoverflow_similar_questions/data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер нескольких первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "2 1001\n",
      "3 1001\n",
      "4 1001\n",
      "5 1001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i + 1, len(validation_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранжирование без обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        candidates: массив строк(кандидатов) [a, b, c]\n",
    "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
    "    \"\"\"\n",
    "    quest_vec = question_to_vec(question, embeddings, tokenizer)\n",
    "    ranks = []\n",
    "    for i, candidate in enumerate(candidates):\n",
    "        cand_vec = question_to_vec(candidate, embeddings, tokenizer)\n",
    "        cos_sim = cosine_similarity([quest_vec], [cand_vec])[0][0]\n",
    "        ranks.append((cos_sim, (i, candidate)))\n",
    "    ranks = sorted(ranks,reverse=True)\n",
    "    ranks = [r[1] for r in ranks]\n",
    "    return ranks\n",
    "\n",
    "# rank_candidates(questions[0], candidates[0], wv_embeddings, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "questions = ['converting string to list', 'Sending array via Ajax fails']\n",
    "\n",
    "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
    "               'C# create cookie from string and send it',\n",
    "               'How to use jQuery AJAX for an outside domain?'],\n",
    "\n",
    "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
    "               'WPF- How to update the changes in list item of a list',\n",
    "               'select2 not displaying search results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'C# create cookie from string and send it'), (0, 'Convert Google results object (pure js) to Python object'), (2, 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "[(1, 'WPF- How to update the changes in list item of a list'), (0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, q_candidates in zip(questions, candidates):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
    "        print(ranks)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# должно вывести\n",
    "results = [[(1, 'C# create cookie from string and send it'),\n",
    "            (0, 'Convert Google results object (pure js) to Python object'),\n",
    "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "           [\n",
    "            (1, 'WPF- How to update the changes in list item of a list'),\n",
    "            (0, 'Getting all list items of an unordered list in PHP'), #скрыт\n",
    "            (2, 'select2 not displaying search results'), #скрыт\n",
    "            ]\n",
    "          ] #скрыт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 5:\n",
    "* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "102\n",
    "\n",
    "[(1, 'WPF- How to update the changes in list item of a list'), (0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f79898111f94e33ae5b5c5e049b2149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810436f049524b31b0f9f8a7327fd360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.223 | Hits@   1: 0.223\n",
      "DCG@   5: 0.282 | Hits@   5: 0.335\n",
      "DCG@  10: 0.301 | Hits@  10: 0.392\n",
      "DCG@ 100: 0.347 | Hits@ 100: 0.622\n",
      "DCG@ 500: 0.372 | Hits@ 500: 0.821\n",
      "DCG@1000: 0.391 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги, обученные на корпусе похожих вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = read_corpus('./stackoverflow_similar_questions/data/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "среднее кол-во слов в вопросе: 19.699199\n"
     ]
    }
   ],
   "source": [
    "# train_words = [tokenizer.tokenize(\" \".join(w)) for w in train_data[:1000]]\n",
    "train_words = [tokenizer.tokenize(\" \".join(w)) for w in train_data]\n",
    "# train_data[0], train_words\n",
    "# len(train_words)\n",
    "\n",
    "# определеям среднее кол-во слов в вопросе\n",
    "print(f\"среднее кол-во слов в вопросе: {np.array(list(map(len, train_words))).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# min_count = int — игнорирует все слова у которых частота ниже заданной (2, 100)\n",
    "# window = int - размер контекстного окна -  максимальное расстояние между текущим и прогнозируемым словом в предложении.\n",
    "# параметр «window» должен быть достаточно большим, чтобы фиксировать синтаксические/семантические отношения. Как правило для англиского языка принято значение по умолчанию равное 5. Зависит от исследуемого текста.\n",
    "\n",
    "# size — размер векторного представления слова (word embedding).\n",
    "# negative — сколько неконтекстных слов учитывать в обучении, используя negative sampling.\n",
    "# alpha — начальный learning_rate, используемый в алгоритме обратного распространения ошибки (Backpropogation).\n",
    "# min_alpha — минимальное значение learning_rate, на которое может опуститься в процессе обучения.\n",
    "# sg — если 1, то используется реализация Skip-gram; если 0, то CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=5).wv\n",
    "# Параметр «window»:\n",
    "# - определяет размер контекстного окна -  максимальное расстояние между текущим и прогнозируемым словом в предложении.\n",
    "# - должен быть достаточно большим, чтобы фиксировать синтаксические/семантические отношения. Как правило для англиского языка принято значение по умолчанию равное 5 (Значение по умолчанию https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "# - зависит от исходных данных, после склейки вопросов средняя длина предложений составила 20 слов (19.699).Так как склеивались 2 вопроса, то под средней длиной вопроса можно взять 10 слов. Тогда окно должно быть равным 5\n",
    "# Таким образом параметр «window» окно стоит рассматривать равным 5\n",
    "# Однако, из-за особенностей данных (технические вопросы), есть смысл произвести дополнительную проверку на окне меньшем и большем размерах окон\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1292dd9fe98c49239dbc0713497046a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c6b7abab64dce83ea1c586bc79b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.258 | Hits@   1: 0.258\n",
      "DCG@   5: 0.326 | Hits@   5: 0.388\n",
      "DCG@  10: 0.352 | Hits@  10: 0.468\n",
      "DCG@ 100: 0.404 | Hits@ 100: 0.724\n",
      "DCG@ 500: 0.430 | Hits@ 500: 0.926\n",
      "DCG@1000: 0.438 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Правим токенизацию так чтобы числа убрать, были только слова или слова с цифрами ( можно через метод isalpha)\n",
    "class MyTokenizer2:\n",
    "    def __init__(self):\n",
    "        # Stemmer (Стеминг)\n",
    "        self.stemmer = SnowballStemmer(language=\"english\")\n",
    "        # Stop words\n",
    "        self.eng_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # переводим в нижний регистр\n",
    "        text = text.lower()\n",
    "        find_words = re.findall('\\w+', text)\n",
    "        # Производим Стеминг (Stemmer)\n",
    "        find_words = [self.stemmer.stem(w) for w in find_words if w.isalpha()]\n",
    "        # убираем стоп-слова\n",
    "        find_words = [w for w in find_words if w not in self.eng_stopwords]\n",
    "        return find_words\n",
    "\n",
    "\n",
    "tokenizer2 = MyTokenizer2()\n",
    "# tokenizer2.tokenize(train_data[1][0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_words = [tokenizer2.tokenize(\" \".join(w)) for w in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель с параметром \"window=5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer2)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.405 | Hits@   1: 0.405\n",
      "DCG@   5: 0.505 | Hits@   5: 0.592\n",
      "DCG@  10: 0.529 | Hits@  10: 0.667\n",
      "DCG@ 100: 0.576 | Hits@ 100: 0.892\n",
      "DCG@ 500: 0.588 | Hits@ 500: 0.977\n",
      "DCG@1000: 0.590 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель с параметром \"window=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=5).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=10).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce468ba82af04620a22a53bdb500a841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer2)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77cfbca369425d9080d1f81bad44b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.412 | Hits@   1: 0.412\n",
      "DCG@   5: 0.515 | Hits@   5: 0.601\n",
      "DCG@  10: 0.540 | Hits@  10: 0.680\n",
      "DCG@ 100: 0.586 | Hits@ 100: 0.900\n",
      "DCG@ 500: 0.596 | Hits@ 500: 0.978\n",
      "DCG@1000: 0.599 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# window 10\n",
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings_trained.most_similar(['machine', 'learning'])\n",
    "# embeddings_trained.most_similar(['machin', 'learn'])\n",
    "# stemmer = SnowballStemmer(language=\"english\")\n",
    "# stemmer.stem(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Правим токенизацию так чтобы числа убрать, были только слова или слова с цифрами ( можно через метод isalpha)\n",
    "class MyTokenizer3:\n",
    "    def __init__(self):\n",
    "        # Лемматизация\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        # Stop words\n",
    "        self.eng_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # переводим в нижний регистр\n",
    "        doc = self.nlp(text.lower(), disable=[\"tok2vec\", \"parser\", \"ner\" ,\"textcat\", \"custom\"])\n",
    "        find_words = [w.lemma_ for w in doc]\n",
    "        # убираем стоп-слова\n",
    "        find_words = [w for w in find_words if w.isalpha() and w not in self.eng_stopwords]\n",
    "\n",
    "\n",
    "\n",
    "        return find_words\n",
    "\n",
    "\n",
    "tokenizer3 = MyTokenizer3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_words = [tokenizer3.tokenize(\" \".join(w)) for w in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=10, sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6139d615e2b04b299bb4a562af2e9b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer3)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a504203970f54c0d86179780f6c33141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.398 | Hits@   1: 0.398\n",
      "DCG@   5: 0.494 | Hits@   5: 0.574\n",
      "DCG@  10: 0.520 | Hits@  10: 0.654\n",
      "DCG@ 100: 0.567 | Hits@ 100: 0.880\n",
      "DCG@ 500: 0.579 | Hits@ 500: 0.969\n",
      "DCG@1000: 0.582 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# window 10\n",
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=10, sg=1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41916d4f91b344cfa09e047add92d530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer3)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d9a36edf0d4d55807ba5d74d68b2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.491 | Hits@   1: 0.491\n",
      "DCG@   5: 0.585 | Hits@   5: 0.663\n",
      "DCG@  10: 0.603 | Hits@  10: 0.719\n",
      "DCG@ 100: 0.639 | Hits@ 100: 0.890\n",
      "DCG@ 500: 0.650 | Hits@ 500: 0.971\n",
      "DCG@1000: 0.653 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# window 10\n",
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предварительный результат:\n",
    "Выбор параметр размер контекстного окна («window»):\n",
    "- Определяет размер контекстного окна -  максимальное расстояние между текущим и прогнозируемым словом в предложении.\n",
    "- Должен быть достаточно большим, чтобы фиксировать синтаксические/семантические отношения. Как правило для англиского языка принято значение по умолчанию равное 5 (Значение по умолчанию https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "- Также выбор размера окна зависит от исходных данных, например, после склейки вопросов средняя длина предложений составила 20 слов (19.994), однако также надо учитывать исключение стоп-слов. Так как склеивались 2 вопроса, то под средней длиной вопроса можно взять 10 слов. Тогда окно должно быть равным 5\n",
    "- Общий подход при выборе размера окна: окно большего размера, как правило, содержат больше информации о тематике/области, т.е. сильно важна контекстная связь с соседними словами. Окна меньшего размера, как правило, больше отражают особенности самого слова (напрмер фразы или синонимы).\n",
    "- Необходимо учитывать специфику текста ,в нашем случае это вопросы, как правило вопросы задаются в минималистическом стиле, т.е. таким образом, что все слова в вопросе играют роль. В таком случае имеет смысл рассматривать увеличенный размер окна.\n",
    "- Таким образом размер окна (параметр «window») стоит рассматривать не менее чем 5 и не более чем 10.\n",
    "\n",
    "\n",
    "\n",
    "Использование предрасчитанной модели показало гораздно лучшие результаты чем самостоятельное обучение без использования дополнительной предобработки текстов:\n",
    "\n",
    "Использование предобученной модели:\n",
    "\n",
    "DCG@   1: 0.223 | Hits@   1: 0.223  \n",
    "DCG@   5: 0.282 | Hits@   5: 0.335  \n",
    "DCG@  10: 0.301 | Hits@  10: 0.392  \n",
    "DCG@ 100: 0.347 | Hits@ 100: 0.622  \n",
    "DCG@ 500: 0.372 | Hits@ 500: 0.821  \n",
    "DCG@1000: 0.391 | Hits@1000: 1.000  \n",
    "\n",
    "\n",
    "Использование собственно обученной модели на всех примерах примерах (размер окна=5):  \n",
    "  \n",
    "DCG@   1: 0.258 | Hits@   1: 0.258  \n",
    "DCG@   5: 0.326 | Hits@   5: 0.388  \n",
    "DCG@  10: 0.352 | Hits@  10: 0.468  \n",
    "DCG@ 100: 0.404 | Hits@ 100: 0.724  \n",
    "DCG@ 500: 0.430 | Hits@ 500: 0.926  \n",
    "DCG@1000: 0.438 | Hits@1000: 1.000  \n",
    "\n",
    "Использование собственно обученной модели на всех примерах (размер окна=5) и проведена предобработка текста (стоп-слова стемминг и пр.):  \n",
    "  \n",
    "DCG@   1: 0.405 | Hits@   1: 0.405  \n",
    "DCG@   5: 0.505 | Hits@   5: 0.592  \n",
    "DCG@  10: 0.529 | Hits@  10: 0.667  \n",
    "DCG@ 100: 0.576 | Hits@ 100: 0.892  \n",
    "DCG@ 500: 0.588 | Hits@ 500: 0.977  \n",
    "DCG@1000: 0.590 | Hits@1000: 1.000  \n",
    "\n",
    "Проверка на других размерах параметра контекстного окна:\n",
    "Размер окна=10  \n",
    "DCG@   1: 0.412 | Hits@   1: 0.412  \n",
    "DCG@   5: 0.515 | Hits@   5: 0.601  \n",
    "DCG@  10: 0.540 | Hits@  10: 0.680  \n",
    "DCG@ 100: 0.586 | Hits@ 100: 0.900  \n",
    "DCG@ 500: 0.596 | Hits@ 500: 0.978  \n",
    "DCG@1000: 0.599 | Hits@1000: 1.000  \n",
    "  \n",
    "Использование лемматизация (маленький словарь: \"en_core_web_sm\") вместо стемминга. Размер окна=10  \n",
    "  \n",
    "DCG@   1: 0.398 | Hits@   1: 0.398  \n",
    "DCG@   5: 0.494 | Hits@   5: 0.574  \n",
    "DCG@  10: 0.520 | Hits@  10: 0.654  \n",
    "DCG@ 100: 0.567 | Hits@ 100: 0.880  \n",
    "DCG@ 500: 0.579 | Hits@ 500: 0.969  \n",
    "DCG@1000: 0.582 | Hits@1000: 1.000  \n",
    "\n",
    "\n",
    "Использование лемматизация (маленький словарь: \"en_core_web_sm\") вместо стемминга. Размер окна=10  + добавлен параметр skip-gram (https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)  \n",
    "  \n",
    "DCG@   1: 0.491 | Hits@   1: 0.491  \n",
    "DCG@   5: 0.585 | Hits@   5: 0.663  \n",
    "DCG@  10: 0.603 | Hits@  10: 0.719  \n",
    "DCG@ 100: 0.639 | Hits@ 100: 0.890  \n",
    "DCG@ 500: 0.650 | Hits@ 500: 0.971  \n",
    "DCG@1000: 0.653 | Hits@1000: 1.000  \n",
    "  \n",
    "Использование собственно обученной модели с использованием предобработки текстов показало лучше результаты чем использование предрасчитанной модели. Предобработка текста сильно улучшила показатели.\n",
    "Использовалась следующая предобработка: исключение стоп-слова, лемматизацию/стемминг, исключение пунктуации и только чисел.\n",
    "Также значимо повлиял выбор гиперпараметров, в том числе размер окна.\n",
    "\n",
    "Лемматизация довольно затратный по ресурсам процесс, поэтому эксперимент проводился только с использованием маленького словаря: \"en_core_web_sm\". Примечательно, что Стемминг показал результат лучше чем Лемматизация с маленьким словарем.\n",
    "\n",
    "Алгоритм Skip-gram довольно хорошо показал себя в качестве улучшения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замечание:\n",
    "Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите свой вывод о полученных результатах.\n",
    "* Какой принцип токенизации даёт качество лучше и почему?\n",
    "* Помогает ли нормализация слов?\n",
    "* Какие эмбеддинги лучше справляются с задачей и почему?\n",
    "* Почему получилось плохое качество решения задачи?\n",
    "* Предложите свой подход к решению задачи.\n",
    "\n",
    "## Вывод:\n",
    "По итогам проведенных тестов выявлены следующие моменты:\n",
    "\n",
    "1. При построении языковой модели необходимо учитывать природу и особеннности входных данных. Так например особенностью вопросов на stackoverflow является высокий уровень технических терминов и узкая тематика, а также стиль написания заголовков вопросов - в боьлшинстве случаев кратко по существу. Поэтому предобученная языковая модель на вопросах stackoverflow работала хуже чем обученная с нуля но на обучающей выборки данных именно stackoverflow.\n",
    "2. При выборе приниципа токенизации необходимо учитывать проводимую предобработку данных. Одни методы предобработки имеет смысл производить до токенизации (например приведение слов текста в нижний регистр), а другие после токенизации (например, отбрасывание стоп-слов). \n",
    "3. Нормализация слов является одним из основных методов предобработки текста. Если сравнивать Стемминг и Лемматизацию, то  Лемматизация довольно затратный по ресурсам процесс, поэтому необходимо обосновано выбирать метод, в зависимости от доступных ресурсов и требуемой точности. При этом Лемматизация на маленьком словаре может проигрывать Стеммингу. Для текущей задачи Стемминг показал хорошие результаты. Дополнительно Стемминг применялся к словарю стоп-слов, чтобы обеспечить исключение слов после Стемминга. \n",
    "П.С. При нормализации текста (слов) важно помнить, что нормализовывать надо не только обучающую выборку, но и тестовые/валидационные данные с которыми будет работать обученная модель.\n",
    "4. Использование эмбеддингов, построенных через Word2Vec библиотеки Gensim, показали гораздо лучшие результаты чем использование предобученных эмбендингов, вероятно это связано со специфичностью вопросов stackoverflow. Т.е. не всегда использование больших обученных моделей может показать хорошие результаты, иногда и небольшие модели но обученные на похожих данных показывают результаты гораздо лучше. \n",
    "5. Алгоритм Skip-gram довольно хорошо показал себя в качестве улучшения модели.\n",
    "6. Тексты вопросов содержит много технических терминов и сокращений, что необходмио учитывать.\n",
    "7. В качестве развития можно подумать о следующих направлениях:  \n",
    "- использовании словаря технических синонимов, например JS = JavaScript и т.д.  \n",
    "- применить алгоритм CBOW (Continuous Bag of Words)\n",
    "- использовать grid search для поиска гиперпараметров и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
