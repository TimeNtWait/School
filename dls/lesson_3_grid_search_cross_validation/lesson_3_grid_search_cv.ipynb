{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,),\n",
       " (10,),\n",
       " (10,),\n",
       " (10,),\n",
       " array([ 7.89473684, -5.78947368,  3.68421053]),\n",
       " array([ 15.99734504, -10.25800181,  12.10041242]))"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_POINTS = 20\n",
    "x = np.linspace(-10, 10, CNT_POINTS)\n",
    "y = x * 2 + 3 + (np.random.rand(CNT_POINTS)-0.5) * 6\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.5)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape, x_train[:3], y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(x_train, y_train, label=\"Train\")\n",
    "plt.scatter(x_test, y_test, label=\"Test\")\n",
    "plt.plot(x,x*2+3, color=\"red\", lw=4, alpha=0.2)\n",
    "# legend_box = plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: RankWarning: Polyfit may be poorly conditioned\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: RankWarning: Polyfit may be poorly conditioned\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: RankWarning: Polyfit may be poorly conditioned\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Figure.show of <Figure size 2000x2000 with 6 Axes>>"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x2000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = np.linspace(-12,12,300)\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(20,20))\n",
    "ax = ax.ravel()\n",
    "for i, deg in enumerate([1,3,7,10,20,40]):\n",
    "    poly = np.polyfit(x_train,y_train,deg)\n",
    "    ax[i].set_title(f\"Polyname fit, dig = {deg}\")\n",
    "    ax[i].scatter(x_train,y_train,label=f\"train mse:{round(mean_squared_error(y_train, np.polyval(poly, x_train)),5)}\")\n",
    "    ax[i].scatter(x_test,y_test,label=f\"test mse:{round(mean_squared_error(y_test, np.polyval(poly, x_test)),5)}\")\n",
    "    ax[i].set_ylim(-40, 40)\n",
    "    ax[i].plot(grid, np.polyval(poly, grid))\n",
    "    ax[i].plot(x, x*2+3, color=\"red\", lw=1, alpha=0.2)\n",
    "fig.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educ-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  educ-num      marital-status  \\\n",
       "0   39         State-gov   77516  Bachelors        13       Never-married   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors        13  Married-civ-spouse   \n",
       "2   38           Private  215646    HS-grad         9            Divorced   \n",
       "\n",
       "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male          2174             0   \n",
       "1    Exec-managerial        Husband  White  Male             0             0   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  salary  \n",
       "0              40  United-States       0  \n",
       "1              13  United-States       0  \n",
       "2              40  United-States       0  "
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adult.data\", sep=\",\", names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \n",
    "                                               \"educ-num\", \"marital-status\", \"occupation\",\n",
    "                                               \"relationship\", \"race\", \"sex\", \"capital-gain\",\n",
    "                                               \"capital-loss\", \"hours-per-week\", \"native-country\",\n",
    "                                               \"salary\",\n",
    "                                              ])\n",
    "num_cols = [\"age\", \"fnlwgt\", \"hours-per-week\", \"educ-num\", \"capital-gain\", \"capital-loss\"]\n",
    "cat_cols = [\"workclass\", \"education\", \"marital-status\", \"occupation\",\n",
    "            \"relationship\", \"race\", \"native-country\",\"sex\"]\n",
    "# bin_cols = [\"sex\"]\n",
    "target_colname = \"salary\"\n",
    "\n",
    "#        \n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.str.strip())\n",
    "df[bin_cols] = df[bin_cols].apply(lambda x: x.str.strip())\n",
    "df[[target_colname]] = df[[target_colname]].apply(lambda x: x.str.strip())\n",
    "\n",
    "# Change binary columns from text to 0/1\n",
    "df[target_colname] = np.where(df[target_colname] == \">50K\", 1, 0)\n",
    "# df[[\"sex\"]] = np.where(df[[\"sex\"]] == \"Male\", 1, 0)\n",
    "y_data = df[target_colname]\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "educ-num          0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "salary            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change nan/\"?\" \"workclass\" on populat categorical: \"Private\"\n",
    "# df.groupby(\"workclass\")[\"age\"].count()\n",
    "# df[df[\"workclass\"]==\"?\"] = \"Private\"\n",
    "df[\"workclass\"] = np.where(df[\"workclass\"]==\"?\", \"Private\", df[\"workclass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change nan/\"?\" \"native-country\" on unknow categorical: \"Private\"\n",
    "# df.groupby(\"native-country\")[\"age\"].count()\n",
    "df[\"native-country\"] = np.where(df[\"native-country\"]==\"?\", \"Private\", df[\"native-country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change nan/\"?\" \"native-country\" on unknow categorical: \"Private\"\n",
    "df.groupby(\"occupation\")[\"age\"].count()\n",
    "df[\"occupation\"] = np.where(df[\"occupation\"]==\"?\", \"Private\", df[\"occupation\"])\n",
    "# df[df[\"occupation\"]==\"?\"] = \"Private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to one-hot encoding\n",
    "# Pandas \"get_dummies\"\n",
    "# df_cat_ohe = pd.get_dummies(df[cat_cols])\n",
    "# x_data = pd.concat([df, df_cat_ohe],axis=1)\n",
    "# x_data = x_data.drop(columns=cat_cols)\n",
    "\n",
    "# sklearn \"OneHotEncoder\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "sk_ohe = OneHotEncoder( handle_unknown=\"ignore\", drop=\"first\", sparse=False, dtype=int)\n",
    "sk_ohe = sk_ohe.fit(df[cat_cols])\n",
    "df_cat_ohe_sklearn = pd.DataFrame(sk_ohe.transform(df[cat_cols]), columns=sk_ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 99), (32561,))"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = pd.concat([df, df_cat_ohe_sklearn],axis=1)\n",
    "x_data = x_data.drop(columns=(cat_cols+[target_colname]))\n",
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 99), (32561,), (26048, 99), (6513, 99), (26048,), (6513,))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, shuffle=True, random_state=53)\n",
    "x_data.shape, y_data.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#    train!!\n",
    "scaler.fit(x_train[num_cols])\n",
    "x_train[num_cols] = scaler.transform(x_train[num_cols])\n",
    "x_test[num_cols] = scaler.transform(x_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 14), (32561,), (26048, 14), (6513, 14), (26048,), (6513,))"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    Catboost.         OHE\n",
    "#  x_data_cb  target\n",
    "x_data_cb = df.drop(columns=([target_colname]))\n",
    "\n",
    "#   train/test\n",
    "x_train_cb, x_test_cb = train_test_split(x_data_cb, test_size=0.2, shuffle=True, random_state=53)\n",
    "\n",
    "#   \n",
    "x_train_cb[num_cols] = scaler.transform(x_train_cb[num_cols])\n",
    "x_test_cb[num_cols] = scaler.transform(x_test_cb[num_cols])\n",
    "\n",
    "x_data_cb.shape, y_data.shape, x_train_cb.shape, x_test_cb.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "# params_models\n",
    "\n",
    "params_models = [\n",
    "    {\"name\": \"KNeighborsClassifier\",\n",
    "    \"model\": KNeighborsClassifier(),\n",
    "    \"param\": {\n",
    "        \"n_neighbors\": np.array(np.linspace(4, 10, 8), dtype=int),\n",
    "#         \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    },\n",
    "    },\n",
    "    {\"name\": \"DecisionTreeClassifier\",\n",
    "    \"model\": DecisionTreeClassifier(),\n",
    "    \"param\": {\"max_depth\": np.array(np.linspace(1, 30, 2), dtype=int),},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'KNeighborsClassifier', 'model': KNeighborsClassifier(), 'param': {'n_neighbors': array([ 4,  4,  5,  6,  7,  8,  9, 10])}}\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .....................n_neighbors=4;, score=0.591 total time=   2.0s\n",
      "[CV 2/5] END .....................n_neighbors=4;, score=0.575 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=4;, score=0.573 total time=   2.2s\n",
      "[CV 4/5] END .....................n_neighbors=4;, score=0.607 total time=   2.8s\n",
      "[CV 5/5] END .....................n_neighbors=4;, score=0.586 total time=   2.9s\n",
      "[CV 1/5] END .....................n_neighbors=4;, score=0.591 total time=   2.0s\n",
      "[CV 2/5] END .....................n_neighbors=4;, score=0.575 total time=   2.0s\n",
      "[CV 3/5] END .....................n_neighbors=4;, score=0.573 total time=   2.1s\n",
      "[CV 4/5] END .....................n_neighbors=4;, score=0.607 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=4;, score=0.586 total time=   2.1s\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.633 total time=   3.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.631 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.644 total time=   2.3s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.647 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.628 total time=   2.1s\n",
      "[CV 1/5] END .....................n_neighbors=6;, score=0.601 total time=   2.0s\n",
      "[CV 2/5] END .....................n_neighbors=6;, score=0.601 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=6;, score=0.610 total time=   2.2s\n",
      "[CV 4/5] END .....................n_neighbors=6;, score=0.614 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=6;, score=0.600 total time=   2.1s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.638 total time=   2.0s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.638 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.645 total time=   2.2s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=0.649 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.638 total time=   2.1s\n",
      "[CV 1/5] END .....................n_neighbors=8;, score=0.617 total time=   2.2s\n",
      "[CV 2/5] END .....................n_neighbors=8;, score=0.624 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=8;, score=0.614 total time=   2.2s\n",
      "[CV 4/5] END .....................n_neighbors=8;, score=0.632 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=8;, score=0.616 total time=   2.1s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.642 total time=   2.0s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=0.639 total time=   2.1s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.647 total time=   2.2s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=0.656 total time=   2.2s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.645 total time=   2.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.619 total time=   2.1s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.624 total time=   3.4s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.626 total time=   3.7s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.637 total time=   3.0s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.625 total time=   2.2s\n",
      "mean_score: [0.5863712  0.5863712  0.63647391 0.60543616 0.64149654 0.62065382\n",
      " 0.64568387 0.62587285]\n",
      "std_test_score: [0.01241167 0.01241167 0.00753851 0.0057911  0.00483302 0.00674807\n",
      " 0.00579077 0.005943  ]\n",
      "BEST:\n",
      "0.6456838670165741\n",
      "{'n_neighbors': 9}\n",
      "KNeighborsClassifier(n_neighbors=9)\n",
      "------------------------------\n",
      "{'name': 'DecisionTreeClassifier', 'model': DecisionTreeClassifier(), 'param': {'max_depth': array([ 1, 30])}}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END .......................max_depth=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END .......................max_depth=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END ......................max_depth=30;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END ......................max_depth=30;, score=0.621 total time=   0.1s\n",
      "[CV 3/5] END ......................max_depth=30;, score=0.615 total time=   0.1s\n",
      "[CV 4/5] END ......................max_depth=30;, score=0.622 total time=   0.2s\n",
      "[CV 5/5] END ......................max_depth=30;, score=0.606 total time=   0.1s\n",
      "mean_score: [0.        0.6179961]\n",
      "std_test_score: [0.         0.00720504]\n",
      "BEST:\n",
      "0.6179961028009128\n",
      "{'max_depth': 30}\n",
      "DecisionTreeClassifier(max_depth=30)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param in params_models:\n",
    "    print(param)\n",
    "    model_grid_search = GridSearchCV(estimator=param[\"model\"], param_grid=param[\"param\"], cv=5, scoring=\"f1\",  verbose=7)\n",
    "    model_grid_search.fit(x_train, y_train)\n",
    "    mean_score = model_grid_search.cv_results_[\"mean_test_score\"]\n",
    "    error = model_grid_search.cv_results_[\"std_test_score\"]\n",
    "    \n",
    "    print(f\"mean_score: {mean_score}\")\n",
    "    print(f\"std_test_score: {error}\")\n",
    "    \n",
    "    print(\"BEST:\")\n",
    "    print(model_grid_search.best_score_)\n",
    "    print(model_grid_search.best_params_)\n",
    "    print(model_grid_search.best_estimator_)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6179961028009128\n",
      "{'max_depth': 30}\n",
      "DecisionTreeClassifier(max_depth=30)\n"
     ]
    }
   ],
   "source": [
    "print(model_grid_search.best_score_)\n",
    "print(model_grid_search.best_params_)\n",
    "print(model_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3cbac1b05743dcb73438487c51c8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 99) 20838 5210\n",
      "(20838, 99)\n",
      "trees: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a404e8217b42939da78d32e061389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:1, score: 0.7147700049328861\n",
      "num:2, score: 0.7847379061807843\n",
      "num:3, score: 0.817019516993063\n",
      "num:4, score: 0.8347841057489218\n",
      "num:5, score: 0.8483332463529735\n",
      "num:6, score: 0.8555195236915505\n",
      "num:7, score: 0.8611321563590939\n",
      "num:8, score: 0.8646771558981983\n",
      "num:9, score: 0.8683497266317265\n",
      "num:10, score: 0.8708581602274207\n",
      "num:11, score: 0.8735438537978124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:12, score: 0.875477017289496\n",
      "num:13, score: 0.8794810131872224\n",
      "num:14, score: 0.8818122867856438\n",
      "num:15, score: 0.8828802456405345\n",
      "num:16, score: 0.8837206558759032\n",
      "num:17, score: 0.883967800070744\n",
      "num:18, score: 0.8848138090419183\n",
      "num:19, score: 0.8855509425971615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:20, score: 0.8857441989598749\n",
      "num:21, score: 0.8873562349621456\n",
      "num:22, score: 0.8889275801524017\n",
      "num:23, score: 0.8896324209993383\n",
      "num:24, score: 0.8901516037678692\n",
      "num:25, score: 0.8903404611238782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:26, score: 0.8900275317833233\n",
      "num:27, score: 0.890397648211034\n",
      "num:28, score: 0.8914057205882912\n",
      "num:29, score: 0.8917125513059152\n",
      "num:30, score: 0.8917456438336224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:31, score: 0.8919788911663746\n",
      "num:32, score: 0.8922333337132475\n",
      "num:33, score: 0.8926354429169894\n",
      "num:34, score: 0.8933738761787589\n",
      "num:35, score: 0.8934511587283591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:36, score: 0.8932108129984249\n",
      "num:37, score: 0.8935107452737172\n",
      "num:38, score: 0.8937860831024353\n",
      "num:39, score: 0.8941097100274757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:40, score: 0.8940877149939543\n",
      "num:41, score: 0.8940859154003027\n",
      "num:42, score: 0.8941190079280099\n",
      "num:43, score: 0.8940518230983443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:44, score: 0.8944980223465542\n",
      "num:45, score: 0.8944169406548003\n",
      "num:46, score: 0.894400444379659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:47, score: 0.8944276382392857\n",
      "num:48, score: 0.8945890018033928\n",
      "num:49, score: 0.8947670615974913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:50, score: 0.8950278027221454\n",
      "num:51, score: 0.8954370103230691\n",
      "num:52, score: 0.8952578507772945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:53, score: 0.8954814002998124\n",
      "num:54, score: 0.8957317437722563\n",
      "num:55, score: 0.8960331757089248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:56, score: 0.896010680788278\n",
      "num:57, score: 0.8959187015571883\n",
      "num:58, score: 0.8957555383994293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:59, score: 0.8959765884863198\n",
      "num:60, score: 0.8961320533823462\n",
      "num:61, score: 0.8964084909627406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:62, score: 0.8965820517727097\n",
      "num:63, score: 0.8966458373699219\n",
      "num:64, score: 0.8965502589515287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:65, score: 0.8965564575518847\n",
      "num:66, score: 0.8965957486799481\n",
      "num:67, score: 0.8966709317036212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:68, score: 0.8966320404852585\n",
      "num:69, score: 0.8966863282270863\n",
      "num:70, score: 0.8969031792621226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:71, score: 0.8972100099797465\n",
      "num:72, score: 0.8973125868178966\n",
      "num:73, score: 0.8972889921455736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:74, score: 0.8975205398620991\n",
      "num:75, score: 0.897506942932286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:76, score: 0.8974207623918519\n",
      "num:77, score: 0.897559531057887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:78, score: 0.8975741277619513\n",
      "num:79, score: 0.8977348914615081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:80, score: 0.8976239165196498\n",
      "num:81, score: 0.8977314922290547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:82, score: 0.8977972773747687\n",
      "num:83, score: 0.8980076298771738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:84, score: 0.8979333466503264\n",
      "num:85, score: 0.897840667577261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:86, score: 0.8977564865853291\n",
      "num:87, score: 0.8977144960667881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:88, score: 0.8976583087538834\n",
      "num:89, score: 0.897807775004404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:90, score: 0.8980041306672955\n",
      "num:91, score: 0.8979803360401222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:92, score: 0.8979871345050288\n",
      "num:93, score: 0.8979090521360278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:94, score: 0.8977557867433533\n",
      "num:95, score: 0.8977397903553378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:96, score: 0.8976814035390809\n",
      "num:97, score: 0.8979139510298574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:98, score: 0.8979767368528186\n",
      "num:99, score: 0.8979129512556066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:100, score: 0.8977862798580081\n",
      "(26048, 99) 20838 5210\n",
      "(20838, 99)\n",
      "trees: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffecadcfd424705b4996acba037bfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:1, score: 0.7269771139920301\n",
      "num:2, score: 0.8085530523405747\n",
      "num:3, score: 0.8350367705987561\n",
      "num:4, score: 0.8538232813276139\n",
      "num:5, score: 0.8627604253455278\n",
      "num:6, score: 0.8691897256567368\n",
      "num:7, score: 0.8770542616282853\n",
      "num:8, score: 0.8781816208898898\n",
      "num:9, score: 0.8817923246731193\n",
      "num:10, score: 0.8839961602734705\n",
      "num:11, score: 0.8871218397043117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:12, score: 0.8873224949732036\n",
      "num:13, score: 0.888967709478943\n",
      "num:14, score: 0.890355632947853\n",
      "num:15, score: 0.8910952702884992\n",
      "num:16, score: 0.8927142994304287\n",
      "num:17, score: 0.8939166440520343\n",
      "num:18, score: 0.8949505691745897\n",
      "num:19, score: 0.8956989349698392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:20, score: 0.896146466642227\n",
      "num:21, score: 0.8968522812212854\n",
      "num:22, score: 0.8981792046949564\n",
      "num:23, score: 0.8985426258048032\n",
      "num:24, score: 0.898424295732738\n",
      "num:25, score: 0.8985817054765498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:26, score: 0.8993258062314817\n",
      "num:27, score: 0.8998306679806958\n",
      "num:28, score: 0.9003947443594347\n",
      "num:29, score: 0.9007374353895985\n",
      "num:30, score: 0.9009406695200779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:31, score: 0.9010307313016666\n",
      "num:32, score: 0.9020131783794593\n",
      "num:33, score: 0.9030359945597923\n",
      "num:34, score: 0.90345109208837\n",
      "num:35, score: 0.9033789831509087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:36, score: 0.9032655132410656\n",
      "num:37, score: 0.9038511131953604\n",
      "num:38, score: 0.9041382595144123\n",
      "num:39, score: 0.9043807716906064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:40, score: 0.9045048546077512\n",
      "num:41, score: 0.9044555586766394\n",
      "num:42, score: 0.9047533180029931\n",
      "num:43, score: 0.905163952117285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:44, score: 0.9050255862744259\n",
      "num:45, score: 0.9049299700217259\n",
      "num:46, score: 0.9047599635309297\n",
      "num:47, score: 0.9049248122985513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:48, score: 0.9050702204172836\n",
      "num:49, score: 0.9051072171623635\n",
      "num:50, score: 0.9051972789439523\n",
      "num:51, score: 0.9052055114636349\n",
      "num:52, score: 0.9052432025176037\n",
      "num:53, score: 0.9050717082220456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:54, score: 0.9053895033191932\n",
      "num:55, score: 0.9054033894969712\n",
      "num:56, score: 0.9056520512661813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:57, score: 0.9058875211665024\n",
      "num:58, score: 0.9058004349944376\n",
      "num:59, score: 0.90565105939634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:60, score: 0.9058315797074539\n",
      "num:61, score: 0.9058630219814228\n",
      "num:62, score: 0.9059206496192014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:63, score: 0.9058496317385653\n",
      "num:64, score: 0.9059700447372974\n",
      "num:65, score: 0.9058631211684067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:66, score: 0.9057244577645952\n",
      "num:67, score: 0.9058358447477715\n",
      "num:68, score: 0.9058298935287238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:69, score: 0.9060853000128546\n",
      "num:70, score: 0.9061557227715857\n",
      "num:71, score: 0.9062505455284127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:72, score: 0.9062887325173022\n",
      "num:73, score: 0.9064723276249241\n",
      "num:74, score: 0.9065558430655603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:75, score: 0.9064503081144475\n",
      "num:76, score: 0.9064861146157179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:77, score: 0.90655415688683\n",
      "num:78, score: 0.9066585015941332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:79, score: 0.9066093048500055\n",
      "num:80, score: 0.9064961325011149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:81, score: 0.9065640755852429\n",
      "num:82, score: 0.9066375731404821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:83, score: 0.9067053178506419\n",
      "num:84, score: 0.9068671910087396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:85, score: 0.9070184511595356\n",
      "num:86, score: 0.9071278544030292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:87, score: 0.9072355714677929\n",
      "num:88, score: 0.9073797893427156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:89, score: 0.9073671925957314\n",
      "num:90, score: 0.9073573730843028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:91, score: 0.907555350304623\n",
      "num:92, score: 0.9076026624960523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:93, score: 0.9076730852547835\n",
      "num:94, score: 0.9077241665516098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:95, score: 0.9078309909335162\n",
      "num:96, score: 0.9075967112770047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:97, score: 0.9077010559843078\n",
      "num:98, score: 0.9076812185874822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:99, score: 0.9076374771274814\n",
      "num:100, score: 0.9075242055916067\n",
      "(26048, 99) 20838 5210\n",
      "(20838, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8817e65cf7f4a36ad18109f805bc593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:1, score: 0.7199969369698964\n",
      "num:2, score: 0.78772497823556\n",
      "num:3, score: 0.8242560986825912\n",
      "num:4, score: 0.8411127568270189\n",
      "num:5, score: 0.8513461731802962\n",
      "num:6, score: 0.8642112055103546\n",
      "num:7, score: 0.8721039121746473\n",
      "num:8, score: 0.8798822140527824\n",
      "num:9, score: 0.8839149317823226\n",
      "num:10, score: 0.8859757474089152\n",
      "num:11, score: 0.8865079030051344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:12, score: 0.8883680514132255\n",
      "num:13, score: 0.8898131001025564\n",
      "num:14, score: 0.8904751591725414\n",
      "num:15, score: 0.8916490827937853\n",
      "num:16, score: 0.8924645992640978\n",
      "num:17, score: 0.8925182328804249\n",
      "num:18, score: 0.893805133777126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:19, score: 0.894297115143625\n",
      "num:20, score: 0.8960984297178362\n",
      "num:21, score: 0.8961074026422406\n",
      "num:22, score: 0.8968040278641932\n",
      "num:23, score: 0.8970933027111896\n",
      "num:24, score: 0.8974777109498839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:25, score: 0.897748530122821\n",
      "num:26, score: 0.8981691359542837\n",
      "num:27, score: 0.8982046197917017\n",
      "num:28, score: 0.8987774594428916\n",
      "num:29, score: 0.899234772692373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:30, score: 0.8993706921040916\n",
      "num:31, score: 0.8990403253419246\n",
      "num:32, score: 0.8991718602564911\n",
      "num:33, score: 0.8988171238473616\n",
      "num:34, score: 0.8991413727065256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:35, score: 0.8990566397499328\n",
      "num:36, score: 0.8990861076493977\n",
      "num:37, score: 0.8991694130952899\n",
      "num:38, score: 0.899385273106249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:39, score: 0.8994008737589068\n",
      "num:40, score: 0.9001340024687778\n",
      "num:41, score: 0.8999804431034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:42, score: 0.9002097625009661\n",
      "num:43, score: 0.9003892209890569\n",
      "num:44, score: 0.9002709415309971\n",
      "num:45, score: 0.9002718592164475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:46, score: 0.9007244820736265\n",
      "num:47, score: 0.900734984473782\n",
      "num:48, score: 0.9005242227153252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:49, score: 0.900812375946771\n",
      "num:50, score: 0.9009886735183101\n",
      "num:51, score: 0.9009131174162219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:52, score: 0.9011566099557451\n",
      "num:53, score: 0.9013828704018096\n",
      "num:54, score: 0.9019168613689296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:55, score: 0.9019342973924886\n",
      "num:56, score: 0.9020054689974246\n",
      "num:57, score: 0.9019189006699307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:58, score: 0.9020547181165994\n",
      "num:59, score: 0.9020121986907279\n",
      "num:60, score: 0.9020940766259193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:61, score: 0.9023671390299575\n",
      "num:62, score: 0.9023550051890014\n",
      "num:63, score: 0.9024468756990979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:64, score: 0.9027095376680307\n",
      "num:65, score: 0.9027878468264703\n",
      "num:66, score: 0.9031121976506844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:67, score: 0.9030782432890173\n",
      "num:68, score: 0.9030861965629213\n",
      "num:69, score: 0.9033360109355477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:70, score: 0.9034018803578809\n",
      "num:71, score: 0.9034512314421059\n",
      "num:72, score: 0.9036783076085709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:73, score: 0.9039677863856673\n",
      "num:74, score: 0.9041619278409656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:75, score: 0.9042374839430537\n",
      "num:76, score: 0.9042328955158014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:77, score: 0.9043374096921043\n",
      "num:78, score: 0.9040769909542725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:79, score: 0.9041375581940032\n",
      "num:80, score: 0.904143370201856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:81, score: 0.9043242562006477\n",
      "num:82, score: 0.9043433236650074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:83, score: 0.9043135498703923\n",
      "num:84, score: 0.9043451590359082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:85, score: 0.9044490614219108\n",
      "num:86, score: 0.9045450105340094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:87, score: 0.9046994875848375\n",
      "num:88, score: 0.9048286773032528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:89, score: 0.9049618436586202\n",
      "num:90, score: 0.9049149397355966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:91, score: 0.9050852213691825\n",
      "num:92, score: 0.9049199360230489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:93, score: 0.9051043907985924\n",
      "num:94, score: 0.9050803270467801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:95, score: 0.904949607852614\n",
      "num:96, score: 0.9049260539260521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:97, score: 0.9051523143721165\n",
      "num:98, score: 0.9052470399036145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:99, score: 0.9052861944828343\n",
      "num:100, score: 0.9053642997111737\n",
      "(26048, 99) 20839 5209\n",
      "(20839, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4f9603fd864127883247a2799ca52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:1, score: 0.7348472304012809\n",
      "num:2, score: 0.801217749435697\n",
      "num:3, score: 0.8341381319541884\n",
      "num:4, score: 0.8492396484242879\n",
      "num:5, score: 0.8600744975637127\n",
      "num:6, score: 0.8686459089420733\n",
      "num:7, score: 0.8748293810323583\n",
      "num:8, score: 0.8794675816698891\n",
      "num:9, score: 0.8829709508887126\n",
      "num:10, score: 0.8848984420293915\n",
      "num:11, score: 0.886817114311907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:12, score: 0.8882027125562695\n",
      "num:13, score: 0.8889969285473287\n",
      "num:14, score: 0.8905811067272741\n",
      "num:15, score: 0.8916032642640361\n",
      "num:16, score: 0.8916156106654648\n",
      "num:17, score: 0.8916813889722357\n",
      "num:18, score: 0.8914197282629672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:19, score: 0.8921035529000763\n",
      "num:20, score: 0.8921306319822011\n",
      "num:21, score: 0.8930874262172825\n",
      "num:22, score: 0.8932383843187837\n",
      "num:23, score: 0.8940760720930241\n",
      "num:24, score: 0.8948776544244315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:25, score: 0.8954771292769905\n",
      "num:26, score: 0.8967483936190477\n",
      "num:27, score: 0.896944587275363\n",
      "num:28, score: 0.8969980191807052\n",
      "num:29, score: 0.8976928414527005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:30, score: 0.898042068235967\n",
      "num:31, score: 0.8979636322739498\n",
      "num:32, score: 0.8979626985124973\n",
      "num:33, score: 0.8983498982615022\n",
      "num:34, score: 0.8985496194610827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:35, score: 0.8984520932649239\n",
      "num:36, score: 0.8987040013545767\n",
      "num:37, score: 0.8988663720960539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:38, score: 0.8992855272369915\n",
      "num:39, score: 0.8990736671385275\n",
      "num:40, score: 0.8994242426883367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:41, score: 0.8993246414667275\n",
      "num:42, score: 0.8992411216923575\n",
      "num:43, score: 0.8993998611392969\n",
      "num:44, score: 0.8996323677409903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:45, score: 0.9000258963176183\n",
      "num:46, score: 0.9004013721728297\n",
      "num:47, score: 0.9006225698858197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:48, score: 0.9007116922289052\n",
      "num:49, score: 0.9009512539171294\n",
      "num:50, score: 0.9013187409243573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:51, score: 0.9012361549114399\n",
      "num:52, score: 0.9011983894482465\n",
      "num:53, score: 0.9010348774427718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:54, score: 0.9012877192938771\n",
      "num:55, score: 0.9013620052049938\n",
      "num:56, score: 0.9013004807003957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:57, score: 0.9013378311584992\n",
      "num:58, score: 0.9015247909515611\n",
      "num:59, score: 0.9014399224106484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:60, score: 0.9014293397808525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:61, score: 0.9014541363349822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:62, score: 0.9015108882810448\n",
      "num:63, score: 0.9015703377601927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:64, score: 0.9015164908497604\n",
      "num:65, score: 0.901496051849076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:66, score: 0.901524790951561\n",
      "num:67, score: 0.9016022931521256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:68, score: 0.9021508261298825\n",
      "num:69, score: 0.9021902516134361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:70, score: 0.9020574499846241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:71, score: 0.9022131806446606\n",
      "num:72, score: 0.902123643296485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:73, score: 0.9019285909041674\n",
      "num:74, score: 0.9019699876618985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:75, score: 0.9020409535322951\n",
      "num:76, score: 0.9020076493738196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:77, score: 0.9022198207261012\n",
      "num:78, score: 0.9020943854376373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:79, score: 0.9021958541821515\n",
      "num:80, score: 0.9022600762198348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:81, score: 0.902222414507914\n",
      "num:82, score: 0.9021976179537842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:83, score: 0.9024155993773264\n",
      "num:84, score: 0.9023870677773862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:85, score: 0.9026031816780232\n",
      "num:86, score: 0.9028217856092005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:87, score: 0.9029269893995249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:88, score: 0.9028231343757431\n",
      "num:89, score: 0.9029108042010134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:90, score: 0.9030196392858758\n",
      "num:91, score: 0.9029285456686126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:92, score: 0.9030550184698015\n",
      "num:93, score: 0.9031425845437994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:94, score: 0.9032314993843399\n",
      "num:95, score: 0.9032560884359246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:96, score: 0.9033684510640523\n",
      "num:97, score: 0.9035165041299232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:98, score: 0.9035509495523963\n",
      "num:99, score: 0.9035694172789028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:100, score: 0.903693088795734\n",
      "(26048, 99) 20839 5209\n",
      "(20839, 99)\n",
      "trees: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7220f38692964533bd9ade00e6693466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:1, score: 0.7364781987665827\n",
      "num:2, score: 0.8045651246171251\n",
      "num:3, score: 0.8376304744128372\n",
      "num:4, score: 0.8521210317613684\n",
      "num:5, score: 0.8640582429398276\n",
      "num:6, score: 0.8723138757608169\n",
      "num:7, score: 0.8778678740741132\n",
      "num:8, score: 0.8843929677561351\n",
      "num:9, score: 0.8854817377521766\n",
      "num:10, score: 0.8890588633505678\n",
      "num:11, score: 0.8926017137982197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:12, score: 0.8935450432436456\n",
      "num:13, score: 0.8936543779233042\n",
      "num:14, score: 0.8945747216593323\n",
      "num:15, score: 0.8957637744406236\n",
      "num:16, score: 0.8971398658041398\n",
      "num:17, score: 0.8984669345484977\n",
      "num:18, score: 0.8993645976951639\n",
      "num:19, score: 0.9001261773056599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:20, score: 0.9005043227372603\n",
      "num:21, score: 0.9010643197104695\n",
      "num:22, score: 0.9023633174114918\n",
      "num:23, score: 0.9028705286184286\n",
      "num:24, score: 0.9028817163530913\n",
      "num:25, score: 0.9035611169671557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:26, score: 0.9042957443077823\n",
      "num:27, score: 0.9046562944839586\n",
      "num:28, score: 0.9045503161246988\n",
      "num:29, score: 0.9046698214722326\n",
      "num:30, score: 0.9047200645715362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:31, score: 0.9048151603161695\n",
      "num:32, score: 0.9048522832539139\n",
      "num:33, score: 0.9054805254085659\n",
      "num:34, score: 0.9059900758691141\n",
      "num:35, score: 0.9059554955983383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:36, score: 0.9062798381968789\n",
      "num:37, score: 0.9066249289578849\n",
      "num:38, score: 0.9067842016168108\n",
      "num:39, score: 0.9069570012640107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:40, score: 0.9071327504048943\n",
      "num:41, score: 0.907106611788455\n",
      "num:42, score: 0.9069414401421615\n",
      "num:43, score: 0.906920793686375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:44, score: 0.9070371461268674\n",
      "num:45, score: 0.9069234380600224\n",
      "num:46, score: 0.9071629572884836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:47, score: 0.9071462773931684\n",
      "num:48, score: 0.9076009062471904\n",
      "num:49, score: 0.9074665517245588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:50, score: 0.9076165690757182\n",
      "num:51, score: 0.9074725524186052\n",
      "num:52, score: 0.9077003753790099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:53, score: 0.9078695135857748\n",
      "num:54, score: 0.9080643835822638\n",
      "num:55, score: 0.908254676778209\n",
      "num:56, score: 0.9082820358747934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:57, score: 0.9085260301971197\n",
      "num:58, score: 0.9087640238253998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:59, score: 0.9088715277848408\n",
      "num:60, score: 0.9089001073615701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:61, score: 0.9090098488679437\n",
      "num:62, score: 0.909133625895985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:63, score: 0.908966216702759\n",
      "num:64, score: 0.9088825121061459\n",
      "num:65, score: 0.9090401574582117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:66, score: 0.9092726589258391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:67, score: 0.9092246533734681\n",
      "num:68, score: 0.9093729417110887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:69, score: 0.9094810559106024\n",
      "num:70, score: 0.9095048552734304\n",
      "num:71, score: 0.9095655741606454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:72, score: 0.909804889975749\n",
      "num:73, score: 0.909717117111986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:74, score: 0.9097759035723048\n",
      "num:75, score: 0.9097855657067861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:76, score: 0.9095312990099058\n",
      "num:77, score: 0.909822993764567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:78, score: 0.9099019181472785\n",
      "num:79, score: 0.9098120094432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:80, score: 0.9098313337122246\n",
      "num:81, score: 0.9098810682781344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:82, score: 0.909864388382819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:83, score: 0.9099577551139135\n",
      "num:84, score: 0.9101317752412583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:85, score: 0.9101892395147533\n",
      "num:86, score: 0.9101990033559136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:87, score: 0.9101950367954422\n",
      "num:88, score: 0.9102461952548546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:89, score: 0.9103896016718951\n",
      "num:90, score: 0.9106266799400664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:91, score: 0.9106751940258311\n",
      "num:92, score: 0.9107095708832492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:93, score: 0.910888167811138\n",
      "num:94, score: 0.9109619051532333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:95, score: 0.9110224206270908\n",
      "num:96, score: 0.9109346477633278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:97, score: 0.9108952872786507\n",
      "num:98, score: 0.9108259233237417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:99, score: 0.9108921343716093\n",
      "num:100, score: 0.9111576905098311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "max_trees = 100\n",
    "n_splits = 5\n",
    "values = np.arange(1, max_trees + 1)\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=53)\n",
    "\n",
    "for k_train, k_valid in tqdm(kf.split(x_train), total=n_splits):\n",
    "    scores = []\n",
    "#     print(f\"k_train: {k_train[:30]}\")\n",
    "#     print(f\"k_validate: {k_valid[:30]}\")\n",
    "    print(x_train.shape, len(k_train), len(k_valid))\n",
    "    print(x_train.iloc[k_train].shape)\n",
    "    \n",
    "    kfold_x_train = x_train.iloc[k_train]\n",
    "    kfold_y_train = y_train.iloc[k_train]\n",
    "\n",
    "    kfold_x_valid = x_train.iloc[k_valid]\n",
    "    kfold_y_valid = y_train.iloc[k_valid]\n",
    "    \n",
    "    forest_model = RandomForestClassifier(n_estimators=max_trees)\n",
    "    forest_model.fit(kfold_x_train, kfold_y_train)\n",
    "    trees = forest_model.estimators_\n",
    "    print(f\"trees: {len(trees)}\")\n",
    "    \n",
    "    for num in tqdm(values):\n",
    "        random_forest_model = RandomForestClassifier(n_estimators=num)\n",
    "        random_forest_model.n_classes_ = 2\n",
    "        random_forest_model.estimators_ = trees[:num]\n",
    "#         print(f\"n_classes_: {random_forest_model.n_classes_}\")\n",
    "#         print(\"estimators_\" ,random_forest_model.estimators_)\n",
    "        predict = random_forest_model.predict_proba(kfold_x_valid)[:,1]\n",
    "#         print(f\"predict: {predict}\")\n",
    "        print(f\"num:{num}, score: {roc_auc_score(kfold_y_valid, predict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score_test: 0.8934906423256599\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=50, )\n",
    "rf_model.fit(x_train, y_train)\n",
    "predict = rf_model.predict_proba(x_test)[:,-1]\n",
    "\n",
    "roc_auc_score_test = roc_auc_score(y_test, predict)\n",
    "print(f\"roc_auc_score_test: {roc_auc_score_test}\")\n",
    "# print(random_forest_model.best_score_)\n",
    "# print(random_forest_model.best_params_)\n",
    "# print(random_forest_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     KNeighborsClassifier(n_neighbors=5),\n",
    "    KNeighborsClassifier(n_neighbors=30, n_jobs=-1),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(max_depth=3, n_estimators=50, n_jobs=-1),\n",
    "    RandomForestClassifier(max_depth=7, n_estimators=50, n_jobs=-1),\n",
    "#     DecisionTreeClassifier(max_depth=3),\n",
    "    DecisionTreeClassifier(max_depth=8),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 1), (6513, 1))"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_model_predicts = np.zeros(x_train.shape[0])[...,None]\n",
    "test_features_model_predicts = np.zeros(x_test.shape[0])[...,None]\n",
    "\n",
    "train_features_model_predicts.shape, test_features_model_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: KNeighborsClassifier(n_jobs=-1, n_neighbors=30)\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "cv_predict (26048, 2)\n",
      "predict_test (6513, 2)\n",
      "shape: (26048, 2)\n",
      "model: LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "D:\\_Work\\_Projects\\_Conda\\School\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_predict (26048, 2)\n",
      "predict_test (6513, 2)\n",
      "shape: (26048, 3)\n",
      "model: RandomForestClassifier(max_depth=3, n_estimators=50, n_jobs=-1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "cv_predict (26048, 2)\n",
      "predict_test (6513, 2)\n",
      "shape: (26048, 4)\n",
      "model: RandomForestClassifier(max_depth=7, n_estimators=50, n_jobs=-1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "cv_predict (26048, 2)\n",
      "predict_test (6513, 2)\n",
      "shape: (26048, 5)\n",
      "model: DecisionTreeClassifier(max_depth=8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "cv_predict (26048, 2)\n",
      "predict_test (6513, 2)\n",
      "shape: (26048, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((26048, 5), (6513, 5))"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"model: {model}\")\n",
    "    model.fit(x_train, y_train)\n",
    "    print(type(model))\n",
    "    \n",
    "    if type(model) == type(LogisticRegression):\n",
    "        cv_predict = cross_val_predict(model, x_train, y_train, cv=5, method=\"predict\")\n",
    "        predict_test = model.predict(x_test)\n",
    "    else:\n",
    "        cv_predict = cross_val_predict(model, x_train, y_train, cv=5, method=\"predict_proba\")\n",
    "        predict_test = model.predict_proba(x_test)\n",
    "\n",
    "    train_features_model_predicts = np.concatenate((train_features_model_predicts, cv_predict[:, -1][...,None]), axis=1)\n",
    "    print(\"cv_predict\", cv_predict.shape)\n",
    "    \n",
    "    print(\"predict_test\", predict_test.shape)\n",
    "    test_features_model_predicts = np.concatenate((test_features_model_predicts, predict_test[:, -1][...,None]), axis=1)\n",
    "    \n",
    "    print(f\"shape: {train_features_model_predicts.shape}\")\n",
    "train_features_model_predicts = train_features_model_predicts[:,1:]\n",
    "test_features_model_predicts = test_features_model_predicts[:,1:]\n",
    "    \n",
    "train_features_model_predicts.shape, test_features_model_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.23541486, 0.33774353, 0.35489748, 0.16774194],\n",
       "       [0.13333333, 0.11461162, 0.2745923 , 0.24403564, 0.13595166],\n",
       "       [0.        , 0.00265649, 0.07145064, 0.01775516, 0.00280308],\n",
       "       ...,\n",
       "       [0.6       , 0.09390242, 0.20817408, 0.23877031, 0.6       ],\n",
       "       [0.        , 0.02890825, 0.18453027, 0.11170615, 0.13065327],\n",
       "       [0.83333333, 0.71364019, 0.42297946, 0.4852633 , 0.96621622]])"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_model_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.23541485, 0.3098159 , 0.31590381, 0.16774194],\n",
       "       [0.13333333, 0.11461164, 0.26008878, 0.23118577, 0.13595166],\n",
       "       [0.        , 0.00265649, 0.07397786, 0.0144256 , 0.00280308],\n",
       "       ...,\n",
       "       [0.6       , 0.09390241, 0.19485564, 0.19881144, 0.6       ],\n",
       "       [0.        , 0.02890825, 0.20437561, 0.15955095, 0.13065327],\n",
       "       [0.83333333, 0.71364019, 0.36752825, 0.57986482, 0.96621622]])"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 5), (6513, 5))"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_model_predicts.shape, test_features_model_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7584773768411884, 0.9097823114901176)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking_model = LinearRegression()\n",
    "# stacking_model = KNeighborsClassifier(n_neighbors=100)\n",
    "stacking_model = LogisticRegression()\n",
    "# stacking_model = RandomForestClassifier(n_estimators=100, )\n",
    "\n",
    "stacking_model.fit(train_features_model_predicts, y_train)\n",
    "\n",
    "predict_stacking_model = stacking_model.predict(test_features_model_predicts)\n",
    "predict_stacking_model_proba = stacking_model.predict_proba(test_features_model_predicts)[:, 1]\n",
    "# y_train_predicted2 =     stacking_model.predict_proba(train_features_model_predicts)[:, 1]\n",
    "predict_stacking_model\n",
    "\n",
    "roc_auc_score(y_test, predict_stacking_model), roc_auc_score(y_test, predict_stacking_model_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8998292143175668"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta_features_test == test_features_model_predicts\n",
    "stacking_model = LogisticRegression()\n",
    "stacking_model = RandomForestClassifier(n_estimators=50, )\n",
    "stacking_model.fit(train_features_model_predicts, y_train)\n",
    "\n",
    "\n",
    "y_train_predicted2 = stacking_model.predict_proba(train_features_model_predicts)[:, 1]\n",
    "y_test_predicted2 = stacking_model.predict_proba(test_features_model_predicts)[:, 1]\n",
    "roc_auc_score(y_test, y_test_predicted2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=50, )\n",
    "rf_model.fit(x_train, y_train)\n",
    "predict = rf_model.predict_proba(x_test)[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9101433845968616"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "boosting_model = xgboost.XGBClassifier(n_estimators=500)\n",
    "boosting_model.fit(x_train, y_train)\n",
    "\n",
    "predict_boosting = boosting_model.predict_proba(x_test)[:, 1]\n",
    "roc_auc_score(y_test, predict_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243603061899945"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost\n",
    "boosting_model = catboost.CatBoostClassifier(n_estimators=500,)\n",
    "boosting_model.fit(x_train, y_train)\n",
    "\n",
    "predict_boosting = boosting_model.predict_proba(x_test)[:, 1]\n",
    "roc_auc_score(y_test, predict_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d19215ec74d7cbca7c04b1a9e8306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.9302303117\n",
      "bestIteration = 421\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "0:\tloss: 0.9302303\tbest: 0.9302303 (0)\ttotal: 3.78s\tremaining: 1m 11s\n",
      "\n",
      "bestTest = 0.9314734645\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "1:\tloss: 0.9314735\tbest: 0.9314735 (1)\ttotal: 7.18s\tremaining: 1m 4s\n",
      "\n",
      "bestTest = 0.9321582865\n",
      "bestIteration = 490\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "2:\tloss: 0.9321583\tbest: 0.9321583 (2)\ttotal: 10.2s\tremaining: 57.9s\n",
      "\n",
      "bestTest = 0.9312020777\n",
      "bestIteration = 497\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "3:\tloss: 0.9312021\tbest: 0.9321583 (2)\ttotal: 13.8s\tremaining: 55s\n",
      "\n",
      "bestTest = 0.9316466274\n",
      "bestIteration = 495\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "4:\tloss: 0.9316466\tbest: 0.9321583 (2)\ttotal: 16.9s\tremaining: 50.6s\n",
      "\n",
      "bestTest = 0.9309336397\n",
      "bestIteration = 493\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "5:\tloss: 0.9309336\tbest: 0.9321583 (2)\ttotal: 20s\tremaining: 46.7s\n",
      "\n",
      "bestTest = 0.9316059549\n",
      "bestIteration = 482\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "6:\tloss: 0.9316060\tbest: 0.9321583 (2)\ttotal: 23.3s\tremaining: 43.3s\n",
      "\n",
      "bestTest = 0.9314511963\n",
      "bestIteration = 495\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "7:\tloss: 0.9314512\tbest: 0.9321583 (2)\ttotal: 26.3s\tremaining: 39.5s\n",
      "\n",
      "bestTest = 0.9316232407\n",
      "bestIteration = 484\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "8:\tloss: 0.9316232\tbest: 0.9321583 (2)\ttotal: 29.4s\tremaining: 35.9s\n",
      "\n",
      "bestTest = 0.931298573\n",
      "bestIteration = 492\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "9:\tloss: 0.9312986\tbest: 0.9321583 (2)\ttotal: 32.4s\tremaining: 32.4s\n",
      "\n",
      "bestTest = 0.9314192685\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "10:\tloss: 0.9314193\tbest: 0.9321583 (2)\ttotal: 35.5s\tremaining: 29.1s\n",
      "\n",
      "bestTest = 0.9316726577\n",
      "bestIteration = 496\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "11:\tloss: 0.9316727\tbest: 0.9321583 (2)\ttotal: 38.8s\tremaining: 25.9s\n",
      "\n",
      "bestTest = 0.9310825008\n",
      "bestIteration = 495\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "12:\tloss: 0.9310825\tbest: 0.9321583 (2)\ttotal: 43.9s\tremaining: 23.6s\n",
      "\n",
      "bestTest = 0.9316313752\n",
      "bestIteration = 498\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "13:\tloss: 0.9316314\tbest: 0.9321583 (2)\ttotal: 47.5s\tremaining: 20.3s\n",
      "\n",
      "bestTest = 0.931213771\n",
      "bestIteration = 497\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "14:\tloss: 0.9312138\tbest: 0.9321583 (2)\ttotal: 51.7s\tremaining: 17.2s\n",
      "\n",
      "bestTest = 0.9314101172\n",
      "bestIteration = 498\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "15:\tloss: 0.9314101\tbest: 0.9321583 (2)\ttotal: 56.9s\tremaining: 14.2s\n",
      "\n",
      "bestTest = 0.9316305618\n",
      "bestIteration = 489\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "16:\tloss: 0.9316306\tbest: 0.9321583 (2)\ttotal: 1m\tremaining: 10.7s\n",
      "\n",
      "bestTest = 0.9315018335\n",
      "bestIteration = 497\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "17:\tloss: 0.9315018\tbest: 0.9321583 (2)\ttotal: 1m 4s\tremaining: 7.12s\n",
      "\n",
      "bestTest = 0.9314873948\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "18:\tloss: 0.9314874\tbest: 0.9321583 (2)\ttotal: 1m 7s\tremaining: 3.56s\n",
      "\n",
      "bestTest = 0.9313753423\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "19:\tloss: 0.9313753\tbest: 0.9321583 (2)\ttotal: 1m 11s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.9260462425\n",
      "bestIteration = 495\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.9252071575\n",
      "bestIteration = 499\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.9309225156\n",
      "bestIteration = 499\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'l2_leaf_reg': 0.10526315789473684},\n",
       " 'cv_results': defaultdict(list,\n",
       "             {'iterations': [0,\n",
       "               1,\n",
       "               2,\n",
       "               3,\n",
       "               4,\n",
       "               5,\n",
       "               6,\n",
       "               7,\n",
       "               8,\n",
       "               9,\n",
       "               10,\n",
       "               11,\n",
       "               12,\n",
       "               13,\n",
       "               14,\n",
       "               15,\n",
       "               16,\n",
       "               17,\n",
       "               18,\n",
       "               19,\n",
       "               20,\n",
       "               21,\n",
       "               22,\n",
       "               23,\n",
       "               24,\n",
       "               25,\n",
       "               26,\n",
       "               27,\n",
       "               28,\n",
       "               29,\n",
       "               30,\n",
       "               31,\n",
       "               32,\n",
       "               33,\n",
       "               34,\n",
       "               35,\n",
       "               36,\n",
       "               37,\n",
       "               38,\n",
       "               39,\n",
       "               40,\n",
       "               41,\n",
       "               42,\n",
       "               43,\n",
       "               44,\n",
       "               45,\n",
       "               46,\n",
       "               47,\n",
       "               48,\n",
       "               49,\n",
       "               50,\n",
       "               51,\n",
       "               52,\n",
       "               53,\n",
       "               54,\n",
       "               55,\n",
       "               56,\n",
       "               57,\n",
       "               58,\n",
       "               59,\n",
       "               60,\n",
       "               61,\n",
       "               62,\n",
       "               63,\n",
       "               64,\n",
       "               65,\n",
       "               66,\n",
       "               67,\n",
       "               68,\n",
       "               69,\n",
       "               70,\n",
       "               71,\n",
       "               72,\n",
       "               73,\n",
       "               74,\n",
       "               75,\n",
       "               76,\n",
       "               77,\n",
       "               78,\n",
       "               79,\n",
       "               80,\n",
       "               81,\n",
       "               82,\n",
       "               83,\n",
       "               84,\n",
       "               85,\n",
       "               86,\n",
       "               87,\n",
       "               88,\n",
       "               89,\n",
       "               90,\n",
       "               91,\n",
       "               92,\n",
       "               93,\n",
       "               94,\n",
       "               95,\n",
       "               96,\n",
       "               97,\n",
       "               98,\n",
       "               99,\n",
       "               100,\n",
       "               101,\n",
       "               102,\n",
       "               103,\n",
       "               104,\n",
       "               105,\n",
       "               106,\n",
       "               107,\n",
       "               108,\n",
       "               109,\n",
       "               110,\n",
       "               111,\n",
       "               112,\n",
       "               113,\n",
       "               114,\n",
       "               115,\n",
       "               116,\n",
       "               117,\n",
       "               118,\n",
       "               119,\n",
       "               120,\n",
       "               121,\n",
       "               122,\n",
       "               123,\n",
       "               124,\n",
       "               125,\n",
       "               126,\n",
       "               127,\n",
       "               128,\n",
       "               129,\n",
       "               130,\n",
       "               131,\n",
       "               132,\n",
       "               133,\n",
       "               134,\n",
       "               135,\n",
       "               136,\n",
       "               137,\n",
       "               138,\n",
       "               139,\n",
       "               140,\n",
       "               141,\n",
       "               142,\n",
       "               143,\n",
       "               144,\n",
       "               145,\n",
       "               146,\n",
       "               147,\n",
       "               148,\n",
       "               149,\n",
       "               150,\n",
       "               151,\n",
       "               152,\n",
       "               153,\n",
       "               154,\n",
       "               155,\n",
       "               156,\n",
       "               157,\n",
       "               158,\n",
       "               159,\n",
       "               160,\n",
       "               161,\n",
       "               162,\n",
       "               163,\n",
       "               164,\n",
       "               165,\n",
       "               166,\n",
       "               167,\n",
       "               168,\n",
       "               169,\n",
       "               170,\n",
       "               171,\n",
       "               172,\n",
       "               173,\n",
       "               174,\n",
       "               175,\n",
       "               176,\n",
       "               177,\n",
       "               178,\n",
       "               179,\n",
       "               180,\n",
       "               181,\n",
       "               182,\n",
       "               183,\n",
       "               184,\n",
       "               185,\n",
       "               186,\n",
       "               187,\n",
       "               188,\n",
       "               189,\n",
       "               190,\n",
       "               191,\n",
       "               192,\n",
       "               193,\n",
       "               194,\n",
       "               195,\n",
       "               196,\n",
       "               197,\n",
       "               198,\n",
       "               199,\n",
       "               200,\n",
       "               201,\n",
       "               202,\n",
       "               203,\n",
       "               204,\n",
       "               205,\n",
       "               206,\n",
       "               207,\n",
       "               208,\n",
       "               209,\n",
       "               210,\n",
       "               211,\n",
       "               212,\n",
       "               213,\n",
       "               214,\n",
       "               215,\n",
       "               216,\n",
       "               217,\n",
       "               218,\n",
       "               219,\n",
       "               220,\n",
       "               221,\n",
       "               222,\n",
       "               223,\n",
       "               224,\n",
       "               225,\n",
       "               226,\n",
       "               227,\n",
       "               228,\n",
       "               229,\n",
       "               230,\n",
       "               231,\n",
       "               232,\n",
       "               233,\n",
       "               234,\n",
       "               235,\n",
       "               236,\n",
       "               237,\n",
       "               238,\n",
       "               239,\n",
       "               240,\n",
       "               241,\n",
       "               242,\n",
       "               243,\n",
       "               244,\n",
       "               245,\n",
       "               246,\n",
       "               247,\n",
       "               248,\n",
       "               249,\n",
       "               250,\n",
       "               251,\n",
       "               252,\n",
       "               253,\n",
       "               254,\n",
       "               255,\n",
       "               256,\n",
       "               257,\n",
       "               258,\n",
       "               259,\n",
       "               260,\n",
       "               261,\n",
       "               262,\n",
       "               263,\n",
       "               264,\n",
       "               265,\n",
       "               266,\n",
       "               267,\n",
       "               268,\n",
       "               269,\n",
       "               270,\n",
       "               271,\n",
       "               272,\n",
       "               273,\n",
       "               274,\n",
       "               275,\n",
       "               276,\n",
       "               277,\n",
       "               278,\n",
       "               279,\n",
       "               280,\n",
       "               281,\n",
       "               282,\n",
       "               283,\n",
       "               284,\n",
       "               285,\n",
       "               286,\n",
       "               287,\n",
       "               288,\n",
       "               289,\n",
       "               290,\n",
       "               291,\n",
       "               292,\n",
       "               293,\n",
       "               294,\n",
       "               295,\n",
       "               296,\n",
       "               297,\n",
       "               298,\n",
       "               299,\n",
       "               300,\n",
       "               301,\n",
       "               302,\n",
       "               303,\n",
       "               304,\n",
       "               305,\n",
       "               306,\n",
       "               307,\n",
       "               308,\n",
       "               309,\n",
       "               310,\n",
       "               311,\n",
       "               312,\n",
       "               313,\n",
       "               314,\n",
       "               315,\n",
       "               316,\n",
       "               317,\n",
       "               318,\n",
       "               319,\n",
       "               320,\n",
       "               321,\n",
       "               322,\n",
       "               323,\n",
       "               324,\n",
       "               325,\n",
       "               326,\n",
       "               327,\n",
       "               328,\n",
       "               329,\n",
       "               330,\n",
       "               331,\n",
       "               332,\n",
       "               333,\n",
       "               334,\n",
       "               335,\n",
       "               336,\n",
       "               337,\n",
       "               338,\n",
       "               339,\n",
       "               340,\n",
       "               341,\n",
       "               342,\n",
       "               343,\n",
       "               344,\n",
       "               345,\n",
       "               346,\n",
       "               347,\n",
       "               348,\n",
       "               349,\n",
       "               350,\n",
       "               351,\n",
       "               352,\n",
       "               353,\n",
       "               354,\n",
       "               355,\n",
       "               356,\n",
       "               357,\n",
       "               358,\n",
       "               359,\n",
       "               360,\n",
       "               361,\n",
       "               362,\n",
       "               363,\n",
       "               364,\n",
       "               365,\n",
       "               366,\n",
       "               367,\n",
       "               368,\n",
       "               369,\n",
       "               370,\n",
       "               371,\n",
       "               372,\n",
       "               373,\n",
       "               374,\n",
       "               375,\n",
       "               376,\n",
       "               377,\n",
       "               378,\n",
       "               379,\n",
       "               380,\n",
       "               381,\n",
       "               382,\n",
       "               383,\n",
       "               384,\n",
       "               385,\n",
       "               386,\n",
       "               387,\n",
       "               388,\n",
       "               389,\n",
       "               390,\n",
       "               391,\n",
       "               392,\n",
       "               393,\n",
       "               394,\n",
       "               395,\n",
       "               396,\n",
       "               397,\n",
       "               398,\n",
       "               399,\n",
       "               400,\n",
       "               401,\n",
       "               402,\n",
       "               403,\n",
       "               404,\n",
       "               405,\n",
       "               406,\n",
       "               407,\n",
       "               408,\n",
       "               409,\n",
       "               410,\n",
       "               411,\n",
       "               412,\n",
       "               413,\n",
       "               414,\n",
       "               415,\n",
       "               416,\n",
       "               417,\n",
       "               418,\n",
       "               419,\n",
       "               420,\n",
       "               421,\n",
       "               422,\n",
       "               423,\n",
       "               424,\n",
       "               425,\n",
       "               426,\n",
       "               427,\n",
       "               428,\n",
       "               429,\n",
       "               430,\n",
       "               431,\n",
       "               432,\n",
       "               433,\n",
       "               434,\n",
       "               435,\n",
       "               436,\n",
       "               437,\n",
       "               438,\n",
       "               439,\n",
       "               440,\n",
       "               441,\n",
       "               442,\n",
       "               443,\n",
       "               444,\n",
       "               445,\n",
       "               446,\n",
       "               447,\n",
       "               448,\n",
       "               449,\n",
       "               450,\n",
       "               451,\n",
       "               452,\n",
       "               453,\n",
       "               454,\n",
       "               455,\n",
       "               456,\n",
       "               457,\n",
       "               458,\n",
       "               459,\n",
       "               460,\n",
       "               461,\n",
       "               462,\n",
       "               463,\n",
       "               464,\n",
       "               465,\n",
       "               466,\n",
       "               467,\n",
       "               468,\n",
       "               469,\n",
       "               470,\n",
       "               471,\n",
       "               472,\n",
       "               473,\n",
       "               474,\n",
       "               475,\n",
       "               476,\n",
       "               477,\n",
       "               478,\n",
       "               479,\n",
       "               480,\n",
       "               481,\n",
       "               482,\n",
       "               483,\n",
       "               484,\n",
       "               485,\n",
       "               486,\n",
       "               487,\n",
       "               488,\n",
       "               489,\n",
       "               490,\n",
       "               491,\n",
       "               492,\n",
       "               493,\n",
       "               494,\n",
       "               495,\n",
       "               496,\n",
       "               497,\n",
       "               498,\n",
       "               499],\n",
       "              'test-AUC-mean': [0.878132608795466,\n",
       "               0.8896777640603976,\n",
       "               0.8934489494343457,\n",
       "               0.8973252328632836,\n",
       "               0.8975945299140542,\n",
       "               0.897996583917554,\n",
       "               0.8991543989586854,\n",
       "               0.8999296971117822,\n",
       "               0.9000027742784539,\n",
       "               0.9002455378438988,\n",
       "               0.9002005357296178,\n",
       "               0.9006420310925013,\n",
       "               0.9011169603370459,\n",
       "               0.9016397226894145,\n",
       "               0.9016731813535492,\n",
       "               0.9019798737866335,\n",
       "               0.9026875307254799,\n",
       "               0.9030293239075232,\n",
       "               0.9031491217405834,\n",
       "               0.9036933035696295,\n",
       "               0.9039916637626608,\n",
       "               0.9044226620087655,\n",
       "               0.9045661164754919,\n",
       "               0.9049536170826536,\n",
       "               0.9051074131432539,\n",
       "               0.9052652377319621,\n",
       "               0.9056677719368791,\n",
       "               0.9058472124467017,\n",
       "               0.9062073167496211,\n",
       "               0.906504869374832,\n",
       "               0.906810879862407,\n",
       "               0.9071529357843467,\n",
       "               0.9073818666420735,\n",
       "               0.907528372983751,\n",
       "               0.9077868526839131,\n",
       "               0.9080035159537062,\n",
       "               0.9083075835176064,\n",
       "               0.908494386547796,\n",
       "               0.908711604530394,\n",
       "               0.9088428948900681,\n",
       "               0.9089713932335487,\n",
       "               0.9090726782309207,\n",
       "               0.9092176896542062,\n",
       "               0.9094312752827712,\n",
       "               0.9095832688751854,\n",
       "               0.9099147192687363,\n",
       "               0.9100663501480999,\n",
       "               0.9101909107368952,\n",
       "               0.9103282915475589,\n",
       "               0.9104161346530731,\n",
       "               0.910586966772771,\n",
       "               0.9107204578769995,\n",
       "               0.9108856530790278,\n",
       "               0.910967540508748,\n",
       "               0.9110961604397757,\n",
       "               0.9113141475106022,\n",
       "               0.9114302275919893,\n",
       "               0.9116389772710249,\n",
       "               0.9118471427114446,\n",
       "               0.9119342945428862,\n",
       "               0.912104304542673,\n",
       "               0.9122257703263861,\n",
       "               0.9123205702680938,\n",
       "               0.9124258129655921,\n",
       "               0.9125465476077753,\n",
       "               0.9126599033797177,\n",
       "               0.9128222091163226,\n",
       "               0.912901339601266,\n",
       "               0.9129536810345528,\n",
       "               0.9130254780623184,\n",
       "               0.9130625266188331,\n",
       "               0.9131982643667252,\n",
       "               0.9133870549430964,\n",
       "               0.9134904480669698,\n",
       "               0.9135621477040647,\n",
       "               0.9136945036573983,\n",
       "               0.9137654243096719,\n",
       "               0.9138869618348983,\n",
       "               0.9140019448819118,\n",
       "               0.9141446766572758,\n",
       "               0.9142434371158324,\n",
       "               0.9143794249430094,\n",
       "               0.9144834608652189,\n",
       "               0.9145922364237858,\n",
       "               0.9146543769419875,\n",
       "               0.9147136566363248,\n",
       "               0.9148308831120732,\n",
       "               0.9149809379034167,\n",
       "               0.915054077143392,\n",
       "               0.9151407776433587,\n",
       "               0.9151940799772375,\n",
       "               0.9152755087672292,\n",
       "               0.9154410620326665,\n",
       "               0.9156102428092479,\n",
       "               0.9156613085014635,\n",
       "               0.9157374592336068,\n",
       "               0.9158033280032393,\n",
       "               0.9158330475706831,\n",
       "               0.915991105098246,\n",
       "               0.9160578749145802,\n",
       "               0.9160834489515951,\n",
       "               0.916117371900615,\n",
       "               0.9161366234496048,\n",
       "               0.9162225027256241,\n",
       "               0.9164068699701101,\n",
       "               0.916448991209679,\n",
       "               0.9164995752599081,\n",
       "               0.916551349659425,\n",
       "               0.9165935728104745,\n",
       "               0.91667903645888,\n",
       "               0.9167435904105399,\n",
       "               0.916787888379322,\n",
       "               0.9168457957676096,\n",
       "               0.9169186773213922,\n",
       "               0.9169897382534756,\n",
       "               0.9170225309120571,\n",
       "               0.9173153644026684,\n",
       "               0.9173714478606323,\n",
       "               0.9174293451239443,\n",
       "               0.9174699793565392,\n",
       "               0.9175409523436349,\n",
       "               0.9175718250163838,\n",
       "               0.9176382764318077,\n",
       "               0.9176765259544872,\n",
       "               0.9177250565905618,\n",
       "               0.9177351153468435,\n",
       "               0.9177702541479089,\n",
       "               0.9178153216031258,\n",
       "               0.9178627082750671,\n",
       "               0.9178749436434428,\n",
       "               0.9178813928664145,\n",
       "               0.9179275047810879,\n",
       "               0.9179551592751364,\n",
       "               0.9179935959722494,\n",
       "               0.9180577014150125,\n",
       "               0.9181189748862858,\n",
       "               0.9181527275436393,\n",
       "               0.9184047029688375,\n",
       "               0.9184144963324673,\n",
       "               0.9184699714252108,\n",
       "               0.9185036532077352,\n",
       "               0.9185614764925525,\n",
       "               0.9186395893852387,\n",
       "               0.918674697249204,\n",
       "               0.918763450443041,\n",
       "               0.9187879695208415,\n",
       "               0.9188390696168928,\n",
       "               0.9188796363594102,\n",
       "               0.9190094650274775,\n",
       "               0.9190402789004115,\n",
       "               0.9190730185624463,\n",
       "               0.9190948888025696,\n",
       "               0.9191080290357411,\n",
       "               0.9191351415361556,\n",
       "               0.9191436687098048,\n",
       "               0.9193138576622402,\n",
       "               0.9193285998082682,\n",
       "               0.9193575959347852,\n",
       "               0.9193906742711054,\n",
       "               0.9194001592826732,\n",
       "               0.9194324157098972,\n",
       "               0.919535418872882,\n",
       "               0.9195742594036812,\n",
       "               0.9196450770669751,\n",
       "               0.9197350141275383,\n",
       "               0.9197860058939632,\n",
       "               0.9198011522367476,\n",
       "               0.9198206697581304,\n",
       "               0.9198457793931407,\n",
       "               0.9198605303758304,\n",
       "               0.9198740724048098,\n",
       "               0.9199181920358203,\n",
       "               0.9199564959136318,\n",
       "               0.9199982879128861,\n",
       "               0.9200418153880063,\n",
       "               0.920081909008977,\n",
       "               0.9200858005600434,\n",
       "               0.9201300457548057,\n",
       "               0.9201659659826328,\n",
       "               0.9202110780720684,\n",
       "               0.9202339021094894,\n",
       "               0.9202472734837324,\n",
       "               0.9202843133148487,\n",
       "               0.9202964795534748,\n",
       "               0.9203288561452448,\n",
       "               0.9203350754803229,\n",
       "               0.9204374923433898,\n",
       "               0.9204768726249855,\n",
       "               0.9204970688183888,\n",
       "               0.9205290508347644,\n",
       "               0.9205313378026511,\n",
       "               0.9205289943012106,\n",
       "               0.9205585033171805,\n",
       "               0.9205923726957682,\n",
       "               0.9206130080519369,\n",
       "               0.9206220787242047,\n",
       "               0.9206466040854631,\n",
       "               0.9206643222891727,\n",
       "               0.9209541307134727,\n",
       "               0.9210075038577651,\n",
       "               0.9210405822292212,\n",
       "               0.921110260531176,\n",
       "               0.9211595715984968,\n",
       "               0.9212137690294101,\n",
       "               0.9212642490307287,\n",
       "               0.9212686975198695,\n",
       "               0.9212826399860711,\n",
       "               0.9213171299630053,\n",
       "               0.9213406209253671,\n",
       "               0.9213812895735097,\n",
       "               0.9214096545667867,\n",
       "               0.9214699208577212,\n",
       "               0.9214808826751592,\n",
       "               0.9214810516199519,\n",
       "               0.9214828282047415,\n",
       "               0.9214805697671505,\n",
       "               0.9215076636280063,\n",
       "               0.9215611971966521,\n",
       "               0.9215689489459109,\n",
       "               0.9216170104190754,\n",
       "               0.9216297484699449,\n",
       "               0.9216448410666181,\n",
       "               0.9216556341149427,\n",
       "               0.9216972712237369,\n",
       "               0.9217986994933204,\n",
       "               0.9218080477855093,\n",
       "               0.9217917639787209,\n",
       "               0.9218126307687594,\n",
       "               0.9218321244446241,\n",
       "               0.9218276536910777,\n",
       "               0.921857220985681,\n",
       "               0.9218749199115308,\n",
       "               0.9218836233733613,\n",
       "               0.9218961394126198,\n",
       "               0.9219218762456567,\n",
       "               0.9220238999856103,\n",
       "               0.922101941259759,\n",
       "               0.9221071429674442,\n",
       "               0.9221716164229129,\n",
       "               0.9221755044721082,\n",
       "               0.9222006836409301,\n",
       "               0.922205666335262,\n",
       "               0.9222175983115837,\n",
       "               0.9222341847198701,\n",
       "               0.922247164353009,\n",
       "               0.9222522423122937,\n",
       "               0.9222484114115295,\n",
       "               0.9222651874361896,\n",
       "               0.9223089063078994,\n",
       "               0.9223167561681133,\n",
       "               0.922342033319059,\n",
       "               0.9223488663600042,\n",
       "               0.9224012726130454,\n",
       "               0.9224578275645959,\n",
       "               0.9225144170429577,\n",
       "               0.9225250143846976,\n",
       "               0.9225407657547985,\n",
       "               0.922618637123775,\n",
       "               0.9226361578055485,\n",
       "               0.9226415576559029,\n",
       "               0.9226606688196757,\n",
       "               0.9226677655667527,\n",
       "               0.9226708292122078,\n",
       "               0.922692234693112,\n",
       "               0.9227026403805997,\n",
       "               0.9228113726869575,\n",
       "               0.9228166276605642,\n",
       "               0.9229016701650302,\n",
       "               0.922937495666654,\n",
       "               0.9229455936444021,\n",
       "               0.9229549776521644,\n",
       "               0.9229508485126013,\n",
       "               0.9229755660317256,\n",
       "               0.9229935740006422,\n",
       "               0.9230458219901839,\n",
       "               0.9230636157476443,\n",
       "               0.9230518766436169,\n",
       "               0.9230588267922905,\n",
       "               0.9230794639638105,\n",
       "               0.9231250335920516,\n",
       "               0.9231292174263931,\n",
       "               0.9231484700470257,\n",
       "               0.9231595578849815,\n",
       "               0.9231744379918543,\n",
       "               0.9231753846331543,\n",
       "               0.92316277565962,\n",
       "               0.9231799305305337,\n",
       "               0.9232295286341788,\n",
       "               0.9232362878078931,\n",
       "               0.9232532748817848,\n",
       "               0.9232710425801698,\n",
       "               0.9232799619282646,\n",
       "               0.9233404332602032,\n",
       "               0.9233547731185215,\n",
       "               0.9233830416756517,\n",
       "               0.9234023646265083,\n",
       "               0.9234146378303191,\n",
       "               0.9234238025904893,\n",
       "               0.9234343017158665,\n",
       "               0.9234457017708261,\n",
       "               0.9235263133482113,\n",
       "               0.9235554074568522,\n",
       "               0.9235717606569089,\n",
       "               0.9236094116758246,\n",
       "               0.9236066896443531,\n",
       "               0.923643557391876,\n",
       "               0.9236454294758575,\n",
       "               0.923654882478682,\n",
       "               0.9236706826993014,\n",
       "               0.9236710979814129,\n",
       "               0.9236783388088252,\n",
       "               0.9236820819695609,\n",
       "               0.9237329528335875,\n",
       "               0.9237601492910731,\n",
       "               0.9237786006039191,\n",
       "               0.923784212944074,\n",
       "               0.923790435476513,\n",
       "               0.9238001572216051,\n",
       "               0.9237687046202355,\n",
       "               0.9237712375975065,\n",
       "               0.923779963253471,\n",
       "               0.9237968311583322,\n",
       "               0.9238045356733208,\n",
       "               0.9238141375232419,\n",
       "               0.9238375062246201,\n",
       "               0.9238500474914059,\n",
       "               0.923867667689568,\n",
       "               0.9240259964130507,\n",
       "               0.9240845885167221,\n",
       "               0.924105394129421,\n",
       "               0.924124179010145,\n",
       "               0.924125303110821,\n",
       "               0.9241328880702849,\n",
       "               0.9241381855699604,\n",
       "               0.9241692674180296,\n",
       "               0.9241929134816664,\n",
       "               0.9241988205528928,\n",
       "               0.9241929869038437,\n",
       "               0.9242658927013503,\n",
       "               0.9242668590421402,\n",
       "               0.9242756345558506,\n",
       "               0.9242670320978252,\n",
       "               0.9243850906017895,\n",
       "               0.9244021549979357,\n",
       "               0.9244104196249353,\n",
       "               0.9244553790491805,\n",
       "               0.9244408481222072,\n",
       "               0.9245277404989527,\n",
       "               0.9245359559943472,\n",
       "               0.9245441952298524,\n",
       "               0.9245517527248075,\n",
       "               0.924534897029648,\n",
       "               0.92453202946556,\n",
       "               0.9245576462980184,\n",
       "               0.924573495673667,\n",
       "               0.9246428780850678,\n",
       "               0.9247311342005763,\n",
       "               0.9247430169515972,\n",
       "               0.9247587446752833,\n",
       "               0.9248853819674339,\n",
       "               0.92495748902207,\n",
       "               0.9249761033886008,\n",
       "               0.925057751590152,\n",
       "               0.9250801857369563,\n",
       "               0.9251283044463915,\n",
       "               0.9252345299750968,\n",
       "               0.9252646409264301,\n",
       "               0.9253256404553324,\n",
       "               0.9253597369109472,\n",
       "               0.9254275148679997,\n",
       "               0.9254322052790563,\n",
       "               0.9254792267198791,\n",
       "               0.9255080496853036,\n",
       "               0.9255101896331569,\n",
       "               0.9255121196151338,\n",
       "               0.9255096642529158,\n",
       "               0.9255275765820977,\n",
       "               0.9255413600293793,\n",
       "               0.9255475192763285,\n",
       "               0.925555250775636,\n",
       "               0.9256111266920959,\n",
       "               0.9256743617734505,\n",
       "               0.9256746529206672,\n",
       "               0.9256864180369222,\n",
       "               0.9256744099329643,\n",
       "               0.9256973371760363,\n",
       "               0.9257519673164335,\n",
       "               0.9257320629495395,\n",
       "               0.9257790881733202,\n",
       "               0.9257869888516593,\n",
       "               0.9258678342814309,\n",
       "               0.9258846481473825,\n",
       "               0.9258794720068709,\n",
       "               0.9260067023567314,\n",
       "               0.9261369895825432,\n",
       "               0.9261789956292864,\n",
       "               0.9261873112852262,\n",
       "               0.926190496149302,\n",
       "               0.9261868711035218,\n",
       "               0.9261878667241717,\n",
       "               0.926240116025451,\n",
       "               0.9262221070727309,\n",
       "               0.9262342868620763,\n",
       "               0.9262303515083392,\n",
       "               0.9262332981748971,\n",
       "               0.9262497373347672,\n",
       "               0.9262340360742188,\n",
       "               0.9262588095061638,\n",
       "               0.9263562962146796,\n",
       "               0.926356537796949,\n",
       "               0.9264082782962438,\n",
       "               0.9264054821750145,\n",
       "               0.9264867512609375,\n",
       "               0.9264928978179953,\n",
       "               0.9264858510692074,\n",
       "               0.9264895950263553,\n",
       "               0.9264983600520197,\n",
       "               0.926565242431848,\n",
       "               0.9265809672392599,\n",
       "               0.9266031384880566,\n",
       "               0.9266144160595058,\n",
       "               0.9266283927304398,\n",
       "               0.9266269608750107,\n",
       "               0.9266198875401098,\n",
       "               0.9266091186183899,\n",
       "               0.9266161648167165,\n",
       "               0.926624989661135,\n",
       "               0.9266266199286081,\n",
       "               0.9266097793125766,\n",
       "               0.9266286129618354,\n",
       "               0.9266674741876395,\n",
       "               0.9267150478817592,\n",
       "               0.9267318786070541,\n",
       "               0.9267404825759202,\n",
       "               0.9268451027484574,\n",
       "               0.9268442257580886,\n",
       "               0.9268891241572493,\n",
       "               0.9268881237698382,\n",
       "               0.9269028977899217,\n",
       "               0.9268952152231164,\n",
       "               0.9269113536963914,\n",
       "               0.9269246023880208,\n",
       "               0.9269179907848012,\n",
       "               0.9269019721247136,\n",
       "               0.9269268301051824,\n",
       "               0.926941093390811,\n",
       "               0.9269408279630235,\n",
       "               0.926935139565504,\n",
       "               0.9269466853873191,\n",
       "               0.9269998597330735,\n",
       "               0.9270086302692077,\n",
       "               0.9270250679709408,\n",
       "               0.927023706082665,\n",
       "               0.9270266948536618,\n",
       "               0.9270385329236163,\n",
       "               0.9270441007700958,\n",
       "               0.927068012448911,\n",
       "               0.9270828969828987,\n",
       "               0.9270695794601744,\n",
       "               0.9270633834904247,\n",
       "               0.9271104375255877,\n",
       "               0.9271062792232841,\n",
       "               0.9271101196634267,\n",
       "               0.9271180322938047,\n",
       "               0.9271128309023419,\n",
       "               0.9271221894834737,\n",
       "               0.9271250345137815,\n",
       "               0.9271274417281976,\n",
       "               0.9271232130019743,\n",
       "               0.9271502242702008,\n",
       "               0.9271608689867543,\n",
       "               0.927140744774959,\n",
       "               0.927142959433303,\n",
       "               0.9271474041160622,\n",
       "               0.9271541358955394,\n",
       "               0.9271784719917825,\n",
       "               0.9271887482740006,\n",
       "               0.9271769149239596,\n",
       "               0.9271864412552656,\n",
       "               0.9271930733543873,\n",
       "               0.927186169385909,\n",
       "               0.9271973973924109,\n",
       "               0.9271775620322912,\n",
       "               0.9271913752981821,\n",
       "               0.927189064777576,\n",
       "               0.9272027720503736,\n",
       "               0.9272001964416262,\n",
       "               0.9271901105253463,\n",
       "               0.9271994655928951,\n",
       "               0.9272009959691975,\n",
       "               0.9272464444725133,\n",
       "               0.9272769929000919,\n",
       "               0.9273208731741022,\n",
       "               0.9273279515919869,\n",
       "               0.9273308428259138,\n",
       "               0.9273628741378617,\n",
       "               0.9273618783181087,\n",
       "               0.927372790898534,\n",
       "               0.9273711850270404,\n",
       "               0.9273824696607917],\n",
       "              'test-AUC-std': [0.0031472317155223782,\n",
       "               0.0038821421773643536,\n",
       "               0.004881979440633601,\n",
       "               0.004753842128068811,\n",
       "               0.0035336656603507793,\n",
       "               0.003917179839847354,\n",
       "               0.004267692845269378,\n",
       "               0.004234855672819568,\n",
       "               0.003968250522113511,\n",
       "               0.0036620323210917235,\n",
       "               0.0033366206489766543,\n",
       "               0.0030095778585502056,\n",
       "               0.0029134795234228277,\n",
       "               0.0029477637681237724,\n",
       "               0.0030471767839824015,\n",
       "               0.003050697644923547,\n",
       "               0.0034446084508665056,\n",
       "               0.0033886722542550087,\n",
       "               0.0031280404717108764,\n",
       "               0.0028828421210447745,\n",
       "               0.0028468694541777997,\n",
       "               0.002792857735145034,\n",
       "               0.002850426115867742,\n",
       "               0.0027071724584197374,\n",
       "               0.0028074264226919054,\n",
       "               0.0029104623957914013,\n",
       "               0.0030500850112461305,\n",
       "               0.003197141893626724,\n",
       "               0.0031313673818761313,\n",
       "               0.00331820247545002,\n",
       "               0.0032776157351483578,\n",
       "               0.0034085191713480304,\n",
       "               0.003440134299025377,\n",
       "               0.003510516811773328,\n",
       "               0.003585549216633144,\n",
       "               0.003714049762134931,\n",
       "               0.003785004672905461,\n",
       "               0.0036560435951432757,\n",
       "               0.0038236658631901183,\n",
       "               0.003861662084464979,\n",
       "               0.003821015754062169,\n",
       "               0.0038091746864655704,\n",
       "               0.0038048796238331776,\n",
       "               0.00394038175050696,\n",
       "               0.0038999661198320422,\n",
       "               0.0037823319879793102,\n",
       "               0.003917255928550127,\n",
       "               0.003859188970662637,\n",
       "               0.003879809748592335,\n",
       "               0.0038654814968157023,\n",
       "               0.0038521889618649105,\n",
       "               0.0038286944287500816,\n",
       "               0.003926190917494989,\n",
       "               0.0040384189808533024,\n",
       "               0.0040622387096884245,\n",
       "               0.004068166323732007,\n",
       "               0.004096290434719338,\n",
       "               0.004076815692980168,\n",
       "               0.004142766464639274,\n",
       "               0.004067821132382186,\n",
       "               0.004113775186447669,\n",
       "               0.004119659152228135,\n",
       "               0.004137228432382631,\n",
       "               0.004000532854007101,\n",
       "               0.003977024491407886,\n",
       "               0.003946949927587675,\n",
       "               0.0038203186903172735,\n",
       "               0.0038800063804245674,\n",
       "               0.003843309078059705,\n",
       "               0.0038278642778553852,\n",
       "               0.0038651630353957983,\n",
       "               0.003979244002182912,\n",
       "               0.003991005268709668,\n",
       "               0.0039573248246848915,\n",
       "               0.003989216753884393,\n",
       "               0.004045942734315005,\n",
       "               0.004068218882596804,\n",
       "               0.004095359574283513,\n",
       "               0.004044028938009906,\n",
       "               0.004073958384013131,\n",
       "               0.004037097089289348,\n",
       "               0.0040462103285922,\n",
       "               0.004063288407506618,\n",
       "               0.004094030671745312,\n",
       "               0.004087124068094316,\n",
       "               0.004023204190392,\n",
       "               0.0040715188939027805,\n",
       "               0.004028947284908372,\n",
       "               0.004007608459771525,\n",
       "               0.0040126608118197125,\n",
       "               0.004011190231473465,\n",
       "               0.004025591613749286,\n",
       "               0.004067314233922192,\n",
       "               0.003999144069211703,\n",
       "               0.004005048771941369,\n",
       "               0.003991077823873728,\n",
       "               0.0039716396229912375,\n",
       "               0.003993513531729949,\n",
       "               0.003963730940756281,\n",
       "               0.003931505897082917,\n",
       "               0.003934741039529714,\n",
       "               0.003935364469111987,\n",
       "               0.003942336051052281,\n",
       "               0.0038295865690972024,\n",
       "               0.0038760523273264984,\n",
       "               0.0039427900856778665,\n",
       "               0.003953771502946162,\n",
       "               0.00396568068107161,\n",
       "               0.004004662403914328,\n",
       "               0.0040153620933227,\n",
       "               0.0039916497899727165,\n",
       "               0.003992549774871447,\n",
       "               0.004041639612421298,\n",
       "               0.004018498698817961,\n",
       "               0.004022582670583806,\n",
       "               0.004027065872933049,\n",
       "               0.004319996500396881,\n",
       "               0.004307567281512913,\n",
       "               0.004296435411004467,\n",
       "               0.0042759680716042015,\n",
       "               0.004269799800672672,\n",
       "               0.004272403120108987,\n",
       "               0.004257508301215538,\n",
       "               0.004262080551571712,\n",
       "               0.004279903977327956,\n",
       "               0.004266727751418347,\n",
       "               0.004281481535906949,\n",
       "               0.00428239291815587,\n",
       "               0.004292058367299498,\n",
       "               0.004275343669254401,\n",
       "               0.004263974993468866,\n",
       "               0.0042703109684427976,\n",
       "               0.00428925000755474,\n",
       "               0.004269779058250965,\n",
       "               0.00424944631705991,\n",
       "               0.004236200487957015,\n",
       "               0.004257064853475243,\n",
       "               0.004170384519521222,\n",
       "               0.004155224268948803,\n",
       "               0.004145342821248897,\n",
       "               0.004166190309263438,\n",
       "               0.004176299692385359,\n",
       "               0.004112547713235554,\n",
       "               0.004096934357534205,\n",
       "               0.0040629653312490395,\n",
       "               0.00409388431596306,\n",
       "               0.004085244575716367,\n",
       "               0.004071332864440683,\n",
       "               0.004058042022769487,\n",
       "               0.0040869327093018,\n",
       "               0.004081496641050881,\n",
       "               0.004060149179442908,\n",
       "               0.004069298351047743,\n",
       "               0.004062829072320341,\n",
       "               0.004029778981976783,\n",
       "               0.004249128689135008,\n",
       "               0.004240609063006059,\n",
       "               0.004223714518036135,\n",
       "               0.004209253682511686,\n",
       "               0.0042224219419544455,\n",
       "               0.004234101902407202,\n",
       "               0.004219707467847914,\n",
       "               0.004217366136364262,\n",
       "               0.004201236910627373,\n",
       "               0.004236698437142138,\n",
       "               0.004215806724116849,\n",
       "               0.004243965891716588,\n",
       "               0.004234969519754565,\n",
       "               0.004246651062822462,\n",
       "               0.004230965240893715,\n",
       "               0.004249945684729437,\n",
       "               0.004273359353337412,\n",
       "               0.004263112996875443,\n",
       "               0.004314555188969982,\n",
       "               0.004269443411631485,\n",
       "               0.004280688083455162,\n",
       "               0.004285152959798533,\n",
       "               0.0043120345713033486,\n",
       "               0.00430490420085912,\n",
       "               0.004310654107912825,\n",
       "               0.0043198959018499955,\n",
       "               0.004333201692597949,\n",
       "               0.004318191687119178,\n",
       "               0.0043245878997447895,\n",
       "               0.004326485778920273,\n",
       "               0.004313093445203556,\n",
       "               0.004407563853215362,\n",
       "               0.004416003569534102,\n",
       "               0.004387806981941362,\n",
       "               0.0043690535705087335,\n",
       "               0.004368830946444184,\n",
       "               0.00437537221935311,\n",
       "               0.004379645719619476,\n",
       "               0.004379305805211991,\n",
       "               0.004376690242073943,\n",
       "               0.004395199942719914,\n",
       "               0.004394513135496004,\n",
       "               0.004389832425457536,\n",
       "               0.004512405923193984,\n",
       "               0.004512887084296618,\n",
       "               0.004496372766044521,\n",
       "               0.00443710637788202,\n",
       "               0.004435974650518086,\n",
       "               0.0044184069387774,\n",
       "               0.004412088770804873,\n",
       "               0.004401825139209831,\n",
       "               0.0044146141713254285,\n",
       "               0.004407662525032037,\n",
       "               0.0044093731033903434,\n",
       "               0.004430586546643416,\n",
       "               0.004421559170381743,\n",
       "               0.00447255337155678,\n",
       "               0.004467053696099189,\n",
       "               0.004462357947483953,\n",
       "               0.0044719413605362225,\n",
       "               0.004481147165691508,\n",
       "               0.004437785460613076,\n",
       "               0.0044203584102448,\n",
       "               0.004413531019142825,\n",
       "               0.004450296259338408,\n",
       "               0.004459648362758908,\n",
       "               0.004440521368873835,\n",
       "               0.004443110801689135,\n",
       "               0.004448505546356639,\n",
       "               0.004333317846469837,\n",
       "               0.004350693585297846,\n",
       "               0.004352254561018878,\n",
       "               0.004347140577641361,\n",
       "               0.004341908727551922,\n",
       "               0.004346718333178378,\n",
       "               0.004407394045764125,\n",
       "               0.004423057789927978,\n",
       "               0.004446504513660706,\n",
       "               0.004438228027727231,\n",
       "               0.004421952708339161,\n",
       "               0.0043929207400146076,\n",
       "               0.004478621874119027,\n",
       "               0.004487803872388725,\n",
       "               0.004548429503466542,\n",
       "               0.0045462435930648335,\n",
       "               0.004537165743276363,\n",
       "               0.004531101629600511,\n",
       "               0.004514280340773598,\n",
       "               0.004498496361776275,\n",
       "               0.004493737192995188,\n",
       "               0.0044788646511211925,\n",
       "               0.0044634280500579545,\n",
       "               0.004479191945346956,\n",
       "               0.0044145125185595805,\n",
       "               0.004408870396237732,\n",
       "               0.004406629207665355,\n",
       "               0.004421757716056178,\n",
       "               0.004443504199396103,\n",
       "               0.0043849120939138,\n",
       "               0.004411221136960902,\n",
       "               0.0044099734806861066,\n",
       "               0.004418967934981358,\n",
       "               0.004361356832736973,\n",
       "               0.004341284450454816,\n",
       "               0.004361746427013654,\n",
       "               0.004391887770702273,\n",
       "               0.0043859322277667945,\n",
       "               0.004385900734724348,\n",
       "               0.0044049647343592764,\n",
       "               0.004418982886612323,\n",
       "               0.004308758225864727,\n",
       "               0.004328309787003763,\n",
       "               0.0042039468759938105,\n",
       "               0.004183014973114417,\n",
       "               0.004199383530934814,\n",
       "               0.004208316294195326,\n",
       "               0.004229941303114945,\n",
       "               0.004211575675269849,\n",
       "               0.004193500169635862,\n",
       "               0.004155479782251539,\n",
       "               0.004162287256622647,\n",
       "               0.004167148107382677,\n",
       "               0.004157828750402989,\n",
       "               0.004169313358925848,\n",
       "               0.004136494515519665,\n",
       "               0.004153955843783547,\n",
       "               0.004166522836475363,\n",
       "               0.004184682480635318,\n",
       "               0.004210877964920047,\n",
       "               0.004202430104416757,\n",
       "               0.004230276162935881,\n",
       "               0.004269066450743243,\n",
       "               0.004188530613065697,\n",
       "               0.004200055595213368,\n",
       "               0.004181423119176192,\n",
       "               0.00417763210046966,\n",
       "               0.004172778132606173,\n",
       "               0.004172476428695371,\n",
       "               0.0041675767488706834,\n",
       "               0.0041734757287650165,\n",
       "               0.004167957365142654,\n",
       "               0.004158769267960299,\n",
       "               0.004166121026666013,\n",
       "               0.004159009291119649,\n",
       "               0.004160785566144615,\n",
       "               0.004129059095949637,\n",
       "               0.004133258687179614,\n",
       "               0.004120588670595648,\n",
       "               0.004133789281801954,\n",
       "               0.004139231743471316,\n",
       "               0.004125096549307553,\n",
       "               0.00412748532060249,\n",
       "               0.004110578074979657,\n",
       "               0.004119751031253677,\n",
       "               0.004129972115582437,\n",
       "               0.004115006215375107,\n",
       "               0.0041140451214201346,\n",
       "               0.0040906610311076995,\n",
       "               0.004061000168213965,\n",
       "               0.004073400895559833,\n",
       "               0.00406057925085473,\n",
       "               0.004049312759345689,\n",
       "               0.0040428982295105925,\n",
       "               0.004035624954790585,\n",
       "               0.004056437633513473,\n",
       "               0.004053941064120534,\n",
       "               0.004048528907226686,\n",
       "               0.004048029245038255,\n",
       "               0.0040552752073472415,\n",
       "               0.004108048941092813,\n",
       "               0.004108207847272818,\n",
       "               0.004096562379853617,\n",
       "               0.004054471486641938,\n",
       "               0.003980672736807747,\n",
       "               0.003975434715848953,\n",
       "               0.003948494666817134,\n",
       "               0.0039822606919071865,\n",
       "               0.003990178399319198,\n",
       "               0.003987679298480904,\n",
       "               0.003952109191603383,\n",
       "               0.003936864829502928,\n",
       "               0.003942582019333755,\n",
       "               0.003938904446241679,\n",
       "               0.0038489042488594875,\n",
       "               0.0038205444380260832,\n",
       "               0.0038243333057035494,\n",
       "               0.003832173916167469,\n",
       "               0.003831294915130606,\n",
       "               0.0038382993106086632,\n",
       "               0.0038402584785325847,\n",
       "               0.0038108485784176687,\n",
       "               0.0038312671557682067,\n",
       "               0.003810502669230157,\n",
       "               0.00380856617438151,\n",
       "               0.0038077517713600447,\n",
       "               0.0037986919111291507,\n",
       "               0.003804649939470873,\n",
       "               0.0038094219181199563,\n",
       "               0.003797581120048252,\n",
       "               0.0038072851380092283,\n",
       "               0.0037271944131695768,\n",
       "               0.0037187091917064642,\n",
       "               0.0037031763930586176,\n",
       "               0.003709615698293985,\n",
       "               0.0036151812136960516,\n",
       "               0.0035510340320892304,\n",
       "               0.0035274487224177184,\n",
       "               0.003539371230352285,\n",
       "               0.0035391068656367274,\n",
       "               0.0034894467280200377,\n",
       "               0.0034077975884077177,\n",
       "               0.003390826896857955,\n",
       "               0.0034713347966490696,\n",
       "               0.0034370063741203096,\n",
       "               0.003385205833091673,\n",
       "               0.0033827228085726033,\n",
       "               0.0034524346950375,\n",
       "               0.0034322332883229383,\n",
       "               0.0034373975115881638,\n",
       "               0.0034272001773257886,\n",
       "               0.003424117802212595,\n",
       "               0.0034154064176518217,\n",
       "               0.0034244517336474963,\n",
       "               0.00340945749307009,\n",
       "               0.003417340111614184,\n",
       "               0.0035265327625090283,\n",
       "               0.003488469852485018,\n",
       "               0.0034835244408155277,\n",
       "               0.003488798824942928,\n",
       "               0.0034823086988169803,\n",
       "               0.0035174180506828755,\n",
       "               0.0034746156749717086,\n",
       "               0.0034901528238100643,\n",
       "               0.003461732049277848,\n",
       "               0.00347133941181617,\n",
       "               0.003470330053443011,\n",
       "               0.0034444694041626442,\n",
       "               0.003445240391338261,\n",
       "               0.003520648750046261,\n",
       "               0.0034372753644008524,\n",
       "               0.003386797666673046,\n",
       "               0.003401615186656026,\n",
       "               0.0034046124501251425,\n",
       "               0.0033846415030805484,\n",
       "               0.003381535560606354,\n",
       "               0.003462566806966873,\n",
       "               0.003472934559319196,\n",
       "               0.003486877840348252,\n",
       "               0.0035012950693526735,\n",
       "               0.0035319958082808195,\n",
       "               0.00350390956982995,\n",
       "               0.0035075972335591394,\n",
       "               0.003534821131657645,\n",
       "               0.0035227496912455794,\n",
       "               0.003511950016110258,\n",
       "               0.0034548997635366393,\n",
       "               0.0034498164050371745,\n",
       "               0.003386042292647796,\n",
       "               0.0033716563379382444,\n",
       "               0.0033813655516983865,\n",
       "               0.0033841258812057923,\n",
       "               0.003397499431489798,\n",
       "               0.003368322390063712,\n",
       "               0.0033560455265726594,\n",
       "               0.0033780482389316143,\n",
       "               0.003377454920120986,\n",
       "               0.00338321734870651,\n",
       "               0.00339272634059179,\n",
       "               0.003393295823853864,\n",
       "               0.0033891221236999583,\n",
       "               0.003377955473083757,\n",
       "               0.003383328640618032,\n",
       "               0.0033942171474230696,\n",
       "               0.0034124121349507707,\n",
       "               0.0033858493554129307,\n",
       "               0.0033535976840270306,\n",
       "               0.0033740999647902626,\n",
       "               0.0033670776182646595,\n",
       "               0.0033631886574677933,\n",
       "               0.003266721677321903,\n",
       "               0.0032574364542983796,\n",
       "               0.0032182495293173762,\n",
       "               0.0031951863767349068,\n",
       "               0.003183600675225569,\n",
       "               0.003172448981524826,\n",
       "               0.0031661704648686313,\n",
       "               0.0031744415415750783,\n",
       "               0.0031694865960449226,\n",
       "               0.0031668578095774063,\n",
       "               0.0031276536194862203,\n",
       "               0.0031055890818420845,\n",
       "               0.0031138851061739345,\n",
       "               0.003110642886529719,\n",
       "               0.0031133469002426087,\n",
       "               0.0030838477689215955,\n",
       "               0.00306108738451588,\n",
       "               0.003094827234806271,\n",
       "               0.0030918288062660236,\n",
       "               0.0030848641490642406,\n",
       "               0.0030888973256873176,\n",
       "               0.0030995005919493774,\n",
       "               0.0030760088019903134,\n",
       "               0.003126249342339917,\n",
       "               0.003136553045331426,\n",
       "               0.003144733319869933,\n",
       "               0.003140422351429178,\n",
       "               0.0031284973712854456,\n",
       "               0.003128086791458075,\n",
       "               0.003133388166201968,\n",
       "               0.003134522720362116,\n",
       "               0.003137769877478718,\n",
       "               0.0031435944130040914,\n",
       "               0.0031486259976408874,\n",
       "               0.0031448171744254023,\n",
       "               0.003181669238037724,\n",
       "               0.0031748822608098142,\n",
       "               0.003181403883531361,\n",
       "               0.003198968001238087,\n",
       "               0.0031802968480073523,\n",
       "               0.0031762356127410943,\n",
       "               0.0032046732580337627,\n",
       "               0.003179160790243922,\n",
       "               0.003199870574292388,\n",
       "               0.0031942465055108424,\n",
       "               0.003176924438118468,\n",
       "               0.003173230004670376,\n",
       "               0.00316164045481048,\n",
       "               0.0031536004236344018,\n",
       "               0.0031928993728474703,\n",
       "               0.0031870460953872335,\n",
       "               0.0031786928799259415,\n",
       "               0.003180839904010278,\n",
       "               0.0031866891360451065,\n",
       "               0.0031689540044037468,\n",
       "               0.0031647616825578977,\n",
       "               0.003131036532355534,\n",
       "               0.003099633714752317,\n",
       "               0.003067924536143375,\n",
       "               0.003096408143306748,\n",
       "               0.0030898371158207256,\n",
       "               0.0030717075480345617,\n",
       "               0.003075014224074139,\n",
       "               0.0030690487307606148,\n",
       "               0.0030589412961837784,\n",
       "               0.0030924428856226103],\n",
       "              'test-Logloss-mean': [0.6607382077940236,\n",
       "               0.6319428886217141,\n",
       "               0.6048138241654566,\n",
       "               0.5811730596190221,\n",
       "               0.5603867417175604,\n",
       "               0.5413416572908594,\n",
       "               0.5204845511887704,\n",
       "               0.5039629786707468,\n",
       "               0.48959034369572013,\n",
       "               0.4761126842302437,\n",
       "               0.4635528265508397,\n",
       "               0.45224170690952165,\n",
       "               0.4411209464340282,\n",
       "               0.43062612993291743,\n",
       "               0.42235788285871195,\n",
       "               0.41407574551837184,\n",
       "               0.40792454254784644,\n",
       "               0.40135208298774955,\n",
       "               0.39588418582483803,\n",
       "               0.39043587630109905,\n",
       "               0.38590792678434754,\n",
       "               0.3810277374091995,\n",
       "               0.3769439524490707,\n",
       "               0.3730644986679568,\n",
       "               0.3690390376738067,\n",
       "               0.3660458532173519,\n",
       "               0.3629555760505323,\n",
       "               0.359772679128678,\n",
       "               0.35654170676515823,\n",
       "               0.35373760584129865,\n",
       "               0.35117645562587296,\n",
       "               0.3488286452164074,\n",
       "               0.34703177123756507,\n",
       "               0.3451935398116208,\n",
       "               0.3433237408248854,\n",
       "               0.3415831840273884,\n",
       "               0.34014393309750085,\n",
       "               0.3388565970275949,\n",
       "               0.3374299553385714,\n",
       "               0.3358090318415246,\n",
       "               0.33430150614656,\n",
       "               0.33304794748812644,\n",
       "               0.3318946613707141,\n",
       "               0.3309072668593213,\n",
       "               0.3298324172804264,\n",
       "               0.3286937702950734,\n",
       "               0.327562681734554,\n",
       "               0.3265733550707084,\n",
       "               0.32546764835520203,\n",
       "               0.3245620109170057,\n",
       "               0.32379759092692595,\n",
       "               0.3230042185610155,\n",
       "               0.3221571525619657,\n",
       "               0.3216168978687188,\n",
       "               0.32101371107522375,\n",
       "               0.320212608427339,\n",
       "               0.319547324006199,\n",
       "               0.318972141041107,\n",
       "               0.31845441050105855,\n",
       "               0.31805723289670373,\n",
       "               0.31748626199844315,\n",
       "               0.31698086616251303,\n",
       "               0.316440333647549,\n",
       "               0.3159982864385584,\n",
       "               0.31541066034918025,\n",
       "               0.3149248779405474,\n",
       "               0.31443817515656924,\n",
       "               0.3140734510227185,\n",
       "               0.3137413934086503,\n",
       "               0.31328047508781837,\n",
       "               0.3128747085122548,\n",
       "               0.31250924675546105,\n",
       "               0.3120402801108153,\n",
       "               0.31163080463212534,\n",
       "               0.31128641972684873,\n",
       "               0.3107897465351988,\n",
       "               0.31046956097338635,\n",
       "               0.31013585227608415,\n",
       "               0.30985315419400283,\n",
       "               0.30951538959639996,\n",
       "               0.30916709662853004,\n",
       "               0.30870901928400213,\n",
       "               0.3083753116924372,\n",
       "               0.30810302080497176,\n",
       "               0.3079178340593151,\n",
       "               0.30765788438423136,\n",
       "               0.3074214415086431,\n",
       "               0.3070633949122425,\n",
       "               0.3068116443481228,\n",
       "               0.30658534438743307,\n",
       "               0.30637610508349994,\n",
       "               0.3061847556698825,\n",
       "               0.30584850193628776,\n",
       "               0.30547299858072136,\n",
       "               0.30528619239105675,\n",
       "               0.305086428940392,\n",
       "               0.3048366914482517,\n",
       "               0.3046708090898022,\n",
       "               0.30433588331272776,\n",
       "               0.30411437405977165,\n",
       "               0.30398062704482737,\n",
       "               0.3038482464846926,\n",
       "               0.30368410869617396,\n",
       "               0.30344623495392403,\n",
       "               0.3031389289135879,\n",
       "               0.3029378941768242,\n",
       "               0.30280597631034345,\n",
       "               0.3025940168196903,\n",
       "               0.30242466018002895,\n",
       "               0.3022190186268405,\n",
       "               0.3020265584033694,\n",
       "               0.30185703414934345,\n",
       "               0.3017120116109056,\n",
       "               0.30151463553105157,\n",
       "               0.3013632688626634,\n",
       "               0.30124326555302,\n",
       "               0.3007716248161288,\n",
       "               0.30063482328508134,\n",
       "               0.30051915542329355,\n",
       "               0.30038312310997645,\n",
       "               0.3002477993188257,\n",
       "               0.30010046969474197,\n",
       "               0.29992946161073,\n",
       "               0.29983059274636464,\n",
       "               0.29969038979938833,\n",
       "               0.29960701969530673,\n",
       "               0.29951545720164496,\n",
       "               0.2993857396227345,\n",
       "               0.2992633232706381,\n",
       "               0.2992210025329786,\n",
       "               0.29915923795148297,\n",
       "               0.2990293380478449,\n",
       "               0.2989340683858884,\n",
       "               0.2988142511400983,\n",
       "               0.2986852119148053,\n",
       "               0.2985575880595322,\n",
       "               0.2984180771633475,\n",
       "               0.298061688445534,\n",
       "               0.297991247390565,\n",
       "               0.29788499025212584,\n",
       "               0.2977918966769418,\n",
       "               0.29763544363607347,\n",
       "               0.2974875826329238,\n",
       "               0.2973932796913257,\n",
       "               0.2972134332433514,\n",
       "               0.29710117741686126,\n",
       "               0.2969485218680052,\n",
       "               0.29684215944776304,\n",
       "               0.2966430893340852,\n",
       "               0.29656651761663916,\n",
       "               0.29648162186615296,\n",
       "               0.2964381753608644,\n",
       "               0.2963568975346363,\n",
       "               0.29628304334540334,\n",
       "               0.29624179780808546,\n",
       "               0.29596819306477035,\n",
       "               0.29591259161449246,\n",
       "               0.2958131045809691,\n",
       "               0.2957364967558738,\n",
       "               0.29567967516867816,\n",
       "               0.29557349799979454,\n",
       "               0.2954041181995359,\n",
       "               0.2953345821374464,\n",
       "               0.29520859325172094,\n",
       "               0.2950005940331845,\n",
       "               0.29491737734922907,\n",
       "               0.2948485169639201,\n",
       "               0.29479700888679583,\n",
       "               0.2947306815904587,\n",
       "               0.29468747713560867,\n",
       "               0.29463831959156644,\n",
       "               0.2945462912511527,\n",
       "               0.2944431387021998,\n",
       "               0.2943569075251427,\n",
       "               0.29426944218548573,\n",
       "               0.2941895873278313,\n",
       "               0.294152828648887,\n",
       "               0.2940766914174033,\n",
       "               0.29398140189562444,\n",
       "               0.2939169812171653,\n",
       "               0.29384236900702526,\n",
       "               0.2937880128429065,\n",
       "               0.2936666470407452,\n",
       "               0.29364241211004577,\n",
       "               0.2935381755766792,\n",
       "               0.2935007540140648,\n",
       "               0.2932885861375605,\n",
       "               0.293225310849089,\n",
       "               0.29315614537890466,\n",
       "               0.293091922301931,\n",
       "               0.29307288400529674,\n",
       "               0.29304542672603096,\n",
       "               0.29298549507149674,\n",
       "               0.29289149825413485,\n",
       "               0.2928505646666845,\n",
       "               0.2928231173959857,\n",
       "               0.2927812667955994,\n",
       "               0.2927423323951502,\n",
       "               0.29231116348334607,\n",
       "               0.2921907900970166,\n",
       "               0.29213022958031104,\n",
       "               0.2920222703857674,\n",
       "               0.2919257866200691,\n",
       "               0.29181230910971556,\n",
       "               0.2916855910975304,\n",
       "               0.2916410931980787,\n",
       "               0.2916141008508177,\n",
       "               0.29152617513366236,\n",
       "               0.2914584598193371,\n",
       "               0.29139677235651584,\n",
       "               0.2913147099888811,\n",
       "               0.2911962681050058,\n",
       "               0.29116875089084254,\n",
       "               0.2911572081525622,\n",
       "               0.2911233813870451,\n",
       "               0.2911081042515451,\n",
       "               0.29104954787497694,\n",
       "               0.2909444285442942,\n",
       "               0.2909257818071998,\n",
       "               0.29081960280313496,\n",
       "               0.29079418016377195,\n",
       "               0.2907486853607599,\n",
       "               0.29071382545168256,\n",
       "               0.2906344202359314,\n",
       "               0.29045699913491513,\n",
       "               0.29042648929564435,\n",
       "               0.290434605439382,\n",
       "               0.29039105514234165,\n",
       "               0.2903516651653521,\n",
       "               0.2903509911576068,\n",
       "               0.29028811426269224,\n",
       "               0.2902464991905953,\n",
       "               0.29022505696842943,\n",
       "               0.29018899425582817,\n",
       "               0.29013835602312943,\n",
       "               0.28991331869966364,\n",
       "               0.28976966786394226,\n",
       "               0.28975202122062077,\n",
       "               0.2896169344758159,\n",
       "               0.28958544330169605,\n",
       "               0.2895473708878943,\n",
       "               0.28952730938592275,\n",
       "               0.2894893731745004,\n",
       "               0.28945838470789376,\n",
       "               0.2894303780595376,\n",
       "               0.28941181785518727,\n",
       "               0.2894141552215556,\n",
       "               0.2893720299073666,\n",
       "               0.2893043944931379,\n",
       "               0.28928653283192995,\n",
       "               0.2892464778479363,\n",
       "               0.28921623195095925,\n",
       "               0.28911541513314654,\n",
       "               0.2890255407138062,\n",
       "               0.288928708429913,\n",
       "               0.28890782465971726,\n",
       "               0.28888796370794995,\n",
       "               0.2887522037150811,\n",
       "               0.28870670742798993,\n",
       "               0.28869366170784794,\n",
       "               0.2886608477357322,\n",
       "               0.28864045003783684,\n",
       "               0.2886156432758178,\n",
       "               0.28856836616214426,\n",
       "               0.2885417715904904,\n",
       "               0.28834720255490204,\n",
       "               0.28832927782886153,\n",
       "               0.2881987177967446,\n",
       "               0.2881338659896314,\n",
       "               0.288098299615554,\n",
       "               0.28808236339639454,\n",
       "               0.28805229865934523,\n",
       "               0.28799865548710685,\n",
       "               0.28795698827308197,\n",
       "               0.28784622117395725,\n",
       "               0.28782085548717484,\n",
       "               0.2878162168376232,\n",
       "               0.28780784359260864,\n",
       "               0.28772995564763404,\n",
       "               0.28766414645711663,\n",
       "               0.28764446086187556,\n",
       "               0.2876119208719543,\n",
       "               0.2875920388080917,\n",
       "               0.2875552880097616,\n",
       "               0.2875306476363705,\n",
       "               0.2875448517547518,\n",
       "               0.2875116410471634,\n",
       "               0.28745245868885255,\n",
       "               0.28743650836600265,\n",
       "               0.2874136551195951,\n",
       "               0.28738262855449287,\n",
       "               0.2873546515845029,\n",
       "               0.28722468026501274,\n",
       "               0.2871874244814881,\n",
       "               0.2871418477934952,\n",
       "               0.28710709569004306,\n",
       "               0.28707753041359346,\n",
       "               0.2870496594587651,\n",
       "               0.2870304405130728,\n",
       "               0.28701122391587025,\n",
       "               0.28688163299261377,\n",
       "               0.2868351097933306,\n",
       "               0.28680406914076184,\n",
       "               0.2867377709898063,\n",
       "               0.28672765839117353,\n",
       "               0.28665058606946153,\n",
       "               0.2866473544450343,\n",
       "               0.28661374108977183,\n",
       "               0.2865934139204773,\n",
       "               0.2865863822549157,\n",
       "               0.286566870233054,\n",
       "               0.28655052843674084,\n",
       "               0.2864505480113084,\n",
       "               0.28640970472363975,\n",
       "               0.2863701148784695,\n",
       "               0.2863644786508368,\n",
       "               0.28631538763330905,\n",
       "               0.28630118860267634,\n",
       "               0.2863350320605893,\n",
       "               0.28633195342760315,\n",
       "               0.2863185016185596,\n",
       "               0.2862746007986894,\n",
       "               0.28625906188689726,\n",
       "               0.2862385768755606,\n",
       "               0.2861929001897711,\n",
       "               0.28617697983248097,\n",
       "               0.28613721902558065,\n",
       "               0.28591366983429284,\n",
       "               0.28582865716562855,\n",
       "               0.28579581765288503,\n",
       "               0.28575841384775075,\n",
       "               0.2857543472455549,\n",
       "               0.2857372249357784,\n",
       "               0.28571587882896415,\n",
       "               0.2856646538146625,\n",
       "               0.2856105609580172,\n",
       "               0.28560206578829644,\n",
       "               0.2856157064879932,\n",
       "               0.28550196232076736,\n",
       "               0.28548048360213674,\n",
       "               0.2854609568898065,\n",
       "               0.28546738294319285,\n",
       "               0.28527328680038017,\n",
       "               0.28523881147764013,\n",
       "               0.2852242293264847,\n",
       "               0.28515239688611,\n",
       "               0.28516508531531787,\n",
       "               0.28501594682607545,\n",
       "               0.2849895925902696,\n",
       "               0.2849671463881501,\n",
       "               0.28494434563904264,\n",
       "               0.2849631084787705,\n",
       "               0.2849550094107384,\n",
       "               0.2849144852461852,\n",
       "               0.28489042363988376,\n",
       "               0.28477609551322,\n",
       "               0.2846295221990464,\n",
       "               0.28460353219869433,\n",
       "               0.28458099317713553,\n",
       "               0.28438149285624087,\n",
       "               0.2842432386777897,\n",
       "               0.28421259583613145,\n",
       "               0.2840723936972869,\n",
       "               0.28402004717202106,\n",
       "               0.28393984148192175,\n",
       "               0.2837605470524965,\n",
       "               0.2836975840288993,\n",
       "               0.283596265178493,\n",
       "               0.2835236737702128,\n",
       "               0.2833933557891702,\n",
       "               0.2833924058455481,\n",
       "               0.283314200849658,\n",
       "               0.28325824825646945,\n",
       "               0.28325230462602313,\n",
       "               0.2832470611170076,\n",
       "               0.28324847931006064,\n",
       "               0.2832242486283298,\n",
       "               0.28320053684356594,\n",
       "               0.2831971573721084,\n",
       "               0.28317521445124444,\n",
       "               0.28308518478610273,\n",
       "               0.28296159052084296,\n",
       "               0.28296540356641037,\n",
       "               0.2829421625733401,\n",
       "               0.28295428876691525,\n",
       "               0.28291236179026863,\n",
       "               0.2828291440719157,\n",
       "               0.282846602031588,\n",
       "               0.2827601211633309,\n",
       "               0.28274225443691337,\n",
       "               0.2825737131814339,\n",
       "               0.28252847126614017,\n",
       "               0.2825408620117878,\n",
       "               0.2823308883823004,\n",
       "               0.282123496372997,\n",
       "               0.28204625901107283,\n",
       "               0.2820408272624999,\n",
       "               0.2820369225209256,\n",
       "               0.282037377444677,\n",
       "               0.2820252045023622,\n",
       "               0.2819349539589969,\n",
       "               0.28195950877234743,\n",
       "               0.2819342241845062,\n",
       "               0.2819349466248447,\n",
       "               0.28192974682781063,\n",
       "               0.28189872696020274,\n",
       "               0.281914830809251,\n",
       "               0.28186263317736776,\n",
       "               0.28169187643064425,\n",
       "               0.2816884863492591,\n",
       "               0.2815834292226029,\n",
       "               0.2815897477134193,\n",
       "               0.28143282889356014,\n",
       "               0.28141139409870025,\n",
       "               0.2814174091332398,\n",
       "               0.2814131048014337,\n",
       "               0.28140255547583964,\n",
       "               0.28126843110592753,\n",
       "               0.2812326922716612,\n",
       "               0.28119357728859073,\n",
       "               0.28117088238893384,\n",
       "               0.2811554798414367,\n",
       "               0.28113945197664436,\n",
       "               0.28114901104847845,\n",
       "               0.2811614524821047,\n",
       "               0.28115303247344864,\n",
       "               0.2811189391452556,\n",
       "               0.28111813466913765,\n",
       "               0.2811281397495085,\n",
       "               0.2810887399227036,\n",
       "               0.28100327910369255,\n",
       "               0.28089176428304535,\n",
       "               0.28087131825327455,\n",
       "               0.28084327006641313,\n",
       "               0.28066392448831273,\n",
       "               0.2806695648714343,\n",
       "               0.2805908418767524,\n",
       "               0.28058333835990296,\n",
       "               0.28054508776372405,\n",
       "               0.2805319315181347,\n",
       "               0.2805116506466376,\n",
       "               0.28049423912499694,\n",
       "               0.2804925846863184,\n",
       "               0.28051430456674614,\n",
       "               0.28045110691810765,\n",
       "               0.2804026343457173,\n",
       "               0.2804004627500368,\n",
       "               0.2803992412763238,\n",
       "               0.2803825239299326,\n",
       "               0.28027072663371205,\n",
       "               0.2802597392311595,\n",
       "               0.2802240923209501,\n",
       "               0.2802232520209667,\n",
       "               0.2801960515594897,\n",
       "               0.2801784104513614,\n",
       "               0.2801582316280257,\n",
       "               0.2801205497359521,\n",
       "               0.2800860441154433,\n",
       "               0.28010596424494466,\n",
       "               0.2801114147078801,\n",
       "               0.2800489091048546,\n",
       "               0.28004826628920837,\n",
       "               0.28004380684521873,\n",
       "               0.28002474555070694,\n",
       "               0.28003329839909724,\n",
       "               0.2800120548079906,\n",
       "               0.2800076888819698,\n",
       "               0.28000419194107834,\n",
       "               0.28000705555947325,\n",
       "               0.27995667800230756,\n",
       "               0.2799392595444194,\n",
       "               0.27997675632182856,\n",
       "               0.27996865236277363,\n",
       "               0.2799599023034139,\n",
       "               0.279949732504148,\n",
       "               0.2798969005842053,\n",
       "               0.2798748114596961,\n",
       "               0.27989165889275663,\n",
       "               0.2798660846283405,\n",
       "               0.279854680426675,\n",
       "               0.27987055537063416,\n",
       "               0.2798522787488415,\n",
       "               0.2798793113674989,\n",
       "               0.2798581637127758,\n",
       "               0.27985628173131327,\n",
       "               0.2798279772426362,\n",
       "               0.2798218825016429,\n",
       "               0.27984188892049344,\n",
       "               0.2798193253547614,\n",
       "               0.27981740657124526,\n",
       "               0.2797398219525454,\n",
       "               0.2796763533906343,\n",
       "               0.27960963236634134,\n",
       "               0.2795910332843619,\n",
       "               0.27958657553012584,\n",
       "               0.2795288707207326,\n",
       "               0.27953974540597043,\n",
       "               0.2795180406046377,\n",
       "               0.2795223958962166,\n",
       "               0.27949558476700714],\n",
       "              'test-Logloss-std': [0.0011057415630465544,\n",
       "               0.002072552731495657,\n",
       "               0.0008941486665658791,\n",
       "               0.0008606013970549489,\n",
       "               0.001028538684966062,\n",
       "               0.0015888959891171318,\n",
       "               0.0022742419709305866,\n",
       "               0.0032500524746690482,\n",
       "               0.0036252353176504048,\n",
       "               0.0048728508635502545,\n",
       "               0.005152305428423988,\n",
       "               0.005159431604519011,\n",
       "               0.004233492237648402,\n",
       "               0.003493195142768006,\n",
       "               0.003091123777991221,\n",
       "               0.0025995693634184953,\n",
       "               0.0033277328703255876,\n",
       "               0.0028569225977638077,\n",
       "               0.002332906112745103,\n",
       "               0.0024789127432797054,\n",
       "               0.002464807373112009,\n",
       "               0.0021867039946193664,\n",
       "               0.002208042426364178,\n",
       "               0.0017034734859723,\n",
       "               0.0009663783079071941,\n",
       "               0.0011319881996919553,\n",
       "               0.000655545915627696,\n",
       "               0.000785755295968823,\n",
       "               0.0007628749201294312,\n",
       "               0.0008959263519425149,\n",
       "               0.0009179796477192728,\n",
       "               0.0012303485401303684,\n",
       "               0.0008371232208946261,\n",
       "               0.0011129722552674858,\n",
       "               0.0012758045894720345,\n",
       "               0.0015866983879638452,\n",
       "               0.0016070463097834257,\n",
       "               0.0017868447477524592,\n",
       "               0.001586343761017525,\n",
       "               0.0016085718288381585,\n",
       "               0.001967911447418435,\n",
       "               0.0020377477112355135,\n",
       "               0.002209145798949513,\n",
       "               0.0023728811282838517,\n",
       "               0.0024987581427866677,\n",
       "               0.0026819212045231565,\n",
       "               0.002959685515130994,\n",
       "               0.0030752259617012005,\n",
       "               0.0029800961855113296,\n",
       "               0.0028578596682967035,\n",
       "               0.003020982956507107,\n",
       "               0.0029760324226334113,\n",
       "               0.0031049555703424286,\n",
       "               0.003098449270603797,\n",
       "               0.003282769768736882,\n",
       "               0.0035195106745458823,\n",
       "               0.003684012547515738,\n",
       "               0.0035793210886104964,\n",
       "               0.003659524658772345,\n",
       "               0.003714154444763312,\n",
       "               0.003629232088599964,\n",
       "               0.0037218056031640095,\n",
       "               0.003821760700340471,\n",
       "               0.003696591054068506,\n",
       "               0.003693037423605857,\n",
       "               0.0037037354778003666,\n",
       "               0.0034238781996161617,\n",
       "               0.00354112243864317,\n",
       "               0.003507369773748958,\n",
       "               0.003650638067366325,\n",
       "               0.00375125954416465,\n",
       "               0.003906666982898011,\n",
       "               0.0038151808298953014,\n",
       "               0.0038024328642493666,\n",
       "               0.003970232767268382,\n",
       "               0.00395790623462544,\n",
       "               0.004062089258770428,\n",
       "               0.00416259288943577,\n",
       "               0.004049633129125743,\n",
       "               0.004067412789116559,\n",
       "               0.0041361704717002845,\n",
       "               0.004127834101828864,\n",
       "               0.004179712221165749,\n",
       "               0.004192027803948758,\n",
       "               0.004186302703387752,\n",
       "               0.004133013419451349,\n",
       "               0.0042120721928564685,\n",
       "               0.004215003325698864,\n",
       "               0.0042543011398066145,\n",
       "               0.004298060920639544,\n",
       "               0.00428952672714125,\n",
       "               0.004275067730773919,\n",
       "               0.004307202828591526,\n",
       "               0.004159739640357244,\n",
       "               0.0041887997526280085,\n",
       "               0.004171542568587996,\n",
       "               0.004146380453546668,\n",
       "               0.0042373513768388495,\n",
       "               0.004255941205337863,\n",
       "               0.004156182686232916,\n",
       "               0.004230651163212582,\n",
       "               0.00421408489497273,\n",
       "               0.004217955032652496,\n",
       "               0.0040915983203613625,\n",
       "               0.004179018639008598,\n",
       "               0.004320436945239434,\n",
       "               0.0043163859748829485,\n",
       "               0.004428824734887089,\n",
       "               0.004478546151819175,\n",
       "               0.004493526205568695,\n",
       "               0.004543029567117733,\n",
       "               0.004587564270314318,\n",
       "               0.0046557015649943585,\n",
       "               0.004549846231082284,\n",
       "               0.004608852414654768,\n",
       "               0.0046228905188648375,\n",
       "               0.004967491055752123,\n",
       "               0.0049708581576575935,\n",
       "               0.004948673551290202,\n",
       "               0.004904064493116172,\n",
       "               0.004877194293004748,\n",
       "               0.004899847837823794,\n",
       "               0.004818195081347443,\n",
       "               0.004827845415004515,\n",
       "               0.004918556278330086,\n",
       "               0.004931517254204071,\n",
       "               0.00494370710585903,\n",
       "               0.004950237114051538,\n",
       "               0.004978745795937542,\n",
       "               0.004973527681485235,\n",
       "               0.004968725023434444,\n",
       "               0.004987637708943402,\n",
       "               0.005027233539181988,\n",
       "               0.005004079984683331,\n",
       "               0.004984627574199051,\n",
       "               0.004951414217069349,\n",
       "               0.00506430617504862,\n",
       "               0.004967465332306139,\n",
       "               0.004963978716755303,\n",
       "               0.004955816132199981,\n",
       "               0.004979485980461484,\n",
       "               0.005011138057960803,\n",
       "               0.004932456161951396,\n",
       "               0.004896210879802147,\n",
       "               0.004901577309552957,\n",
       "               0.004995189667508675,\n",
       "               0.00498540761693007,\n",
       "               0.0049760180386159945,\n",
       "               0.00497315604608523,\n",
       "               0.005023908727637304,\n",
       "               0.0050236762582130555,\n",
       "               0.004990112385206991,\n",
       "               0.005003723367188421,\n",
       "               0.005017898720457813,\n",
       "               0.004973780245363729,\n",
       "               0.005305283960604246,\n",
       "               0.005305670960991512,\n",
       "               0.005274127427769057,\n",
       "               0.005261306788410594,\n",
       "               0.0052837294540694696,\n",
       "               0.005315172984250459,\n",
       "               0.005285419626277098,\n",
       "               0.0052846291346115015,\n",
       "               0.005269182091946805,\n",
       "               0.005348067908010014,\n",
       "               0.005327362704670445,\n",
       "               0.005388208789135329,\n",
       "               0.005382668360470799,\n",
       "               0.005397020186559312,\n",
       "               0.005395376406927574,\n",
       "               0.005414607914830882,\n",
       "               0.005446978718765458,\n",
       "               0.0054758865426112625,\n",
       "               0.0055439741334541316,\n",
       "               0.005473315503459538,\n",
       "               0.005512038255732455,\n",
       "               0.005545316522649281,\n",
       "               0.005591223220604983,\n",
       "               0.005607625424100334,\n",
       "               0.00561381537105601,\n",
       "               0.005646297377634404,\n",
       "               0.005676570724212613,\n",
       "               0.005625118234386106,\n",
       "               0.005638999796241214,\n",
       "               0.005660161838759239,\n",
       "               0.005653293958866084,\n",
       "               0.005810693097240804,\n",
       "               0.005823781446105008,\n",
       "               0.005814970874091179,\n",
       "               0.0057942919296187344,\n",
       "               0.005796664396666151,\n",
       "               0.00580318279069085,\n",
       "               0.005810292698090874,\n",
       "               0.00580898293579141,\n",
       "               0.00581260958777054,\n",
       "               0.005843167273381246,\n",
       "               0.005834067351361354,\n",
       "               0.005834136871893213,\n",
       "               0.006041366502777927,\n",
       "               0.006082156577294415,\n",
       "               0.006067713027217771,\n",
       "               0.005976271714038974,\n",
       "               0.0059874734625922285,\n",
       "               0.005984784439219421,\n",
       "               0.005993269956450989,\n",
       "               0.005981186940565444,\n",
       "               0.006004793097474185,\n",
       "               0.006002111627313163,\n",
       "               0.006015417891969973,\n",
       "               0.006047733920584069,\n",
       "               0.00601499049096966,\n",
       "               0.006105471932750348,\n",
       "               0.00609444801797375,\n",
       "               0.006100519962111123,\n",
       "               0.006124315749591015,\n",
       "               0.006145100725581121,\n",
       "               0.0060950895598991485,\n",
       "               0.006061557280699888,\n",
       "               0.0060746574306641925,\n",
       "               0.006166185157910256,\n",
       "               0.006180242146642583,\n",
       "               0.006161802883512121,\n",
       "               0.006180018376496447,\n",
       "               0.0062027918100951525,\n",
       "               0.006001395209595574,\n",
       "               0.0060270279024489965,\n",
       "               0.006023524750569937,\n",
       "               0.006028608165177813,\n",
       "               0.006017898224318491,\n",
       "               0.0060333032042829545,\n",
       "               0.006117760285301619,\n",
       "               0.006157264078595879,\n",
       "               0.0061965682269196735,\n",
       "               0.00620191397348932,\n",
       "               0.006185405172331229,\n",
       "               0.00620172030567703,\n",
       "               0.006335952585885739,\n",
       "               0.006346887492845848,\n",
       "               0.006479340935587948,\n",
       "               0.006486828475051433,\n",
       "               0.006483782755735235,\n",
       "               0.006482632523059563,\n",
       "               0.006473561461298689,\n",
       "               0.00645782330760546,\n",
       "               0.0064637355100930945,\n",
       "               0.00646008104012441,\n",
       "               0.006442643814536635,\n",
       "               0.006477683378849305,\n",
       "               0.00639781277991533,\n",
       "               0.0063939205860929,\n",
       "               0.006398960677291493,\n",
       "               0.006427224041688448,\n",
       "               0.006495098660763568,\n",
       "               0.006421245717595223,\n",
       "               0.006464345758783219,\n",
       "               0.006459442329515139,\n",
       "               0.0064828878509753515,\n",
       "               0.006410231165425034,\n",
       "               0.0063874839010898445,\n",
       "               0.006408344948252347,\n",
       "               0.006451803127146346,\n",
       "               0.006448269305109706,\n",
       "               0.006463405905700092,\n",
       "               0.006489364984074812,\n",
       "               0.006512952973401065,\n",
       "               0.006305198830648592,\n",
       "               0.006343072353211106,\n",
       "               0.006176345776242227,\n",
       "               0.006154531105800527,\n",
       "               0.0061801919122839045,\n",
       "               0.006196194324843243,\n",
       "               0.006238793642994381,\n",
       "               0.006219964032047981,\n",
       "               0.006187138178546542,\n",
       "               0.00614063657493253,\n",
       "               0.006147488581178357,\n",
       "               0.006165509755610947,\n",
       "               0.006148566214661679,\n",
       "               0.006186910563976243,\n",
       "               0.006142691476766235,\n",
       "               0.006184320568493914,\n",
       "               0.006199896414342048,\n",
       "               0.00622067170214215,\n",
       "               0.006263769155009618,\n",
       "               0.006268074599333688,\n",
       "               0.006296902649472481,\n",
       "               0.006354291405283271,\n",
       "               0.006239275991675846,\n",
       "               0.00625705232675775,\n",
       "               0.006233279179257616,\n",
       "               0.006224114188201322,\n",
       "               0.006220614678147604,\n",
       "               0.006258762186311518,\n",
       "               0.006249844212180797,\n",
       "               0.006264550568078329,\n",
       "               0.0062623738689018505,\n",
       "               0.006244815263782097,\n",
       "               0.0062688043701576,\n",
       "               0.006261195511385847,\n",
       "               0.006271720198275444,\n",
       "               0.006244482046606561,\n",
       "               0.006263491352377962,\n",
       "               0.006261409694810466,\n",
       "               0.0062871411708728744,\n",
       "               0.006281587325100557,\n",
       "               0.006272554201049289,\n",
       "               0.006281542953789845,\n",
       "               0.00625332308535046,\n",
       "               0.006271691341842753,\n",
       "               0.006292246687297441,\n",
       "               0.006265083959565849,\n",
       "               0.006270024389850031,\n",
       "               0.006214131660661419,\n",
       "               0.006163121066870674,\n",
       "               0.0061961398145636394,\n",
       "               0.006173055755797859,\n",
       "               0.006131728406506097,\n",
       "               0.006123624573268143,\n",
       "               0.006106508061447149,\n",
       "               0.006154058215894113,\n",
       "               0.0061454954645166135,\n",
       "               0.006131803796444977,\n",
       "               0.006125465819137984,\n",
       "               0.006141237850630266,\n",
       "               0.006224726543386674,\n",
       "               0.006223482512652804,\n",
       "               0.006216183855909972,\n",
       "               0.0061379341263900124,\n",
       "               0.006023074462930556,\n",
       "               0.006033138569623679,\n",
       "               0.005985009822332118,\n",
       "               0.006053561713560467,\n",
       "               0.0060664556983840824,\n",
       "               0.006075881913061007,\n",
       "               0.006015614816424094,\n",
       "               0.005997963177630135,\n",
       "               0.0060035300939076134,\n",
       "               0.006001700251222892,\n",
       "               0.005842353743761008,\n",
       "               0.005802857805011943,\n",
       "               0.005807883744450249,\n",
       "               0.005824122127263604,\n",
       "               0.005817419345657241,\n",
       "               0.005831570901966796,\n",
       "               0.0058322151579954995,\n",
       "               0.0058027419643938444,\n",
       "               0.005826177786375871,\n",
       "               0.005795879265499079,\n",
       "               0.005792566846049221,\n",
       "               0.005796259152029246,\n",
       "               0.0057801900958318496,\n",
       "               0.0057936038549778164,\n",
       "               0.005803616620473763,\n",
       "               0.005785083904918135,\n",
       "               0.005789113218113307,\n",
       "               0.005654178516671203,\n",
       "               0.005640305307735333,\n",
       "               0.0056278613575384395,\n",
       "               0.005630509616664549,\n",
       "               0.0055514925104373485,\n",
       "               0.005426394567859505,\n",
       "               0.005393776108133509,\n",
       "               0.005401698380588034,\n",
       "               0.0054092183522306036,\n",
       "               0.005307924903281498,\n",
       "               0.005189320596717335,\n",
       "               0.005165632013230257,\n",
       "               0.005292979594463496,\n",
       "               0.005219740314990129,\n",
       "               0.005155464834760207,\n",
       "               0.005148631805914183,\n",
       "               0.00525307699047679,\n",
       "               0.005233198450227961,\n",
       "               0.005232872595436591,\n",
       "               0.0052270686473233265,\n",
       "               0.005211409420598033,\n",
       "               0.005195238943367993,\n",
       "               0.005210770002823283,\n",
       "               0.005198227532746785,\n",
       "               0.005206485129097913,\n",
       "               0.005386245068604435,\n",
       "               0.005339120292336305,\n",
       "               0.005334693139492056,\n",
       "               0.005332842217048656,\n",
       "               0.005334197770082915,\n",
       "               0.0053966128876566525,\n",
       "               0.005371601844677112,\n",
       "               0.005384092047954742,\n",
       "               0.00534831774683837,\n",
       "               0.0053671640819507645,\n",
       "               0.005393487504893586,\n",
       "               0.005373497922267041,\n",
       "               0.0053705102679329,\n",
       "               0.005510479516914833,\n",
       "               0.005393385574624847,\n",
       "               0.005320782296608987,\n",
       "               0.00533500276489575,\n",
       "               0.0053416979956541575,\n",
       "               0.005311937735729206,\n",
       "               0.005316642562504725,\n",
       "               0.005453747487376614,\n",
       "               0.005480743790820158,\n",
       "               0.005502649640105441,\n",
       "               0.005532935076889534,\n",
       "               0.005578881339572948,\n",
       "               0.005534569912654046,\n",
       "               0.005541899861247973,\n",
       "               0.005598116647843121,\n",
       "               0.005614568163841484,\n",
       "               0.005593899032523315,\n",
       "               0.0054568417333302165,\n",
       "               0.005449911514421114,\n",
       "               0.0053474008251928485,\n",
       "               0.0053264900341954925,\n",
       "               0.005339110539324196,\n",
       "               0.005341081724196839,\n",
       "               0.005361585295207212,\n",
       "               0.005326009957326184,\n",
       "               0.0052943242780669544,\n",
       "               0.005334423796573177,\n",
       "               0.005343075674876885,\n",
       "               0.00535755261644504,\n",
       "               0.005389348485700558,\n",
       "               0.005390838843625602,\n",
       "               0.005387477965689801,\n",
       "               0.005379517710611893,\n",
       "               0.005390846211391474,\n",
       "               0.005408267293875146,\n",
       "               0.005430199964266426,\n",
       "               0.005362328873799887,\n",
       "               0.00532182226714674,\n",
       "               0.005338518532452234,\n",
       "               0.005335382279466396,\n",
       "               0.005322160796873982,\n",
       "               0.005149907791180079,\n",
       "               0.005149085737776045,\n",
       "               0.0050836243486447035,\n",
       "               0.005039926001154321,\n",
       "               0.0050323757852341385,\n",
       "               0.005017533251964571,\n",
       "               0.005009082645274003,\n",
       "               0.0050226638390990196,\n",
       "               0.005012269258376503,\n",
       "               0.005010697949252445,\n",
       "               0.004939840919291857,\n",
       "               0.004907415213817679,\n",
       "               0.004919026432603602,\n",
       "               0.004910641432130546,\n",
       "               0.004914949793658573,\n",
       "               0.00487838135123371,\n",
       "               0.004844067888475788,\n",
       "               0.004894985481181743,\n",
       "               0.004892654610569672,\n",
       "               0.004858433798628891,\n",
       "               0.004872335913231794,\n",
       "               0.004874727254908096,\n",
       "               0.0048528702490965485,\n",
       "               0.004959870356766916,\n",
       "               0.0049770761810649725,\n",
       "               0.004987940927461236,\n",
       "               0.004986281960814069,\n",
       "               0.004966499056722196,\n",
       "               0.004962466214394189,\n",
       "               0.004979976644218125,\n",
       "               0.004978645702714051,\n",
       "               0.004990803781581351,\n",
       "               0.0050116182762780384,\n",
       "               0.005024341380875755,\n",
       "               0.005013187070746191,\n",
       "               0.00507401639824704,\n",
       "               0.005072577735819652,\n",
       "               0.0050923954522632976,\n",
       "               0.005123676154435611,\n",
       "               0.005098517669793154,\n",
       "               0.005088747403235542,\n",
       "               0.005150202112345547,\n",
       "               0.005112130711168902,\n",
       "               0.005144215518451874,\n",
       "               0.005139553526052645,\n",
       "               0.0051194451396579235,\n",
       "               0.005098396569494909,\n",
       "               0.0050839687811989,\n",
       "               0.005076610468771172,\n",
       "               0.005139445786162942,\n",
       "               0.00514728877551018,\n",
       "               0.005144184527199378,\n",
       "               0.005136447773413379,\n",
       "               0.00514835207573116,\n",
       "               0.0051206934922747105,\n",
       "               0.005122041712658397,\n",
       "               0.005026625721569724,\n",
       "               0.004953012628991883,\n",
       "               0.004889204715176158,\n",
       "               0.00494359735240361,\n",
       "               0.004938824137159402,\n",
       "               0.0049181448709840515,\n",
       "               0.004935558492574631,\n",
       "               0.004924678310455056,\n",
       "               0.004913021332909777,\n",
       "               0.004972290450518586],\n",
       "              'train-Logloss-mean': [0.6606151002106989,\n",
       "               0.6317034503367501,\n",
       "               0.6044560214628323,\n",
       "               0.5806892356599985,\n",
       "               0.5598654594528583,\n",
       "               0.5407294661926868,\n",
       "               0.5199804484342007,\n",
       "               0.5034032566558354,\n",
       "               0.48892910710685683,\n",
       "               0.4753234762449577,\n",
       "               0.46261773264602774,\n",
       "               0.45121802254983295,\n",
       "               0.4399871187308105,\n",
       "               0.42937621961467953,\n",
       "               0.4210342112679319,\n",
       "               0.41266305860967645,\n",
       "               0.4064785142485301,\n",
       "               0.39980352359251703,\n",
       "               0.39427172852459663,\n",
       "               0.38877617575005896,\n",
       "               0.3841612938204612,\n",
       "               0.37923200552109265,\n",
       "               0.3750055235802185,\n",
       "               0.3710807383645236,\n",
       "               0.36697706806904035,\n",
       "               0.3638540415422735,\n",
       "               0.360730050529738,\n",
       "               0.35747390662058365,\n",
       "               0.35419424489511125,\n",
       "               0.35130617755585924,\n",
       "               0.3486776972434109,\n",
       "               0.3462094422494871,\n",
       "               0.3443236446535287,\n",
       "               0.3423994243045599,\n",
       "               0.3404706762588128,\n",
       "               0.33864919050954384,\n",
       "               0.3371212203860255,\n",
       "               0.3357925918031401,\n",
       "               0.33423888501470395,\n",
       "               0.33249663877916924,\n",
       "               0.3308480350824675,\n",
       "               0.32952559249706526,\n",
       "               0.3282893845684951,\n",
       "               0.3272514242123885,\n",
       "               0.32611883038156175,\n",
       "               0.32490326087073906,\n",
       "               0.3237176098111351,\n",
       "               0.3226724823793064,\n",
       "               0.32150529661235155,\n",
       "               0.3204969090158483,\n",
       "               0.3197130334527423,\n",
       "               0.31887665564574913,\n",
       "               0.3179655207186527,\n",
       "               0.3173027568503321,\n",
       "               0.316600959804979,\n",
       "               0.31575294606972354,\n",
       "               0.31503102622662266,\n",
       "               0.3144339967151486,\n",
       "               0.31382739881877986,\n",
       "               0.31333890207707804,\n",
       "               0.31268410478561015,\n",
       "               0.31210516291191287,\n",
       "               0.31149636036219924,\n",
       "               0.31095070301219235,\n",
       "               0.3102638458273624,\n",
       "               0.30969131188055377,\n",
       "               0.3091422105380887,\n",
       "               0.3087257651556535,\n",
       "               0.3083187949806519,\n",
       "               0.3077440855848448,\n",
       "               0.307210139684229,\n",
       "               0.30676656710172545,\n",
       "               0.3062058558858837,\n",
       "               0.30569382667416006,\n",
       "               0.30527095822251366,\n",
       "               0.30471448273531904,\n",
       "               0.3043011425034931,\n",
       "               0.3039124559044835,\n",
       "               0.303510913377201,\n",
       "               0.3031100709087702,\n",
       "               0.30270450161815005,\n",
       "               0.30215602986863105,\n",
       "               0.3017287101606156,\n",
       "               0.3014023118805245,\n",
       "               0.30109429237627,\n",
       "               0.3007531778471269,\n",
       "               0.30042209577203666,\n",
       "               0.2999738301864723,\n",
       "               0.2996618914641754,\n",
       "               0.2993347688805527,\n",
       "               0.29905082283458334,\n",
       "               0.29874385018468075,\n",
       "               0.29836303906937384,\n",
       "               0.2980060036305511,\n",
       "               0.29774668263052423,\n",
       "               0.29745593518641056,\n",
       "               0.2971164397422987,\n",
       "               0.2968478483845729,\n",
       "               0.2965342589997779,\n",
       "               0.2962216827533507,\n",
       "               0.29598653135171576,\n",
       "               0.2957411312145271,\n",
       "               0.2954646780128321,\n",
       "               0.29516004517103595,\n",
       "               0.29480558366891074,\n",
       "               0.29453957390121904,\n",
       "               0.29429045848077146,\n",
       "               0.2940231273306952,\n",
       "               0.29375850330050707,\n",
       "               0.2934832925610109,\n",
       "               0.29326517144914505,\n",
       "               0.29301928941835287,\n",
       "               0.29280563105755036,\n",
       "               0.2925698609675867,\n",
       "               0.2923177716546177,\n",
       "               0.292102742535749,\n",
       "               0.29157249846300665,\n",
       "               0.2913741055667544,\n",
       "               0.29117008068034994,\n",
       "               0.29097175480122545,\n",
       "               0.2907843533757828,\n",
       "               0.2905308957575077,\n",
       "               0.2903091742412438,\n",
       "               0.2901235873412248,\n",
       "               0.2899105937488457,\n",
       "               0.2896952833212612,\n",
       "               0.28953881643506846,\n",
       "               0.28931119906244135,\n",
       "               0.2891069823992565,\n",
       "               0.28892773413277334,\n",
       "               0.2887677386984321,\n",
       "               0.28858092687467923,\n",
       "               0.2883898435755294,\n",
       "               0.2882144502837913,\n",
       "               0.2880165590128038,\n",
       "               0.28785066799108433,\n",
       "               0.28763404124132247,\n",
       "               0.28724017393426465,\n",
       "               0.2871002691596049,\n",
       "               0.286932754098234,\n",
       "               0.28679152203523955,\n",
       "               0.28659313328633235,\n",
       "               0.28638636148064606,\n",
       "               0.28621623063585916,\n",
       "               0.28593848933832006,\n",
       "               0.2857375000517877,\n",
       "               0.2855692843261095,\n",
       "               0.2853904485261161,\n",
       "               0.28519300868697095,\n",
       "               0.2850463595362614,\n",
       "               0.2848994711016742,\n",
       "               0.2847848896441013,\n",
       "               0.2846016767670259,\n",
       "               0.28446159469319965,\n",
       "               0.2843429442751501,\n",
       "               0.28397982416699263,\n",
       "               0.28387054500682546,\n",
       "               0.283725238189836,\n",
       "               0.2835298209055973,\n",
       "               0.2834084150328291,\n",
       "               0.2832411696620985,\n",
       "               0.283027753235682,\n",
       "               0.282879482038829,\n",
       "               0.28269929175006175,\n",
       "               0.28242472488005,\n",
       "               0.2822715265308976,\n",
       "               0.28212425470090413,\n",
       "               0.28201523962550995,\n",
       "               0.28186834117240195,\n",
       "               0.2817645853711968,\n",
       "               0.28164532078055315,\n",
       "               0.28149814176618265,\n",
       "               0.2813471626130686,\n",
       "               0.2811755911835839,\n",
       "               0.281052548938778,\n",
       "               0.2809300306717839,\n",
       "               0.2808094809041635,\n",
       "               0.2806748386007208,\n",
       "               0.28051274467812043,\n",
       "               0.2803928568803809,\n",
       "               0.2802432098682018,\n",
       "               0.2800807947272254,\n",
       "               0.27990059328474687,\n",
       "               0.2797881024010694,\n",
       "               0.2796512146141696,\n",
       "               0.2795062212166799,\n",
       "               0.27923345177175696,\n",
       "               0.2790825921423329,\n",
       "               0.2789349368218301,\n",
       "               0.27878612160978367,\n",
       "               0.27868038141892937,\n",
       "               0.2785634930502244,\n",
       "               0.2784428024573628,\n",
       "               0.278305564810623,\n",
       "               0.2781697390837264,\n",
       "               0.27807202784454027,\n",
       "               0.2779398049187108,\n",
       "               0.27781435689445516,\n",
       "               0.27736160111402525,\n",
       "               0.27719165138099794,\n",
       "               0.27709088747826954,\n",
       "               0.2769588538848413,\n",
       "               0.27682941494144436,\n",
       "               0.2766881411012488,\n",
       "               0.27656863541850896,\n",
       "               0.27645911239027954,\n",
       "               0.2763621491865793,\n",
       "               0.2762357286792901,\n",
       "               0.27613173753458103,\n",
       "               0.27598376922725554,\n",
       "               0.27584450901284296,\n",
       "               0.2756518014124992,\n",
       "               0.27554935403130454,\n",
       "               0.2754193529017588,\n",
       "               0.2753274747756497,\n",
       "               0.275231116713655,\n",
       "               0.2751059739760992,\n",
       "               0.2749721852869924,\n",
       "               0.2748557355253621,\n",
       "               0.27466144550145666,\n",
       "               0.27455236896024154,\n",
       "               0.27444333817796823,\n",
       "               0.2743416831396975,\n",
       "               0.27421190767691817,\n",
       "               0.27398015978205154,\n",
       "               0.2738936237602359,\n",
       "               0.2737824128078679,\n",
       "               0.2736968892565188,\n",
       "               0.27359517851792586,\n",
       "               0.2734997460216433,\n",
       "               0.2733471412979765,\n",
       "               0.27323346107043656,\n",
       "               0.2730829772970475,\n",
       "               0.2729358514904294,\n",
       "               0.2728329429736443,\n",
       "               0.27259195964706917,\n",
       "               0.27243210705793736,\n",
       "               0.2722980996367865,\n",
       "               0.27209271332442747,\n",
       "               0.271979723526422,\n",
       "               0.27188515205692326,\n",
       "               0.27176298548173455,\n",
       "               0.27165777308493727,\n",
       "               0.2715657264988864,\n",
       "               0.27145778068512727,\n",
       "               0.271349222954024,\n",
       "               0.27126231281938384,\n",
       "               0.27114292148540514,\n",
       "               0.2710049623076329,\n",
       "               0.27092742293194033,\n",
       "               0.27082232103671444,\n",
       "               0.27071831828941306,\n",
       "               0.27057796125412237,\n",
       "               0.270400075813712,\n",
       "               0.2702624380582397,\n",
       "               0.2701706111893853,\n",
       "               0.2701045383108707,\n",
       "               0.2699252344794086,\n",
       "               0.26983349187992983,\n",
       "               0.2697488027322316,\n",
       "               0.26965697472590905,\n",
       "               0.26957667582339406,\n",
       "               0.26946431841466106,\n",
       "               0.26937116333820915,\n",
       "               0.2692953092327432,\n",
       "               0.26909843781158704,\n",
       "               0.268977606431873,\n",
       "               0.2688132053672984,\n",
       "               0.26865912630567834,\n",
       "               0.26854482923693546,\n",
       "               0.26844632820896264,\n",
       "               0.2683586489175296,\n",
       "               0.2682341438910783,\n",
       "               0.2681467063233947,\n",
       "               0.2679853957092628,\n",
       "               0.2678796972337923,\n",
       "               0.2677959839082529,\n",
       "               0.267732372926196,\n",
       "               0.2676163287176209,\n",
       "               0.2675305446058674,\n",
       "               0.26742478616903914,\n",
       "               0.2673506892304672,\n",
       "               0.267278083692561,\n",
       "               0.26717722546577466,\n",
       "               0.2670805991341046,\n",
       "               0.26696695489972677,\n",
       "               0.2668616801198697,\n",
       "               0.2666828922670021,\n",
       "               0.266568550629434,\n",
       "               0.2664866535180738,\n",
       "               0.26636671315617766,\n",
       "               0.2662836764733255,\n",
       "               0.26613884506189955,\n",
       "               0.26603930875979004,\n",
       "               0.26594245175587494,\n",
       "               0.26586039645484333,\n",
       "               0.2657720906877825,\n",
       "               0.265671525163567,\n",
       "               0.2656251881700283,\n",
       "               0.265515789097759,\n",
       "               0.2653611776586953,\n",
       "               0.26523862633784484,\n",
       "               0.2651477769282716,\n",
       "               0.2650498184520953,\n",
       "               0.264959539763279,\n",
       "               0.26483769149226605,\n",
       "               0.2647616968343906,\n",
       "               0.26465939406321515,\n",
       "               0.2645520030021286,\n",
       "               0.26445130462373717,\n",
       "               0.2643598423436192,\n",
       "               0.264285114248383,\n",
       "               0.2641442550995324,\n",
       "               0.2640153134715411,\n",
       "               0.2639148013335894,\n",
       "               0.2638095292639917,\n",
       "               0.26368992242563977,\n",
       "               0.26360316710367243,\n",
       "               0.2634945165295685,\n",
       "               0.26339788620118504,\n",
       "               0.26330046765148357,\n",
       "               0.2632060571576373,\n",
       "               0.2631333242029968,\n",
       "               0.26305700462248355,\n",
       "               0.2629255292096635,\n",
       "               0.2628168821703754,\n",
       "               0.2627116737716993,\n",
       "               0.2624544763868893,\n",
       "               0.26232064225674917,\n",
       "               0.2622145701544989,\n",
       "               0.2620969635829015,\n",
       "               0.2620148760502775,\n",
       "               0.26193322948854547,\n",
       "               0.26184071888423444,\n",
       "               0.2617188418028011,\n",
       "               0.26161813862662536,\n",
       "               0.26150713008019255,\n",
       "               0.26141548944025034,\n",
       "               0.26123059087117984,\n",
       "               0.2611286493417415,\n",
       "               0.26105079033685846,\n",
       "               0.2609381947517365,\n",
       "               0.26074730987170763,\n",
       "               0.2606376084730906,\n",
       "               0.2605209622824836,\n",
       "               0.2604235248815692,\n",
       "               0.2603260025589663,\n",
       "               0.2601167347166316,\n",
       "               0.26002463070373494,\n",
       "               0.25991449719704607,\n",
       "               0.259827280224641,\n",
       "               0.25973858654812015,\n",
       "               0.259659410954647,\n",
       "               0.2595551421914703,\n",
       "               0.25944558766922504,\n",
       "               0.2592846273349551,\n",
       "               0.2591140491366734,\n",
       "               0.2590280358442644,\n",
       "               0.25891367338218985,\n",
       "               0.2586819605295081,\n",
       "               0.2585285201428678,\n",
       "               0.2584043502494643,\n",
       "               0.2582192488174313,\n",
       "               0.2580854233668565,\n",
       "               0.25795854297835247,\n",
       "               0.2577819690406254,\n",
       "               0.2576554019078137,\n",
       "               0.25749087043958113,\n",
       "               0.2573905202444236,\n",
       "               0.2572227699379522,\n",
       "               0.2571336683805188,\n",
       "               0.25698641781098197,\n",
       "               0.25689575838505946,\n",
       "               0.256812192356139,\n",
       "               0.2567065867602106,\n",
       "               0.2566159866531987,\n",
       "               0.2565244633059531,\n",
       "               0.2564400227406507,\n",
       "               0.2563408734069071,\n",
       "               0.2562548733985662,\n",
       "               0.2560957098394702,\n",
       "               0.25593606139417,\n",
       "               0.25584985988073644,\n",
       "               0.2557138293586036,\n",
       "               0.2556078407206758,\n",
       "               0.2555097397748633,\n",
       "               0.25537391525857933,\n",
       "               0.2552700750123861,\n",
       "               0.255149340280922,\n",
       "               0.255066093072215,\n",
       "               0.2548174358311415,\n",
       "               0.2547249267965419,\n",
       "               0.25462920328083666,\n",
       "               0.25441623417900466,\n",
       "               0.25419955911028297,\n",
       "               0.2540715739744109,\n",
       "               0.25398553394392526,\n",
       "               0.2538791195944134,\n",
       "               0.2538043097504894,\n",
       "               0.25368560943949325,\n",
       "               0.2535150773719925,\n",
       "               0.2534253770749952,\n",
       "               0.25332787820382097,\n",
       "               0.25322211958173363,\n",
       "               0.2531081410323514,\n",
       "               0.2530056511513268,\n",
       "               0.25291360708692195,\n",
       "               0.2528132016769448,\n",
       "               0.2526236451512453,\n",
       "               0.2525226080120675,\n",
       "               0.25239950226262126,\n",
       "               0.2523051462617238,\n",
       "               0.2521068127632973,\n",
       "               0.2520341131688755,\n",
       "               0.25194548925173915,\n",
       "               0.25185553875167604,\n",
       "               0.25174656792362926,\n",
       "               0.25160331134525976,\n",
       "               0.2515028420042184,\n",
       "               0.2514073449238756,\n",
       "               0.25131702744961987,\n",
       "               0.25122213256620135,\n",
       "               0.25111617389491014,\n",
       "               0.2510015408946325,\n",
       "               0.2509105001057642,\n",
       "               0.25083323524451084,\n",
       "               0.2507407835045032,\n",
       "               0.25064299263606515,\n",
       "               0.25052798064083537,\n",
       "               0.2504147861886226,\n",
       "               0.2502795250159802,\n",
       "               0.25007232551805303,\n",
       "               0.2499748698756811,\n",
       "               0.2498642835227379,\n",
       "               0.24970358568897688,\n",
       "               0.2496357529909475,\n",
       "               0.24952512510565392,\n",
       "               0.24943467710309872,\n",
       "               0.24930054708141913,\n",
       "               0.24919005544463294,\n",
       "               0.249101371404846,\n",
       "               0.24901877582928234,\n",
       "               0.248933323698451,\n",
       "               0.24883349350009706,\n",
       "               0.24872597591468804,\n",
       "               0.24863366266658268,\n",
       "               0.2485464067302828,\n",
       "               0.24846401145938435,\n",
       "               0.24836546923258088,\n",
       "               0.248242722957874,\n",
       "               0.2481579667020568,\n",
       "               0.24803019686587438,\n",
       "               0.24794936134537296,\n",
       "               0.24784684656802766,\n",
       "               0.24774118067564396,\n",
       "               0.24765331369886598,\n",
       "               0.2475588417195218,\n",
       "               0.2474283876524566,\n",
       "               0.2473495765618341,\n",
       "               0.24727036147759449,\n",
       "               0.247175644436851,\n",
       "               0.2471021289236689,\n",
       "               0.24702522185630413,\n",
       "               0.246941128925115,\n",
       "               0.2468812454409891,\n",
       "               0.24680567859946714,\n",
       "               0.2467173920392728,\n",
       "               0.24664503516586486,\n",
       "               0.24657202028482494,\n",
       "               0.24646912345626548,\n",
       "               0.2463720384700463,\n",
       "               0.2462908183556806,\n",
       "               0.24620390626986163,\n",
       "               0.24611849656225157,\n",
       "               0.2460429459869279,\n",
       "               0.24593868114561188,\n",
       "               0.2458525502150095,\n",
       "               0.2457803202022363,\n",
       "               0.2456926702120118,\n",
       "               0.24561031252501572,\n",
       "               0.24551652529129753,\n",
       "               0.24545088762349176,\n",
       "               0.24535489688671994,\n",
       "               0.24524499294002655,\n",
       "               0.24515975493299413,\n",
       "               0.24508734603060045,\n",
       "               0.24502899422242339,\n",
       "               0.244948436383522,\n",
       "               0.24488041796372406,\n",
       "               0.244794460344656,\n",
       "               0.24466846547563362,\n",
       "               0.24455704504882103,\n",
       "               0.2444423028032113,\n",
       "               0.24436166382244714,\n",
       "               0.24428144437761032,\n",
       "               0.24417758567694436,\n",
       "               0.24411339175853589,\n",
       "               0.24405218563237016,\n",
       "               0.24395155488603304,\n",
       "               0.2438649208189204],\n",
       "              'train-Logloss-std': [0.001376295835941572,\n",
       "               0.002595801045180399,\n",
       "               0.000912979615286757,\n",
       "               0.0007095400175838067,\n",
       "               0.0014103748581683366,\n",
       "               0.0024747251241276085,\n",
       "               0.0029089660540469755,\n",
       "               0.00409712214821341,\n",
       "               0.004721111177253562,\n",
       "               0.006071489966019809,\n",
       "               0.006688865961407602,\n",
       "               0.006924402480004856,\n",
       "               0.006229300947500686,\n",
       "               0.005800094754528507,\n",
       "               0.005604908428151297,\n",
       "               0.005284972034346529,\n",
       "               0.006363161414737554,\n",
       "               0.005868586283566454,\n",
       "               0.005382163887218117,\n",
       "               0.005705080937193639,\n",
       "               0.005811930288659919,\n",
       "               0.005666728453262131,\n",
       "               0.005702804493320245,\n",
       "               0.005451981390054207,\n",
       "               0.004956772389384113,\n",
       "               0.005164567741366501,\n",
       "               0.004502376111308414,\n",
       "               0.0043131903631252865,\n",
       "               0.00420219669322902,\n",
       "               0.0041833261433844365,\n",
       "               0.004467572805176858,\n",
       "               0.004222601137306331,\n",
       "               0.004496542418142507,\n",
       "               0.0042415108776483815,\n",
       "               0.004019485010971805,\n",
       "               0.0038079947439366413,\n",
       "               0.0036496249082377473,\n",
       "               0.003499333817962276,\n",
       "               0.003578266336511013,\n",
       "               0.0036517624714974247,\n",
       "               0.0033710073371580845,\n",
       "               0.0033977059533599626,\n",
       "               0.003263349868909712,\n",
       "               0.0032213343990887505,\n",
       "               0.003190214164890184,\n",
       "               0.0029953718334433024,\n",
       "               0.0028173588790174524,\n",
       "               0.0027253951856789187,\n",
       "               0.0029126500548914986,\n",
       "               0.003031976863113474,\n",
       "               0.0029695982778785725,\n",
       "               0.0030629272657509564,\n",
       "               0.0029016314373584186,\n",
       "               0.0029737561742661906,\n",
       "               0.0028905689355050845,\n",
       "               0.0027826946708610313,\n",
       "               0.002520499669538341,\n",
       "               0.0025464567397909007,\n",
       "               0.002502366781998516,\n",
       "               0.0024640366994446747,\n",
       "               0.0025690157467121028,\n",
       "               0.0024820345669365165,\n",
       "               0.002358446884008012,\n",
       "               0.002537442453622209,\n",
       "               0.0025602583842717244,\n",
       "               0.0026006432663894566,\n",
       "               0.0028171432193371993,\n",
       "               0.002744928604797337,\n",
       "               0.002743229053990634,\n",
       "               0.002669220470719313,\n",
       "               0.002674996460517796,\n",
       "               0.0025698167521553427,\n",
       "               0.002654205529101273,\n",
       "               0.002574899925029094,\n",
       "               0.002437260019682864,\n",
       "               0.002524416912980607,\n",
       "               0.002437298580934825,\n",
       "               0.0023791963381624482,\n",
       "               0.0024787714183194753,\n",
       "               0.002496167472486574,\n",
       "               0.002407262991402928,\n",
       "               0.002404850667478389,\n",
       "               0.0023688452989878124,\n",
       "               0.002393749219746553,\n",
       "               0.002442610252922314,\n",
       "               0.0024692469028297706,\n",
       "               0.002415821826302592,\n",
       "               0.0023973521281312614,\n",
       "               0.0023547229910838717,\n",
       "               0.002326339441354702,\n",
       "               0.002370969996168292,\n",
       "               0.0024022044205865294,\n",
       "               0.0023572937621112147,\n",
       "               0.0024513587258553453,\n",
       "               0.0024437158090474284,\n",
       "               0.002457929897990431,\n",
       "               0.002508591423069396,\n",
       "               0.002441618581494264,\n",
       "               0.002437533012113886,\n",
       "               0.0025251843775607693,\n",
       "               0.002448949858320185,\n",
       "               0.002495195385777606,\n",
       "               0.00249767909602861,\n",
       "               0.0025508084198408716,\n",
       "               0.0024477267976935964,\n",
       "               0.0023626778349610696,\n",
       "               0.0024110270053595306,\n",
       "               0.0023256512761500436,\n",
       "               0.0023360713710129425,\n",
       "               0.0023498077211810916,\n",
       "               0.0022889155884621756,\n",
       "               0.0022844693905412993,\n",
       "               0.0022552313731501817,\n",
       "               0.0023813132577166865,\n",
       "               0.0023502028144151755,\n",
       "               0.0023554076254978626,\n",
       "               0.0019712024217019308,\n",
       "               0.001963690261375337,\n",
       "               0.0019728531404115345,\n",
       "               0.0019993041156578803,\n",
       "               0.0020299618496896574,\n",
       "               0.002020735999000681,\n",
       "               0.002096918341430101,\n",
       "               0.002111650821774644,\n",
       "               0.0020735325179244723,\n",
       "               0.0020728054537745397,\n",
       "               0.0020377512509923592,\n",
       "               0.0019979006210302046,\n",
       "               0.001994373157197625,\n",
       "               0.0019900766659038875,\n",
       "               0.001979422659846543,\n",
       "               0.0019968295152566194,\n",
       "               0.0019772495876464154,\n",
       "               0.002025761067278728,\n",
       "               0.0020227998189418536,\n",
       "               0.0020658216783426713,\n",
       "               0.0019598545512011286,\n",
       "               0.002056455753071269,\n",
       "               0.002088586923619316,\n",
       "               0.0021034769326142943,\n",
       "               0.0020947902286884623,\n",
       "               0.0021110991525353988,\n",
       "               0.00217941490902137,\n",
       "               0.002163466102920414,\n",
       "               0.0021297081361779423,\n",
       "               0.0020723968304110717,\n",
       "               0.0020936255971405384,\n",
       "               0.0020954885566284993,\n",
       "               0.0021543530815522544,\n",
       "               0.002135088884037472,\n",
       "               0.0021183647734367597,\n",
       "               0.002136433004256858,\n",
       "               0.0020933496386938643,\n",
       "               0.0020988798224111493,\n",
       "               0.00213301226521243,\n",
       "               0.0017587744348533517,\n",
       "               0.0017678781884334868,\n",
       "               0.0017953025808546516,\n",
       "               0.0018233079484334788,\n",
       "               0.0017936731843002714,\n",
       "               0.0017851955522514612,\n",
       "               0.0017810261945269501,\n",
       "               0.0018104103171333755,\n",
       "               0.0018415536713000053,\n",
       "               0.001740777181356809,\n",
       "               0.0017784594026678925,\n",
       "               0.0017564230775593132,\n",
       "               0.0017747231814595386,\n",
       "               0.0018348309735403785,\n",
       "               0.001823557028997913,\n",
       "               0.0018318204746315553,\n",
       "               0.001803017706800301,\n",
       "               0.0017622197622203847,\n",
       "               0.0017498254818757966,\n",
       "               0.0017934311908297442,\n",
       "               0.0017809960499802374,\n",
       "               0.0017397407076285146,\n",
       "               0.0017157348090495936,\n",
       "               0.0017325627700176735,\n",
       "               0.0017292871879702346,\n",
       "               0.0017404559021642206,\n",
       "               0.0017489238091667986,\n",
       "               0.0018021241717185502,\n",
       "               0.001809658929656875,\n",
       "               0.0018145838418814582,\n",
       "               0.0018202678433673065,\n",
       "               0.0016658433256759395,\n",
       "               0.0016404218984299478,\n",
       "               0.0016300593897466218,\n",
       "               0.0016116261140601592,\n",
       "               0.001594888434398137,\n",
       "               0.0016132914462297053,\n",
       "               0.0015762415276607332,\n",
       "               0.0016255930751121256,\n",
       "               0.0016277492733185212,\n",
       "               0.001610037485712256,\n",
       "               0.0015548084739205451,\n",
       "               0.001589127276505364,\n",
       "               0.0014988317215932287,\n",
       "               0.00145964451699893,\n",
       "               0.001487326068186237,\n",
       "               0.0015042698360769047,\n",
       "               0.0015327333586515376,\n",
       "               0.001568513406167079,\n",
       "               0.0016008551427865172,\n",
       "               0.0015596639876601385,\n",
       "               0.001544073664769135,\n",
       "               0.001526085087662224,\n",
       "               0.0015051486677690855,\n",
       "               0.0014942255716726355,\n",
       "               0.001499138693407157,\n",
       "               0.0014004017138129876,\n",
       "               0.0014053165194924987,\n",
       "               0.0014147196372526231,\n",
       "               0.0014067168633688776,\n",
       "               0.0014127810957491034,\n",
       "               0.0014462964655004538,\n",
       "               0.0014548618511084387,\n",
       "               0.0014430379832393535,\n",
       "               0.0013334266519029817,\n",
       "               0.0013470962403045726,\n",
       "               0.001329345688168644,\n",
       "               0.0013032650045275,\n",
       "               0.0013077898274346132,\n",
       "               0.0013850249437255063,\n",
       "               0.0013925416469248685,\n",
       "               0.001378830381567964,\n",
       "               0.0013468844891510673,\n",
       "               0.001345702314317653,\n",
       "               0.0013288648036423921,\n",
       "               0.0012421425856732195,\n",
       "               0.0012169427540245049,\n",
       "               0.001217986984033475,\n",
       "               0.0012313089540960506,\n",
       "               0.0012558146965418661,\n",
       "               0.0013456049653823659,\n",
       "               0.0011927389286441146,\n",
       "               0.0011962046606865525,\n",
       "               0.0010070841191828384,\n",
       "               0.0009891619587140234,\n",
       "               0.000994284926304352,\n",
       "               0.0010464421029479287,\n",
       "               0.0010535686938836087,\n",
       "               0.0010625274742746417,\n",
       "               0.001084786024004735,\n",
       "               0.0011006740925852399,\n",
       "               0.0010496294857199472,\n",
       "               0.0010330733458602636,\n",
       "               0.001061266084386336,\n",
       "               0.001067004463747906,\n",
       "               0.0010397595850524049,\n",
       "               0.0010399102440188602,\n",
       "               0.0010382006301091148,\n",
       "               0.001061931860349052,\n",
       "               0.0009933787215533345,\n",
       "               0.000999452169475987,\n",
       "               0.0010018829890508561,\n",
       "               0.0010221584631995083,\n",
       "               0.001014036195757008,\n",
       "               0.001043407746909035,\n",
       "               0.0010251334983815558,\n",
       "               0.0010401599932903175,\n",
       "               0.0010129683424094738,\n",
       "               0.0009771151720999276,\n",
       "               0.0009757079943018304,\n",
       "               0.0010005154468761925,\n",
       "               0.000999506176131453,\n",
       "               0.0010566666897148362,\n",
       "               0.0010795737568017722,\n",
       "               0.0010462629752088777,\n",
       "               0.001026108513867153,\n",
       "               0.001039648148688082,\n",
       "               0.0009985895709138106,\n",
       "               0.001008318697383866,\n",
       "               0.0010729966498697172,\n",
       "               0.0010919591697978468,\n",
       "               0.001076769229940556,\n",
       "               0.0010956347977857655,\n",
       "               0.0010754872813910972,\n",
       "               0.0011191588326464389,\n",
       "               0.0011025467864156414,\n",
       "               0.001109901040590821,\n",
       "               0.0011172413608385012,\n",
       "               0.0010834766466164157,\n",
       "               0.0010392380300528895,\n",
       "               0.0010393834959654253,\n",
       "               0.0009999042353900913,\n",
       "               0.0010064792633270143,\n",
       "               0.0010196379107694138,\n",
       "               0.0010191099969436785,\n",
       "               0.0010332958549283816,\n",
       "               0.001047450949600026,\n",
       "               0.0010345423247151854,\n",
       "               0.0010541701850602621,\n",
       "               0.00105642980945006,\n",
       "               0.0010859540142651022,\n",
       "               0.0011133607356441585,\n",
       "               0.0010793957780392005,\n",
       "               0.0010893041924231429,\n",
       "               0.0010724827816320135,\n",
       "               0.0011187676330949396,\n",
       "               0.0011043183736622363,\n",
       "               0.0011199792079806007,\n",
       "               0.0011122484718707646,\n",
       "               0.0011049467248896462,\n",
       "               0.0011489331292278673,\n",
       "               0.001136643722367724,\n",
       "               0.001136154334639749,\n",
       "               0.0011443076497313707,\n",
       "               0.0011205949741432246,\n",
       "               0.0011140107461872991,\n",
       "               0.001120168802397195,\n",
       "               0.001176567279458513,\n",
       "               0.001182141272145223,\n",
       "               0.0011171921065602811,\n",
       "               0.0011370604346713701,\n",
       "               0.0011273597891508693,\n",
       "               0.0011485739887239985,\n",
       "               0.00111014534137423,\n",
       "               0.0011000999936433703,\n",
       "               0.001078276410024825,\n",
       "               0.0011081267133219578,\n",
       "               0.001128422722400341,\n",
       "               0.0011481791788357568,\n",
       "               0.0010874011877871034,\n",
       "               0.0010812698651852623,\n",
       "               0.0010788831092218925,\n",
       "               0.00109869909915492,\n",
       "               0.0011533231972855637,\n",
       "               0.0011387648451786742,\n",
       "               0.0011578475362658707,\n",
       "               0.0011366509692751579,\n",
       "               0.0011578396707138381,\n",
       "               0.0011571333781053889,\n",
       "               0.001168426330075433,\n",
       "               0.0011689778846520871,\n",
       "               0.001159674608028004,\n",
       "               0.0011606548555647962,\n",
       "               0.0012433897723073016,\n",
       "               0.0012444963128360618,\n",
       "               0.0012258226847451756,\n",
       "               0.001216123732174661,\n",
       "               0.0011744337058419566,\n",
       "               0.0011915668317550748,\n",
       "               0.001169276343185644,\n",
       "               0.0011807952497194295,\n",
       "               0.0011885255520694873,\n",
       "               0.0012115320667504465,\n",
       "               0.0012266335958096288,\n",
       "               0.0012353341383023685,\n",
       "               0.0012287067993254973,\n",
       "               0.0012236132373603342,\n",
       "               0.0012333012992071005,\n",
       "               0.0012198768646147808,\n",
       "               0.0011977916561599841,\n",
       "               0.0013143901465064963,\n",
       "               0.0013320925207596205,\n",
       "               0.0013116508351204233,\n",
       "               0.0013239712820435313,\n",
       "               0.0013735323221170095,\n",
       "               0.0014587724437962143,\n",
       "               0.0014547898932665902,\n",
       "               0.0014208774322527074,\n",
       "               0.0014410988690960191,\n",
       "               0.0015397628977910967,\n",
       "               0.001602900006060239,\n",
       "               0.0016229330653990326,\n",
       "               0.001510309066940845,\n",
       "               0.0015364906557872944,\n",
       "               0.0015726697705371478,\n",
       "               0.0015601602895780069,\n",
       "               0.0014904510867375573,\n",
       "               0.0014859445027117348,\n",
       "               0.0014971688632322091,\n",
       "               0.001481570073101193,\n",
       "               0.0014858507419387083,\n",
       "               0.0014790516862017342,\n",
       "               0.0014806135631127847,\n",
       "               0.0014669025857239615,\n",
       "               0.00147658367461085,\n",
       "               0.0013626245177651845,\n",
       "               0.0013688392823902127,\n",
       "               0.0013751093553185994,\n",
       "               0.0013957590654471758,\n",
       "               0.0013892863880603202,\n",
       "               0.0013534933992211853,\n",
       "               0.0013721338950166673,\n",
       "               0.0013868933323675525,\n",
       "               0.00141887636827223,\n",
       "               0.0014069075506888034,\n",
       "               0.0013713448884708265,\n",
       "               0.0013546446044746762,\n",
       "               0.0013586670818606535,\n",
       "               0.0012658361149344604,\n",
       "               0.0013454737620554155,\n",
       "               0.0013510047226919575,\n",
       "               0.0013271041649766243,\n",
       "               0.0013430598430909987,\n",
       "               0.0013480855116510533,\n",
       "               0.001358477971156949,\n",
       "               0.0012403960729156377,\n",
       "               0.001263897699130325,\n",
       "               0.0012665095348057022,\n",
       "               0.0012826616434374718,\n",
       "               0.0012777363804538234,\n",
       "               0.0013094270033211844,\n",
       "               0.0013078835139990037,\n",
       "               0.001249934744134189,\n",
       "               0.0012259468500737411,\n",
       "               0.0012060241893506781,\n",
       "               0.0012822044859616371,\n",
       "               0.0012680516762478527,\n",
       "               0.0013651465557407109,\n",
       "               0.0013848170511693888,\n",
       "               0.0013693867009245664,\n",
       "               0.0013977652562756986,\n",
       "               0.0013834241673266682,\n",
       "               0.0014105598495759597,\n",
       "               0.001413227386014872,\n",
       "               0.0013812055642527204,\n",
       "               0.001369031364982095,\n",
       "               0.001369313197186796,\n",
       "               0.0013744392633184908,\n",
       "               0.0014012937783076346,\n",
       "               0.0014055404714787055,\n",
       "               0.0014085433456398225,\n",
       "               0.00143154488735339,\n",
       "               0.001427747564857248,\n",
       "               0.0014025721490093304,\n",
       "               0.001422321457281578,\n",
       "               0.001445105539306523,\n",
       "               0.0014072557407029634,\n",
       "               0.0014095179928318893,\n",
       "               0.001425837780184218,\n",
       "               0.0015119291190396976,\n",
       "               0.001525691579605908,\n",
       "               0.0015653683329483498,\n",
       "               0.0015741448848396787,\n",
       "               0.0015922700417833153,\n",
       "               0.0016000495110049349,\n",
       "               0.0016009204894286086,\n",
       "               0.001585472810979432,\n",
       "               0.0015716116063925578,\n",
       "               0.0015915400433574986,\n",
       "               0.0016135408207866994,\n",
       "               0.0016515514545051952,\n",
       "               0.0016352649394608134,\n",
       "               0.0016319808305554381,\n",
       "               0.0016428502536203825,\n",
       "               0.0016787085271544426,\n",
       "               0.001668063365294206,\n",
       "               0.0016072129351155688,\n",
       "               0.0016035155014000573,\n",
       "               0.0016189178854801904,\n",
       "               0.0015895941229395222,\n",
       "               0.001590387557356869,\n",
       "               0.001602144125550948,\n",
       "               0.0015179303668212017,\n",
       "               0.0015223675692311825,\n",
       "               0.001531155004720116,\n",
       "               0.0015329474652354107,\n",
       "               0.0015363182465039063,\n",
       "               0.0015378110003050982,\n",
       "               0.0015410180519498664,\n",
       "               0.0015458527499290367,\n",
       "               0.0015402412983515667,\n",
       "               0.001560363027253266,\n",
       "               0.0015624109719469038,\n",
       "               0.0015693872195010885,\n",
       "               0.0015272749234689585,\n",
       "               0.0015292899206544753,\n",
       "               0.001546544418031694,\n",
       "               0.0015449957689751951,\n",
       "               0.0015534098263266707,\n",
       "               0.0015506773489389364,\n",
       "               0.0014678463158082642,\n",
       "               0.0014735317486144841,\n",
       "               0.001475913634903184,\n",
       "               0.0014732312532292362,\n",
       "               0.001479811979502581,\n",
       "               0.0014439275180368946,\n",
       "               0.0014317344867067463,\n",
       "               0.0014496361379784581,\n",
       "               0.001448461636859414,\n",
       "               0.0014151788510445617,\n",
       "               0.0013921331550698966,\n",
       "               0.0013923448427936175,\n",
       "               0.0014092750385237935,\n",
       "               0.0014149808777699714,\n",
       "               0.001411596936682188,\n",
       "               0.0014524642098027514,\n",
       "               0.0014903533186805655,\n",
       "               0.001520986023176626,\n",
       "               0.001475959358362399,\n",
       "               0.0014915059574958538,\n",
       "               0.001522521856147436,\n",
       "               0.0015148011319092622,\n",
       "               0.0015271919771408754,\n",
       "               0.0015260830694252237,\n",
       "               0.001473605893730929]})}"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_boosting_model = catboost.CatBoostClassifier(n_estimators=500,\n",
    "                                            silent=True,\n",
    "                                             eval_metric='AUC'                                             \n",
    "                                            )\n",
    "grid_boosting_model.grid_search({'l2_leaf_reg': np.linspace(0, 1, 20)}, \n",
    "                           x_train, \n",
    "                           y_train, plot=True, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_boosting = grid_boosting_model.predict_proba(x_test)[:, 1]\n",
    "roc_auc_score(y_test, predict_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost     ,      OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.078255\n",
      "0:\tlearn: 0.6099682\ttotal: 49.7ms\tremaining: 24.8s\n",
      "1:\tlearn: 0.5494068\ttotal: 95.8ms\tremaining: 23.9s\n",
      "2:\tlearn: 0.5025068\ttotal: 145ms\tremaining: 23.9s\n",
      "3:\tlearn: 0.4643818\ttotal: 190ms\tremaining: 23.6s\n",
      "4:\tlearn: 0.4365127\ttotal: 243ms\tremaining: 24.1s\n",
      "5:\tlearn: 0.4126628\ttotal: 284ms\tremaining: 23.4s\n",
      "6:\tlearn: 0.3953800\ttotal: 329ms\tremaining: 23.2s\n",
      "7:\tlearn: 0.3801667\ttotal: 374ms\tremaining: 23s\n",
      "8:\tlearn: 0.3690772\ttotal: 416ms\tremaining: 22.7s\n",
      "9:\tlearn: 0.3583325\ttotal: 470ms\tremaining: 23.1s\n",
      "10:\tlearn: 0.3521655\ttotal: 522ms\tremaining: 23.2s\n",
      "11:\tlearn: 0.3452166\ttotal: 570ms\tremaining: 23.2s\n",
      "12:\tlearn: 0.3394609\ttotal: 617ms\tremaining: 23.1s\n",
      "13:\tlearn: 0.3350416\ttotal: 662ms\tremaining: 23s\n",
      "14:\tlearn: 0.3310825\ttotal: 711ms\tremaining: 23s\n",
      "15:\tlearn: 0.3268448\ttotal: 760ms\tremaining: 23s\n",
      "16:\tlearn: 0.3238140\ttotal: 810ms\tremaining: 23s\n",
      "17:\tlearn: 0.3209212\ttotal: 860ms\tremaining: 23s\n",
      "18:\tlearn: 0.3184954\ttotal: 908ms\tremaining: 23s\n",
      "19:\tlearn: 0.3163355\ttotal: 962ms\tremaining: 23.1s\n",
      "20:\tlearn: 0.3141272\ttotal: 1.01s\tremaining: 23.1s\n",
      "21:\tlearn: 0.3123404\ttotal: 1.06s\tremaining: 23.1s\n",
      "22:\tlearn: 0.3111859\ttotal: 1.12s\tremaining: 23.2s\n",
      "23:\tlearn: 0.3095853\ttotal: 1.17s\tremaining: 23.2s\n",
      "24:\tlearn: 0.3081437\ttotal: 1.22s\tremaining: 23.2s\n",
      "25:\tlearn: 0.3065872\ttotal: 1.27s\tremaining: 23.2s\n",
      "26:\tlearn: 0.3056431\ttotal: 1.33s\tremaining: 23.3s\n",
      "27:\tlearn: 0.3047501\ttotal: 1.38s\tremaining: 23.3s\n",
      "28:\tlearn: 0.3041441\ttotal: 1.44s\tremaining: 23.4s\n",
      "29:\tlearn: 0.3032814\ttotal: 1.49s\tremaining: 23.4s\n",
      "30:\tlearn: 0.3019658\ttotal: 1.54s\tremaining: 23.4s\n",
      "31:\tlearn: 0.3011753\ttotal: 1.6s\tremaining: 23.4s\n",
      "32:\tlearn: 0.3000812\ttotal: 1.65s\tremaining: 23.4s\n",
      "33:\tlearn: 0.2996336\ttotal: 1.71s\tremaining: 23.4s\n",
      "34:\tlearn: 0.2988488\ttotal: 1.76s\tremaining: 23.4s\n",
      "35:\tlearn: 0.2983921\ttotal: 1.82s\tremaining: 23.4s\n",
      "36:\tlearn: 0.2978381\ttotal: 1.87s\tremaining: 23.4s\n",
      "37:\tlearn: 0.2973346\ttotal: 1.93s\tremaining: 23.4s\n",
      "38:\tlearn: 0.2965652\ttotal: 1.98s\tremaining: 23.5s\n",
      "39:\tlearn: 0.2955667\ttotal: 2.04s\tremaining: 23.5s\n",
      "40:\tlearn: 0.2951069\ttotal: 2.1s\tremaining: 23.5s\n",
      "41:\tlearn: 0.2947772\ttotal: 2.15s\tremaining: 23.5s\n",
      "42:\tlearn: 0.2943459\ttotal: 2.2s\tremaining: 23.4s\n",
      "43:\tlearn: 0.2938791\ttotal: 2.25s\tremaining: 23.4s\n",
      "44:\tlearn: 0.2933977\ttotal: 2.31s\tremaining: 23.3s\n",
      "45:\tlearn: 0.2930860\ttotal: 2.35s\tremaining: 23.2s\n",
      "46:\tlearn: 0.2922028\ttotal: 2.4s\tremaining: 23.1s\n",
      "47:\tlearn: 0.2917672\ttotal: 2.45s\tremaining: 23.1s\n",
      "48:\tlearn: 0.2912858\ttotal: 2.5s\tremaining: 23s\n",
      "49:\tlearn: 0.2905401\ttotal: 2.54s\tremaining: 22.9s\n",
      "50:\tlearn: 0.2901483\ttotal: 2.59s\tremaining: 22.8s\n",
      "51:\tlearn: 0.2897838\ttotal: 2.64s\tremaining: 22.7s\n",
      "52:\tlearn: 0.2894254\ttotal: 2.69s\tremaining: 22.7s\n",
      "53:\tlearn: 0.2891425\ttotal: 2.74s\tremaining: 22.6s\n",
      "54:\tlearn: 0.2885407\ttotal: 2.79s\tremaining: 22.6s\n",
      "55:\tlearn: 0.2882735\ttotal: 2.84s\tremaining: 22.5s\n",
      "56:\tlearn: 0.2878406\ttotal: 2.89s\tremaining: 22.5s\n",
      "57:\tlearn: 0.2872041\ttotal: 2.94s\tremaining: 22.4s\n",
      "58:\tlearn: 0.2869396\ttotal: 3s\tremaining: 22.4s\n",
      "59:\tlearn: 0.2859144\ttotal: 3.05s\tremaining: 22.4s\n",
      "60:\tlearn: 0.2857198\ttotal: 3.1s\tremaining: 22.3s\n",
      "61:\tlearn: 0.2854392\ttotal: 3.15s\tremaining: 22.3s\n",
      "62:\tlearn: 0.2851877\ttotal: 3.2s\tremaining: 22.2s\n",
      "63:\tlearn: 0.2848517\ttotal: 3.26s\tremaining: 22.2s\n",
      "64:\tlearn: 0.2843466\ttotal: 3.31s\tremaining: 22.2s\n",
      "65:\tlearn: 0.2838394\ttotal: 3.37s\tremaining: 22.2s\n",
      "66:\tlearn: 0.2836596\ttotal: 3.43s\tremaining: 22.2s\n",
      "67:\tlearn: 0.2835397\ttotal: 3.48s\tremaining: 22.1s\n",
      "68:\tlearn: 0.2832802\ttotal: 3.53s\tremaining: 22.1s\n",
      "69:\tlearn: 0.2830105\ttotal: 3.58s\tremaining: 22s\n",
      "70:\tlearn: 0.2828437\ttotal: 3.63s\tremaining: 21.9s\n",
      "71:\tlearn: 0.2827338\ttotal: 3.68s\tremaining: 21.9s\n",
      "72:\tlearn: 0.2826281\ttotal: 3.73s\tremaining: 21.8s\n",
      "73:\tlearn: 0.2823966\ttotal: 3.78s\tremaining: 21.8s\n",
      "74:\tlearn: 0.2822713\ttotal: 3.83s\tremaining: 21.7s\n",
      "75:\tlearn: 0.2820445\ttotal: 3.88s\tremaining: 21.6s\n",
      "76:\tlearn: 0.2817996\ttotal: 3.92s\tremaining: 21.6s\n",
      "77:\tlearn: 0.2815993\ttotal: 3.98s\tremaining: 21.5s\n",
      "78:\tlearn: 0.2813803\ttotal: 4.03s\tremaining: 21.5s\n",
      "79:\tlearn: 0.2812977\ttotal: 4.07s\tremaining: 21.4s\n",
      "80:\tlearn: 0.2810259\ttotal: 4.12s\tremaining: 21.3s\n",
      "81:\tlearn: 0.2808591\ttotal: 4.16s\tremaining: 21.2s\n",
      "82:\tlearn: 0.2806293\ttotal: 4.21s\tremaining: 21.1s\n",
      "83:\tlearn: 0.2802438\ttotal: 4.26s\tremaining: 21.1s\n",
      "84:\tlearn: 0.2801801\ttotal: 4.32s\tremaining: 21.1s\n",
      "85:\tlearn: 0.2799333\ttotal: 4.37s\tremaining: 21s\n",
      "86:\tlearn: 0.2796359\ttotal: 4.43s\tremaining: 21s\n",
      "87:\tlearn: 0.2795780\ttotal: 4.48s\tremaining: 21s\n",
      "88:\tlearn: 0.2793665\ttotal: 4.53s\tremaining: 20.9s\n",
      "89:\tlearn: 0.2793012\ttotal: 4.58s\tremaining: 20.9s\n",
      "90:\tlearn: 0.2791957\ttotal: 4.62s\tremaining: 20.8s\n",
      "91:\tlearn: 0.2790198\ttotal: 4.67s\tremaining: 20.7s\n",
      "92:\tlearn: 0.2789230\ttotal: 4.71s\tremaining: 20.6s\n",
      "93:\tlearn: 0.2787632\ttotal: 4.76s\tremaining: 20.6s\n",
      "94:\tlearn: 0.2786494\ttotal: 4.8s\tremaining: 20.5s\n",
      "95:\tlearn: 0.2785506\ttotal: 4.85s\tremaining: 20.4s\n",
      "96:\tlearn: 0.2783906\ttotal: 4.9s\tremaining: 20.4s\n",
      "97:\tlearn: 0.2779418\ttotal: 4.95s\tremaining: 20.3s\n",
      "98:\tlearn: 0.2778734\ttotal: 5s\tremaining: 20.2s\n",
      "99:\tlearn: 0.2776569\ttotal: 5.04s\tremaining: 20.2s\n",
      "100:\tlearn: 0.2774035\ttotal: 5.09s\tremaining: 20.1s\n",
      "101:\tlearn: 0.2772964\ttotal: 5.14s\tremaining: 20.1s\n",
      "102:\tlearn: 0.2771681\ttotal: 5.18s\tremaining: 20s\n",
      "103:\tlearn: 0.2770515\ttotal: 5.22s\tremaining: 19.9s\n",
      "104:\tlearn: 0.2769072\ttotal: 5.27s\tremaining: 19.8s\n",
      "105:\tlearn: 0.2767802\ttotal: 5.32s\tremaining: 19.8s\n",
      "106:\tlearn: 0.2767109\ttotal: 5.37s\tremaining: 19.7s\n",
      "107:\tlearn: 0.2766506\ttotal: 5.42s\tremaining: 19.7s\n",
      "108:\tlearn: 0.2765893\ttotal: 5.47s\tremaining: 19.6s\n",
      "109:\tlearn: 0.2764701\ttotal: 5.52s\tremaining: 19.6s\n",
      "110:\tlearn: 0.2763141\ttotal: 5.56s\tremaining: 19.5s\n",
      "111:\tlearn: 0.2763141\ttotal: 5.57s\tremaining: 19.3s\n",
      "112:\tlearn: 0.2762145\ttotal: 5.62s\tremaining: 19.3s\n",
      "113:\tlearn: 0.2760256\ttotal: 5.67s\tremaining: 19.2s\n",
      "114:\tlearn: 0.2758256\ttotal: 5.71s\tremaining: 19.1s\n",
      "115:\tlearn: 0.2758256\ttotal: 5.72s\tremaining: 18.9s\n",
      "116:\tlearn: 0.2747149\ttotal: 5.77s\tremaining: 18.9s\n",
      "117:\tlearn: 0.2742075\ttotal: 5.82s\tremaining: 18.8s\n",
      "118:\tlearn: 0.2741520\ttotal: 5.87s\tremaining: 18.8s\n",
      "119:\tlearn: 0.2740975\ttotal: 5.92s\tremaining: 18.7s\n",
      "120:\tlearn: 0.2739752\ttotal: 5.97s\tremaining: 18.7s\n",
      "121:\tlearn: 0.2737981\ttotal: 6.01s\tremaining: 18.6s\n",
      "122:\tlearn: 0.2736047\ttotal: 6.06s\tremaining: 18.6s\n",
      "123:\tlearn: 0.2734370\ttotal: 6.12s\tremaining: 18.6s\n",
      "124:\tlearn: 0.2732876\ttotal: 6.18s\tremaining: 18.5s\n",
      "125:\tlearn: 0.2731858\ttotal: 6.23s\tremaining: 18.5s\n",
      "126:\tlearn: 0.2730485\ttotal: 6.29s\tremaining: 18.5s\n",
      "127:\tlearn: 0.2727298\ttotal: 6.33s\tremaining: 18.4s\n",
      "128:\tlearn: 0.2726449\ttotal: 6.38s\tremaining: 18.4s\n",
      "129:\tlearn: 0.2720930\ttotal: 6.43s\tremaining: 18.3s\n",
      "130:\tlearn: 0.2719920\ttotal: 6.48s\tremaining: 18.2s\n",
      "131:\tlearn: 0.2717434\ttotal: 6.52s\tremaining: 18.2s\n",
      "132:\tlearn: 0.2708971\ttotal: 6.57s\tremaining: 18.1s\n",
      "133:\tlearn: 0.2707435\ttotal: 6.62s\tremaining: 18.1s\n",
      "134:\tlearn: 0.2705773\ttotal: 6.66s\tremaining: 18s\n",
      "135:\tlearn: 0.2704219\ttotal: 6.71s\tremaining: 18s\n",
      "136:\tlearn: 0.2703115\ttotal: 6.76s\tremaining: 17.9s\n",
      "137:\tlearn: 0.2697704\ttotal: 6.81s\tremaining: 17.9s\n",
      "138:\tlearn: 0.2693695\ttotal: 6.85s\tremaining: 17.8s\n",
      "139:\tlearn: 0.2691309\ttotal: 6.91s\tremaining: 17.8s\n",
      "140:\tlearn: 0.2686117\ttotal: 6.96s\tremaining: 17.7s\n",
      "141:\tlearn: 0.2684840\ttotal: 7.02s\tremaining: 17.7s\n",
      "142:\tlearn: 0.2684430\ttotal: 7.08s\tremaining: 17.7s\n",
      "143:\tlearn: 0.2682500\ttotal: 7.13s\tremaining: 17.6s\n",
      "144:\tlearn: 0.2681388\ttotal: 7.17s\tremaining: 17.6s\n",
      "145:\tlearn: 0.2679753\ttotal: 7.22s\tremaining: 17.5s\n",
      "146:\tlearn: 0.2679377\ttotal: 7.26s\tremaining: 17.4s\n",
      "147:\tlearn: 0.2678457\ttotal: 7.31s\tremaining: 17.4s\n",
      "148:\tlearn: 0.2674127\ttotal: 7.36s\tremaining: 17.3s\n",
      "149:\tlearn: 0.2672913\ttotal: 7.41s\tremaining: 17.3s\n",
      "150:\tlearn: 0.2671261\ttotal: 7.46s\tremaining: 17.2s\n",
      "151:\tlearn: 0.2670559\ttotal: 7.5s\tremaining: 17.2s\n",
      "152:\tlearn: 0.2665789\ttotal: 7.55s\tremaining: 17.1s\n",
      "153:\tlearn: 0.2664403\ttotal: 7.6s\tremaining: 17.1s\n",
      "154:\tlearn: 0.2662129\ttotal: 7.65s\tremaining: 17s\n",
      "155:\tlearn: 0.2660187\ttotal: 7.7s\tremaining: 17s\n",
      "156:\tlearn: 0.2659863\ttotal: 7.75s\tremaining: 16.9s\n",
      "157:\tlearn: 0.2659562\ttotal: 7.8s\tremaining: 16.9s\n",
      "158:\tlearn: 0.2657434\ttotal: 7.85s\tremaining: 16.8s\n",
      "159:\tlearn: 0.2657089\ttotal: 7.9s\tremaining: 16.8s\n",
      "160:\tlearn: 0.2654194\ttotal: 7.96s\tremaining: 16.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161:\tlearn: 0.2652385\ttotal: 8.01s\tremaining: 16.7s\n",
      "162:\tlearn: 0.2650845\ttotal: 8.06s\tremaining: 16.7s\n",
      "163:\tlearn: 0.2649899\ttotal: 8.11s\tremaining: 16.6s\n",
      "164:\tlearn: 0.2647976\ttotal: 8.16s\tremaining: 16.6s\n",
      "165:\tlearn: 0.2647047\ttotal: 8.21s\tremaining: 16.5s\n",
      "166:\tlearn: 0.2645204\ttotal: 8.26s\tremaining: 16.5s\n",
      "167:\tlearn: 0.2643794\ttotal: 8.31s\tremaining: 16.4s\n",
      "168:\tlearn: 0.2637985\ttotal: 8.36s\tremaining: 16.4s\n",
      "169:\tlearn: 0.2637690\ttotal: 8.4s\tremaining: 16.3s\n",
      "170:\tlearn: 0.2637102\ttotal: 8.45s\tremaining: 16.2s\n",
      "171:\tlearn: 0.2635886\ttotal: 8.5s\tremaining: 16.2s\n",
      "172:\tlearn: 0.2635715\ttotal: 8.55s\tremaining: 16.2s\n",
      "173:\tlearn: 0.2632331\ttotal: 8.6s\tremaining: 16.1s\n",
      "174:\tlearn: 0.2630878\ttotal: 8.66s\tremaining: 16.1s\n",
      "175:\tlearn: 0.2629731\ttotal: 8.71s\tremaining: 16s\n",
      "176:\tlearn: 0.2628865\ttotal: 8.76s\tremaining: 16s\n",
      "177:\tlearn: 0.2627557\ttotal: 8.81s\tremaining: 15.9s\n",
      "178:\tlearn: 0.2626330\ttotal: 8.87s\tremaining: 15.9s\n",
      "179:\tlearn: 0.2625266\ttotal: 8.92s\tremaining: 15.9s\n",
      "180:\tlearn: 0.2625072\ttotal: 8.96s\tremaining: 15.8s\n",
      "181:\tlearn: 0.2624013\ttotal: 9.01s\tremaining: 15.7s\n",
      "182:\tlearn: 0.2623067\ttotal: 9.05s\tremaining: 15.7s\n",
      "183:\tlearn: 0.2622423\ttotal: 9.1s\tremaining: 15.6s\n",
      "184:\tlearn: 0.2620868\ttotal: 9.15s\tremaining: 15.6s\n",
      "185:\tlearn: 0.2619957\ttotal: 9.2s\tremaining: 15.5s\n",
      "186:\tlearn: 0.2618624\ttotal: 9.25s\tremaining: 15.5s\n",
      "187:\tlearn: 0.2617625\ttotal: 9.29s\tremaining: 15.4s\n",
      "188:\tlearn: 0.2617159\ttotal: 9.34s\tremaining: 15.4s\n",
      "189:\tlearn: 0.2616314\ttotal: 9.39s\tremaining: 15.3s\n",
      "190:\tlearn: 0.2615838\ttotal: 9.44s\tremaining: 15.3s\n",
      "191:\tlearn: 0.2615120\ttotal: 9.48s\tremaining: 15.2s\n",
      "192:\tlearn: 0.2614110\ttotal: 9.53s\tremaining: 15.2s\n",
      "193:\tlearn: 0.2613588\ttotal: 9.58s\tremaining: 15.1s\n",
      "194:\tlearn: 0.2612797\ttotal: 9.63s\tremaining: 15.1s\n",
      "195:\tlearn: 0.2610073\ttotal: 9.67s\tremaining: 15s\n",
      "196:\tlearn: 0.2609636\ttotal: 9.72s\tremaining: 14.9s\n",
      "197:\tlearn: 0.2609038\ttotal: 9.76s\tremaining: 14.9s\n",
      "198:\tlearn: 0.2607802\ttotal: 9.81s\tremaining: 14.8s\n",
      "199:\tlearn: 0.2606274\ttotal: 9.87s\tremaining: 14.8s\n",
      "200:\tlearn: 0.2604305\ttotal: 9.91s\tremaining: 14.7s\n",
      "201:\tlearn: 0.2603211\ttotal: 9.96s\tremaining: 14.7s\n",
      "202:\tlearn: 0.2602665\ttotal: 10s\tremaining: 14.6s\n",
      "203:\tlearn: 0.2600748\ttotal: 10.1s\tremaining: 14.6s\n",
      "204:\tlearn: 0.2599951\ttotal: 10.1s\tremaining: 14.6s\n",
      "205:\tlearn: 0.2598617\ttotal: 10.2s\tremaining: 14.5s\n",
      "206:\tlearn: 0.2597622\ttotal: 10.2s\tremaining: 14.5s\n",
      "207:\tlearn: 0.2597122\ttotal: 10.3s\tremaining: 14.4s\n",
      "208:\tlearn: 0.2596270\ttotal: 10.3s\tremaining: 14.3s\n",
      "209:\tlearn: 0.2595400\ttotal: 10.4s\tremaining: 14.3s\n",
      "210:\tlearn: 0.2593797\ttotal: 10.4s\tremaining: 14.2s\n",
      "211:\tlearn: 0.2593431\ttotal: 10.4s\tremaining: 14.2s\n",
      "212:\tlearn: 0.2592261\ttotal: 10.5s\tremaining: 14.1s\n",
      "213:\tlearn: 0.2591778\ttotal: 10.5s\tremaining: 14.1s\n",
      "214:\tlearn: 0.2589950\ttotal: 10.6s\tremaining: 14s\n",
      "215:\tlearn: 0.2589250\ttotal: 10.6s\tremaining: 14s\n",
      "216:\tlearn: 0.2588641\ttotal: 10.7s\tremaining: 13.9s\n",
      "217:\tlearn: 0.2588386\ttotal: 10.7s\tremaining: 13.9s\n",
      "218:\tlearn: 0.2587753\ttotal: 10.8s\tremaining: 13.8s\n",
      "219:\tlearn: 0.2585331\ttotal: 10.8s\tremaining: 13.8s\n",
      "220:\tlearn: 0.2584427\ttotal: 10.9s\tremaining: 13.7s\n",
      "221:\tlearn: 0.2582767\ttotal: 10.9s\tremaining: 13.7s\n",
      "222:\tlearn: 0.2581859\ttotal: 11s\tremaining: 13.6s\n",
      "223:\tlearn: 0.2580726\ttotal: 11s\tremaining: 13.6s\n",
      "224:\tlearn: 0.2579876\ttotal: 11.1s\tremaining: 13.5s\n",
      "225:\tlearn: 0.2578991\ttotal: 11.1s\tremaining: 13.5s\n",
      "226:\tlearn: 0.2578554\ttotal: 11.2s\tremaining: 13.5s\n",
      "227:\tlearn: 0.2578256\ttotal: 11.2s\tremaining: 13.4s\n",
      "228:\tlearn: 0.2576900\ttotal: 11.3s\tremaining: 13.4s\n",
      "229:\tlearn: 0.2575819\ttotal: 11.4s\tremaining: 13.3s\n",
      "230:\tlearn: 0.2573538\ttotal: 11.4s\tremaining: 13.3s\n",
      "231:\tlearn: 0.2572894\ttotal: 11.5s\tremaining: 13.2s\n",
      "232:\tlearn: 0.2572601\ttotal: 11.5s\tremaining: 13.2s\n",
      "233:\tlearn: 0.2571213\ttotal: 11.6s\tremaining: 13.1s\n",
      "234:\tlearn: 0.2570756\ttotal: 11.6s\tremaining: 13.1s\n",
      "235:\tlearn: 0.2570094\ttotal: 11.6s\tremaining: 13s\n",
      "236:\tlearn: 0.2569662\ttotal: 11.7s\tremaining: 13s\n",
      "237:\tlearn: 0.2568302\ttotal: 11.8s\tremaining: 12.9s\n",
      "238:\tlearn: 0.2567218\ttotal: 11.8s\tremaining: 12.9s\n",
      "239:\tlearn: 0.2566829\ttotal: 11.9s\tremaining: 12.9s\n",
      "240:\tlearn: 0.2565476\ttotal: 11.9s\tremaining: 12.8s\n",
      "241:\tlearn: 0.2563725\ttotal: 12s\tremaining: 12.8s\n",
      "242:\tlearn: 0.2562882\ttotal: 12s\tremaining: 12.7s\n",
      "243:\tlearn: 0.2562176\ttotal: 12.1s\tremaining: 12.7s\n",
      "244:\tlearn: 0.2561732\ttotal: 12.1s\tremaining: 12.6s\n",
      "245:\tlearn: 0.2560456\ttotal: 12.2s\tremaining: 12.6s\n",
      "246:\tlearn: 0.2559458\ttotal: 12.2s\tremaining: 12.5s\n",
      "247:\tlearn: 0.2559192\ttotal: 12.3s\tremaining: 12.5s\n",
      "248:\tlearn: 0.2558497\ttotal: 12.3s\tremaining: 12.4s\n",
      "249:\tlearn: 0.2557883\ttotal: 12.4s\tremaining: 12.4s\n",
      "250:\tlearn: 0.2557118\ttotal: 12.4s\tremaining: 12.3s\n",
      "251:\tlearn: 0.2556552\ttotal: 12.5s\tremaining: 12.3s\n",
      "252:\tlearn: 0.2555830\ttotal: 12.5s\tremaining: 12.2s\n",
      "253:\tlearn: 0.2555224\ttotal: 12.6s\tremaining: 12.2s\n",
      "254:\tlearn: 0.2553906\ttotal: 12.6s\tremaining: 12.1s\n",
      "255:\tlearn: 0.2553392\ttotal: 12.7s\tremaining: 12.1s\n",
      "256:\tlearn: 0.2552352\ttotal: 12.7s\tremaining: 12s\n",
      "257:\tlearn: 0.2550688\ttotal: 12.8s\tremaining: 12s\n",
      "258:\tlearn: 0.2549603\ttotal: 12.8s\tremaining: 11.9s\n",
      "259:\tlearn: 0.2548982\ttotal: 12.9s\tremaining: 11.9s\n",
      "260:\tlearn: 0.2547329\ttotal: 12.9s\tremaining: 11.8s\n",
      "261:\tlearn: 0.2546550\ttotal: 13s\tremaining: 11.8s\n",
      "262:\tlearn: 0.2545980\ttotal: 13s\tremaining: 11.7s\n",
      "263:\tlearn: 0.2544941\ttotal: 13.1s\tremaining: 11.7s\n",
      "264:\tlearn: 0.2544091\ttotal: 13.1s\tremaining: 11.6s\n",
      "265:\tlearn: 0.2542903\ttotal: 13.2s\tremaining: 11.6s\n",
      "266:\tlearn: 0.2541641\ttotal: 13.2s\tremaining: 11.5s\n",
      "267:\tlearn: 0.2540535\ttotal: 13.3s\tremaining: 11.5s\n",
      "268:\tlearn: 0.2540222\ttotal: 13.3s\tremaining: 11.4s\n",
      "269:\tlearn: 0.2539728\ttotal: 13.4s\tremaining: 11.4s\n",
      "270:\tlearn: 0.2539098\ttotal: 13.4s\tremaining: 11.3s\n",
      "271:\tlearn: 0.2538050\ttotal: 13.5s\tremaining: 11.3s\n",
      "272:\tlearn: 0.2537112\ttotal: 13.5s\tremaining: 11.2s\n",
      "273:\tlearn: 0.2536464\ttotal: 13.6s\tremaining: 11.2s\n",
      "274:\tlearn: 0.2535654\ttotal: 13.6s\tremaining: 11.1s\n",
      "275:\tlearn: 0.2535260\ttotal: 13.7s\tremaining: 11.1s\n",
      "276:\tlearn: 0.2534719\ttotal: 13.7s\tremaining: 11s\n",
      "277:\tlearn: 0.2533077\ttotal: 13.8s\tremaining: 11s\n",
      "278:\tlearn: 0.2531460\ttotal: 13.8s\tremaining: 10.9s\n",
      "279:\tlearn: 0.2531264\ttotal: 13.9s\tremaining: 10.9s\n",
      "280:\tlearn: 0.2529928\ttotal: 13.9s\tremaining: 10.8s\n",
      "281:\tlearn: 0.2529216\ttotal: 13.9s\tremaining: 10.8s\n",
      "282:\tlearn: 0.2528485\ttotal: 14s\tremaining: 10.7s\n",
      "283:\tlearn: 0.2528202\ttotal: 14s\tremaining: 10.7s\n",
      "284:\tlearn: 0.2527617\ttotal: 14.1s\tremaining: 10.6s\n",
      "285:\tlearn: 0.2527154\ttotal: 14.1s\tremaining: 10.6s\n",
      "286:\tlearn: 0.2526442\ttotal: 14.2s\tremaining: 10.5s\n",
      "287:\tlearn: 0.2526304\ttotal: 14.2s\tremaining: 10.5s\n",
      "288:\tlearn: 0.2525823\ttotal: 14.3s\tremaining: 10.4s\n",
      "289:\tlearn: 0.2524922\ttotal: 14.3s\tremaining: 10.4s\n",
      "290:\tlearn: 0.2524450\ttotal: 14.4s\tremaining: 10.3s\n",
      "291:\tlearn: 0.2522963\ttotal: 14.4s\tremaining: 10.3s\n",
      "292:\tlearn: 0.2522031\ttotal: 14.5s\tremaining: 10.2s\n",
      "293:\tlearn: 0.2521483\ttotal: 14.5s\tremaining: 10.2s\n",
      "294:\tlearn: 0.2520233\ttotal: 14.6s\tremaining: 10.1s\n",
      "295:\tlearn: 0.2519644\ttotal: 14.6s\tremaining: 10.1s\n",
      "296:\tlearn: 0.2519244\ttotal: 14.7s\tremaining: 10s\n",
      "297:\tlearn: 0.2518801\ttotal: 14.7s\tremaining: 9.99s\n",
      "298:\tlearn: 0.2518538\ttotal: 14.8s\tremaining: 9.94s\n",
      "299:\tlearn: 0.2517417\ttotal: 14.8s\tremaining: 9.88s\n",
      "300:\tlearn: 0.2516755\ttotal: 14.9s\tremaining: 9.84s\n",
      "301:\tlearn: 0.2515942\ttotal: 14.9s\tremaining: 9.79s\n",
      "302:\tlearn: 0.2514928\ttotal: 15s\tremaining: 9.74s\n",
      "303:\tlearn: 0.2514816\ttotal: 15s\tremaining: 9.69s\n",
      "304:\tlearn: 0.2514664\ttotal: 15.1s\tremaining: 9.64s\n",
      "305:\tlearn: 0.2513789\ttotal: 15.1s\tremaining: 9.59s\n",
      "306:\tlearn: 0.2512671\ttotal: 15.2s\tremaining: 9.54s\n",
      "307:\tlearn: 0.2512076\ttotal: 15.2s\tremaining: 9.49s\n",
      "308:\tlearn: 0.2511208\ttotal: 15.3s\tremaining: 9.44s\n",
      "309:\tlearn: 0.2510936\ttotal: 15.3s\tremaining: 9.39s\n",
      "310:\tlearn: 0.2510734\ttotal: 15.4s\tremaining: 9.33s\n",
      "311:\tlearn: 0.2510308\ttotal: 15.4s\tremaining: 9.28s\n",
      "312:\tlearn: 0.2509815\ttotal: 15.5s\tremaining: 9.24s\n",
      "313:\tlearn: 0.2509524\ttotal: 15.5s\tremaining: 9.19s\n",
      "314:\tlearn: 0.2509021\ttotal: 15.6s\tremaining: 9.14s\n",
      "315:\tlearn: 0.2508338\ttotal: 15.6s\tremaining: 9.09s\n",
      "316:\tlearn: 0.2507823\ttotal: 15.7s\tremaining: 9.04s\n",
      "317:\tlearn: 0.2507354\ttotal: 15.7s\tremaining: 8.99s\n",
      "318:\tlearn: 0.2506620\ttotal: 15.7s\tremaining: 8.94s\n",
      "319:\tlearn: 0.2505736\ttotal: 15.8s\tremaining: 8.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 0.2505005\ttotal: 15.9s\tremaining: 8.84s\n",
      "321:\tlearn: 0.2504451\ttotal: 15.9s\tremaining: 8.78s\n",
      "322:\tlearn: 0.2503853\ttotal: 15.9s\tremaining: 8.73s\n",
      "323:\tlearn: 0.2502919\ttotal: 16s\tremaining: 8.68s\n",
      "324:\tlearn: 0.2502720\ttotal: 16s\tremaining: 8.63s\n",
      "325:\tlearn: 0.2501789\ttotal: 16.1s\tremaining: 8.58s\n",
      "326:\tlearn: 0.2500903\ttotal: 16.1s\tremaining: 8.52s\n",
      "327:\tlearn: 0.2499905\ttotal: 16.2s\tremaining: 8.47s\n",
      "328:\tlearn: 0.2498995\ttotal: 16.2s\tremaining: 8.42s\n",
      "329:\tlearn: 0.2498053\ttotal: 16.3s\tremaining: 8.37s\n",
      "330:\tlearn: 0.2496592\ttotal: 16.3s\tremaining: 8.32s\n",
      "331:\tlearn: 0.2495646\ttotal: 16.4s\tremaining: 8.27s\n",
      "332:\tlearn: 0.2495183\ttotal: 16.4s\tremaining: 8.22s\n",
      "333:\tlearn: 0.2494887\ttotal: 16.4s\tremaining: 8.18s\n",
      "334:\tlearn: 0.2494445\ttotal: 16.5s\tremaining: 8.13s\n",
      "335:\tlearn: 0.2493848\ttotal: 16.5s\tremaining: 8.08s\n",
      "336:\tlearn: 0.2493489\ttotal: 16.6s\tremaining: 8.02s\n",
      "337:\tlearn: 0.2493101\ttotal: 16.6s\tremaining: 7.97s\n",
      "338:\tlearn: 0.2492649\ttotal: 16.7s\tremaining: 7.92s\n",
      "339:\tlearn: 0.2492475\ttotal: 16.7s\tremaining: 7.87s\n",
      "340:\tlearn: 0.2491913\ttotal: 16.8s\tremaining: 7.82s\n",
      "341:\tlearn: 0.2491071\ttotal: 16.8s\tremaining: 7.77s\n",
      "342:\tlearn: 0.2490766\ttotal: 16.9s\tremaining: 7.72s\n",
      "343:\tlearn: 0.2489666\ttotal: 16.9s\tremaining: 7.67s\n",
      "344:\tlearn: 0.2489281\ttotal: 17s\tremaining: 7.62s\n",
      "345:\tlearn: 0.2488772\ttotal: 17s\tremaining: 7.57s\n",
      "346:\tlearn: 0.2488644\ttotal: 17s\tremaining: 7.51s\n",
      "347:\tlearn: 0.2488162\ttotal: 17.1s\tremaining: 7.47s\n",
      "348:\tlearn: 0.2486769\ttotal: 17.1s\tremaining: 7.42s\n",
      "349:\tlearn: 0.2485739\ttotal: 17.2s\tremaining: 7.37s\n",
      "350:\tlearn: 0.2485590\ttotal: 17.2s\tremaining: 7.32s\n",
      "351:\tlearn: 0.2484893\ttotal: 17.3s\tremaining: 7.27s\n",
      "352:\tlearn: 0.2484261\ttotal: 17.3s\tremaining: 7.22s\n",
      "353:\tlearn: 0.2482566\ttotal: 17.4s\tremaining: 7.17s\n",
      "354:\tlearn: 0.2481727\ttotal: 17.4s\tremaining: 7.12s\n",
      "355:\tlearn: 0.2481326\ttotal: 17.5s\tremaining: 7.07s\n",
      "356:\tlearn: 0.2480722\ttotal: 17.5s\tremaining: 7.02s\n",
      "357:\tlearn: 0.2480311\ttotal: 17.6s\tremaining: 6.97s\n",
      "358:\tlearn: 0.2479972\ttotal: 17.6s\tremaining: 6.92s\n",
      "359:\tlearn: 0.2479117\ttotal: 17.7s\tremaining: 6.87s\n",
      "360:\tlearn: 0.2478057\ttotal: 17.7s\tremaining: 6.82s\n",
      "361:\tlearn: 0.2477535\ttotal: 17.8s\tremaining: 6.77s\n",
      "362:\tlearn: 0.2476920\ttotal: 17.8s\tremaining: 6.72s\n",
      "363:\tlearn: 0.2476581\ttotal: 17.9s\tremaining: 6.67s\n",
      "364:\tlearn: 0.2476164\ttotal: 17.9s\tremaining: 6.62s\n",
      "365:\tlearn: 0.2475845\ttotal: 18s\tremaining: 6.58s\n",
      "366:\tlearn: 0.2475751\ttotal: 18s\tremaining: 6.52s\n",
      "367:\tlearn: 0.2475320\ttotal: 18.1s\tremaining: 6.47s\n",
      "368:\tlearn: 0.2474546\ttotal: 18.1s\tremaining: 6.43s\n",
      "369:\tlearn: 0.2473958\ttotal: 18.1s\tremaining: 6.38s\n",
      "370:\tlearn: 0.2473220\ttotal: 18.2s\tremaining: 6.33s\n",
      "371:\tlearn: 0.2472698\ttotal: 18.3s\tremaining: 6.28s\n",
      "372:\tlearn: 0.2471933\ttotal: 18.3s\tremaining: 6.23s\n",
      "373:\tlearn: 0.2471282\ttotal: 18.3s\tremaining: 6.18s\n",
      "374:\tlearn: 0.2470154\ttotal: 18.4s\tremaining: 6.13s\n",
      "375:\tlearn: 0.2469199\ttotal: 18.4s\tremaining: 6.08s\n",
      "376:\tlearn: 0.2468251\ttotal: 18.5s\tremaining: 6.03s\n",
      "377:\tlearn: 0.2468132\ttotal: 18.5s\tremaining: 5.98s\n",
      "378:\tlearn: 0.2467256\ttotal: 18.6s\tremaining: 5.93s\n",
      "379:\tlearn: 0.2466415\ttotal: 18.6s\tremaining: 5.88s\n",
      "380:\tlearn: 0.2464983\ttotal: 18.7s\tremaining: 5.83s\n",
      "381:\tlearn: 0.2463675\ttotal: 18.7s\tremaining: 5.79s\n",
      "382:\tlearn: 0.2462452\ttotal: 18.8s\tremaining: 5.74s\n",
      "383:\tlearn: 0.2462147\ttotal: 18.8s\tremaining: 5.68s\n",
      "384:\tlearn: 0.2461513\ttotal: 18.9s\tremaining: 5.64s\n",
      "385:\tlearn: 0.2460639\ttotal: 18.9s\tremaining: 5.59s\n",
      "386:\tlearn: 0.2459918\ttotal: 19s\tremaining: 5.54s\n",
      "387:\tlearn: 0.2458836\ttotal: 19s\tremaining: 5.49s\n",
      "388:\tlearn: 0.2457969\ttotal: 19.1s\tremaining: 5.44s\n",
      "389:\tlearn: 0.2457666\ttotal: 19.1s\tremaining: 5.39s\n",
      "390:\tlearn: 0.2457083\ttotal: 19.2s\tremaining: 5.34s\n",
      "391:\tlearn: 0.2456958\ttotal: 19.2s\tremaining: 5.29s\n",
      "392:\tlearn: 0.2455836\ttotal: 19.3s\tremaining: 5.24s\n",
      "393:\tlearn: 0.2455590\ttotal: 19.3s\tremaining: 5.19s\n",
      "394:\tlearn: 0.2455174\ttotal: 19.3s\tremaining: 5.14s\n",
      "395:\tlearn: 0.2454279\ttotal: 19.4s\tremaining: 5.09s\n",
      "396:\tlearn: 0.2454068\ttotal: 19.4s\tremaining: 5.04s\n",
      "397:\tlearn: 0.2453445\ttotal: 19.5s\tremaining: 5s\n",
      "398:\tlearn: 0.2453264\ttotal: 19.5s\tremaining: 4.95s\n",
      "399:\tlearn: 0.2452739\ttotal: 19.6s\tremaining: 4.9s\n",
      "400:\tlearn: 0.2452338\ttotal: 19.6s\tremaining: 4.85s\n",
      "401:\tlearn: 0.2452092\ttotal: 19.7s\tremaining: 4.8s\n",
      "402:\tlearn: 0.2451580\ttotal: 19.7s\tremaining: 4.75s\n",
      "403:\tlearn: 0.2450221\ttotal: 19.8s\tremaining: 4.7s\n",
      "404:\tlearn: 0.2449058\ttotal: 19.8s\tremaining: 4.65s\n",
      "405:\tlearn: 0.2448272\ttotal: 19.9s\tremaining: 4.6s\n",
      "406:\tlearn: 0.2447261\ttotal: 19.9s\tremaining: 4.55s\n",
      "407:\tlearn: 0.2446892\ttotal: 20s\tremaining: 4.5s\n",
      "408:\tlearn: 0.2446439\ttotal: 20s\tremaining: 4.45s\n",
      "409:\tlearn: 0.2446086\ttotal: 20.1s\tremaining: 4.4s\n",
      "410:\tlearn: 0.2445263\ttotal: 20.1s\tremaining: 4.35s\n",
      "411:\tlearn: 0.2444474\ttotal: 20.2s\tremaining: 4.3s\n",
      "412:\tlearn: 0.2444135\ttotal: 20.2s\tremaining: 4.25s\n",
      "413:\tlearn: 0.2443399\ttotal: 20.3s\tremaining: 4.21s\n",
      "414:\tlearn: 0.2442952\ttotal: 20.3s\tremaining: 4.16s\n",
      "415:\tlearn: 0.2442448\ttotal: 20.3s\tremaining: 4.11s\n",
      "416:\tlearn: 0.2441078\ttotal: 20.4s\tremaining: 4.06s\n",
      "417:\tlearn: 0.2440421\ttotal: 20.4s\tremaining: 4.01s\n",
      "418:\tlearn: 0.2440114\ttotal: 20.5s\tremaining: 3.96s\n",
      "419:\tlearn: 0.2439471\ttotal: 20.5s\tremaining: 3.91s\n",
      "420:\tlearn: 0.2438940\ttotal: 20.6s\tremaining: 3.86s\n",
      "421:\tlearn: 0.2438407\ttotal: 20.6s\tremaining: 3.81s\n",
      "422:\tlearn: 0.2436595\ttotal: 20.7s\tremaining: 3.76s\n",
      "423:\tlearn: 0.2435816\ttotal: 20.7s\tremaining: 3.71s\n",
      "424:\tlearn: 0.2435135\ttotal: 20.8s\tremaining: 3.67s\n",
      "425:\tlearn: 0.2434692\ttotal: 20.8s\tremaining: 3.62s\n",
      "426:\tlearn: 0.2433974\ttotal: 20.9s\tremaining: 3.57s\n",
      "427:\tlearn: 0.2433331\ttotal: 20.9s\tremaining: 3.52s\n",
      "428:\tlearn: 0.2431967\ttotal: 21s\tremaining: 3.47s\n",
      "429:\tlearn: 0.2431603\ttotal: 21s\tremaining: 3.42s\n",
      "430:\tlearn: 0.2430205\ttotal: 21.1s\tremaining: 3.37s\n",
      "431:\tlearn: 0.2429705\ttotal: 21.1s\tremaining: 3.32s\n",
      "432:\tlearn: 0.2429000\ttotal: 21.1s\tremaining: 3.27s\n",
      "433:\tlearn: 0.2427968\ttotal: 21.2s\tremaining: 3.22s\n",
      "434:\tlearn: 0.2427514\ttotal: 21.2s\tremaining: 3.17s\n",
      "435:\tlearn: 0.2426902\ttotal: 21.3s\tremaining: 3.13s\n",
      "436:\tlearn: 0.2425846\ttotal: 21.3s\tremaining: 3.08s\n",
      "437:\tlearn: 0.2425346\ttotal: 21.4s\tremaining: 3.03s\n",
      "438:\tlearn: 0.2424898\ttotal: 21.4s\tremaining: 2.98s\n",
      "439:\tlearn: 0.2424303\ttotal: 21.5s\tremaining: 2.93s\n",
      "440:\tlearn: 0.2423783\ttotal: 21.5s\tremaining: 2.88s\n",
      "441:\tlearn: 0.2423518\ttotal: 21.6s\tremaining: 2.83s\n",
      "442:\tlearn: 0.2422994\ttotal: 21.6s\tremaining: 2.78s\n",
      "443:\tlearn: 0.2422643\ttotal: 21.7s\tremaining: 2.73s\n",
      "444:\tlearn: 0.2422345\ttotal: 21.7s\tremaining: 2.68s\n",
      "445:\tlearn: 0.2421898\ttotal: 21.8s\tremaining: 2.63s\n",
      "446:\tlearn: 0.2421496\ttotal: 21.8s\tremaining: 2.59s\n",
      "447:\tlearn: 0.2420112\ttotal: 21.9s\tremaining: 2.54s\n",
      "448:\tlearn: 0.2419459\ttotal: 21.9s\tremaining: 2.49s\n",
      "449:\tlearn: 0.2419104\ttotal: 22s\tremaining: 2.44s\n",
      "450:\tlearn: 0.2417451\ttotal: 22s\tremaining: 2.39s\n",
      "451:\tlearn: 0.2417220\ttotal: 22.1s\tremaining: 2.34s\n",
      "452:\tlearn: 0.2416986\ttotal: 22.1s\tremaining: 2.29s\n",
      "453:\tlearn: 0.2415618\ttotal: 22.2s\tremaining: 2.24s\n",
      "454:\tlearn: 0.2415463\ttotal: 22.2s\tremaining: 2.19s\n",
      "455:\tlearn: 0.2415363\ttotal: 22.2s\tremaining: 2.15s\n",
      "456:\tlearn: 0.2415043\ttotal: 22.3s\tremaining: 2.1s\n",
      "457:\tlearn: 0.2414928\ttotal: 22.4s\tremaining: 2.05s\n",
      "458:\tlearn: 0.2414483\ttotal: 22.4s\tremaining: 2s\n",
      "459:\tlearn: 0.2413901\ttotal: 22.5s\tremaining: 1.95s\n",
      "460:\tlearn: 0.2413474\ttotal: 22.5s\tremaining: 1.9s\n",
      "461:\tlearn: 0.2413355\ttotal: 22.6s\tremaining: 1.85s\n",
      "462:\tlearn: 0.2412772\ttotal: 22.6s\tremaining: 1.81s\n",
      "463:\tlearn: 0.2411750\ttotal: 22.7s\tremaining: 1.76s\n",
      "464:\tlearn: 0.2411408\ttotal: 22.7s\tremaining: 1.71s\n",
      "465:\tlearn: 0.2410877\ttotal: 22.7s\tremaining: 1.66s\n",
      "466:\tlearn: 0.2410615\ttotal: 22.8s\tremaining: 1.61s\n",
      "467:\tlearn: 0.2410278\ttotal: 22.8s\tremaining: 1.56s\n",
      "468:\tlearn: 0.2410052\ttotal: 22.9s\tremaining: 1.51s\n",
      "469:\tlearn: 0.2409827\ttotal: 22.9s\tremaining: 1.46s\n",
      "470:\tlearn: 0.2408872\ttotal: 23s\tremaining: 1.42s\n",
      "471:\tlearn: 0.2407880\ttotal: 23s\tremaining: 1.37s\n",
      "472:\tlearn: 0.2407363\ttotal: 23.1s\tremaining: 1.32s\n",
      "473:\tlearn: 0.2406912\ttotal: 23.1s\tremaining: 1.27s\n",
      "474:\tlearn: 0.2406696\ttotal: 23.2s\tremaining: 1.22s\n",
      "475:\tlearn: 0.2405861\ttotal: 23.2s\tremaining: 1.17s\n",
      "476:\tlearn: 0.2405224\ttotal: 23.3s\tremaining: 1.12s\n",
      "477:\tlearn: 0.2404329\ttotal: 23.3s\tremaining: 1.07s\n",
      "478:\tlearn: 0.2404254\ttotal: 23.4s\tremaining: 1.03s\n",
      "479:\tlearn: 0.2403593\ttotal: 23.5s\tremaining: 978ms\n",
      "480:\tlearn: 0.2402964\ttotal: 23.5s\tremaining: 929ms\n",
      "481:\tlearn: 0.2402444\ttotal: 23.6s\tremaining: 880ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482:\tlearn: 0.2401675\ttotal: 23.6s\tremaining: 831ms\n",
      "483:\tlearn: 0.2401020\ttotal: 23.7s\tremaining: 783ms\n",
      "484:\tlearn: 0.2400667\ttotal: 23.7s\tremaining: 733ms\n",
      "485:\tlearn: 0.2398963\ttotal: 23.8s\tremaining: 684ms\n",
      "486:\tlearn: 0.2398629\ttotal: 23.8s\tremaining: 635ms\n",
      "487:\tlearn: 0.2397604\ttotal: 23.8s\tremaining: 586ms\n",
      "488:\tlearn: 0.2396820\ttotal: 23.9s\tremaining: 537ms\n",
      "489:\tlearn: 0.2395905\ttotal: 23.9s\tremaining: 489ms\n",
      "490:\tlearn: 0.2395676\ttotal: 24s\tremaining: 440ms\n",
      "491:\tlearn: 0.2395318\ttotal: 24s\tremaining: 391ms\n",
      "492:\tlearn: 0.2395062\ttotal: 24.1s\tremaining: 342ms\n",
      "493:\tlearn: 0.2394881\ttotal: 24.1s\tremaining: 293ms\n",
      "494:\tlearn: 0.2394463\ttotal: 24.2s\tremaining: 244ms\n",
      "495:\tlearn: 0.2393991\ttotal: 24.2s\tremaining: 195ms\n",
      "496:\tlearn: 0.2393504\ttotal: 24.3s\tremaining: 147ms\n",
      "497:\tlearn: 0.2392725\ttotal: 24.3s\tremaining: 97.7ms\n",
      "498:\tlearn: 0.2392005\ttotal: 24.4s\tremaining: 48.9ms\n",
      "499:\tlearn: 0.2391384\ttotal: 24.4s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9252839830499259"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     ,      OHE\n",
    "import catboost\n",
    "boosting_model = catboost.CatBoostClassifier(n_estimators=500, cat_features=cat_cols)\n",
    "boosting_model.fit(x_train_cb, y_train)\n",
    "\n",
    "predict_boosting = boosting_model.predict_proba(x_test_cb)[:, 1]\n",
    "roc_auc_score(y_test, predict_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf973348cb345d48ef860145e9ff535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.9291448662\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "0:\tloss: 0.9291449\tbest: 0.9291449 (0)\ttotal: 25.1s\tremaining: 7m 57s\n",
      "\n",
      "bestTest = 0.9300559287\n",
      "bestIteration = 495\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "1:\tloss: 0.9300559\tbest: 0.9300559 (1)\ttotal: 50.2s\tremaining: 7m 31s\n",
      "\n",
      "bestTest = 0.9302629513\n",
      "bestIteration = 486\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "2:\tloss: 0.9302630\tbest: 0.9302630 (2)\ttotal: 1m 17s\tremaining: 7m 16s\n",
      "\n",
      "bestTest = 0.9299045255\n",
      "bestIteration = 481\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "3:\tloss: 0.9299045\tbest: 0.9302630 (2)\ttotal: 1m 39s\tremaining: 6m 39s\n",
      "\n",
      "bestTest = 0.9300078335\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "4:\tloss: 0.9300078\tbest: 0.9302630 (2)\ttotal: 2m 7s\tremaining: 6m 23s\n",
      "\n",
      "bestTest = 0.9294157446\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "5:\tloss: 0.9294157\tbest: 0.9302630 (2)\ttotal: 2m 36s\tremaining: 6m 4s\n",
      "\n",
      "bestTest = 0.9298775801\n",
      "bestIteration = 497\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "6:\tloss: 0.9298776\tbest: 0.9302630 (2)\ttotal: 3m 6s\tremaining: 5m 47s\n",
      "\n",
      "bestTest = 0.9299028986\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "7:\tloss: 0.9299029\tbest: 0.9302630 (2)\ttotal: 3m 37s\tremaining: 5m 26s\n",
      "\n",
      "bestTest = 0.9298506346\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "8:\tloss: 0.9298506\tbest: 0.9302630 (2)\ttotal: 4m 1s\tremaining: 4m 54s\n",
      "\n",
      "bestTest = 0.9303317894\n",
      "bestIteration = 496\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "9:\tloss: 0.9303318\tbest: 0.9303318 (9)\ttotal: 4m 26s\tremaining: 4m 26s\n",
      "\n",
      "bestTest = 0.9297821015\n",
      "bestIteration = 498\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "10:\tloss: 0.9297821\tbest: 0.9303318 (9)\ttotal: 4m 48s\tremaining: 3m 55s\n",
      "\n",
      "bestTest = 0.930164219\n",
      "bestIteration = 496\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "11:\tloss: 0.9301642\tbest: 0.9303318 (9)\ttotal: 5m 10s\tremaining: 3m 27s\n",
      "\n",
      "bestTest = 0.930015663\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "12:\tloss: 0.9300157\tbest: 0.9303318 (9)\ttotal: 5m 33s\tremaining: 2m 59s\n",
      "\n",
      "bestTest = 0.9295224081\n",
      "bestIteration = 496\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "13:\tloss: 0.9295224\tbest: 0.9303318 (9)\ttotal: 5m 55s\tremaining: 2m 32s\n",
      "\n",
      "bestTest = 0.930051353\n",
      "bestIteration = 499\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "14:\tloss: 0.9300514\tbest: 0.9303318 (9)\ttotal: 6m 17s\tremaining: 2m 5s\n",
      "\n",
      "bestTest = 0.9301792678\n",
      "bestIteration = 494\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "15:\tloss: 0.9301793\tbest: 0.9303318 (9)\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "\n",
      "bestTest = 0.9298713775\n",
      "bestIteration = 496\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "16:\tloss: 0.9298714\tbest: 0.9303318 (9)\ttotal: 7m 2s\tremaining: 1m 14s\n",
      "\n",
      "bestTest = 0.9299301492\n",
      "bestIteration = 494\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "17:\tloss: 0.9299301\tbest: 0.9303318 (9)\ttotal: 7m 24s\tremaining: 49.4s\n",
      "\n",
      "bestTest = 0.930027763\n",
      "bestIteration = 495\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "18:\tloss: 0.9300278\tbest: 0.9303318 (9)\ttotal: 7m 46s\tremaining: 24.5s\n",
      "\n",
      "bestTest = 0.9300033595\n",
      "bestIteration = 497\n",
      "\n",
      "Metric AUC is not calculated on train by default. To calculate this metric on train, add hints=skip_train~false to metric parameters.\n",
      "19:\tloss: 0.9300034\tbest: 0.9303318 (9)\ttotal: 8m 8s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.9257641294\n",
      "bestIteration = 499\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.9262952194\n",
      "bestIteration = 499\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.9298154021\n",
      "bestIteration = 494\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'l2_leaf_reg': 0.47368421052631576},\n",
       " 'cv_results': defaultdict(list,\n",
       "             {'iterations': [0,\n",
       "               1,\n",
       "               2,\n",
       "               3,\n",
       "               4,\n",
       "               5,\n",
       "               6,\n",
       "               7,\n",
       "               8,\n",
       "               9,\n",
       "               10,\n",
       "               11,\n",
       "               12,\n",
       "               13,\n",
       "               14,\n",
       "               15,\n",
       "               16,\n",
       "               17,\n",
       "               18,\n",
       "               19,\n",
       "               20,\n",
       "               21,\n",
       "               22,\n",
       "               23,\n",
       "               24,\n",
       "               25,\n",
       "               26,\n",
       "               27,\n",
       "               28,\n",
       "               29,\n",
       "               30,\n",
       "               31,\n",
       "               32,\n",
       "               33,\n",
       "               34,\n",
       "               35,\n",
       "               36,\n",
       "               37,\n",
       "               38,\n",
       "               39,\n",
       "               40,\n",
       "               41,\n",
       "               42,\n",
       "               43,\n",
       "               44,\n",
       "               45,\n",
       "               46,\n",
       "               47,\n",
       "               48,\n",
       "               49,\n",
       "               50,\n",
       "               51,\n",
       "               52,\n",
       "               53,\n",
       "               54,\n",
       "               55,\n",
       "               56,\n",
       "               57,\n",
       "               58,\n",
       "               59,\n",
       "               60,\n",
       "               61,\n",
       "               62,\n",
       "               63,\n",
       "               64,\n",
       "               65,\n",
       "               66,\n",
       "               67,\n",
       "               68,\n",
       "               69,\n",
       "               70,\n",
       "               71,\n",
       "               72,\n",
       "               73,\n",
       "               74,\n",
       "               75,\n",
       "               76,\n",
       "               77,\n",
       "               78,\n",
       "               79,\n",
       "               80,\n",
       "               81,\n",
       "               82,\n",
       "               83,\n",
       "               84,\n",
       "               85,\n",
       "               86,\n",
       "               87,\n",
       "               88,\n",
       "               89,\n",
       "               90,\n",
       "               91,\n",
       "               92,\n",
       "               93,\n",
       "               94,\n",
       "               95,\n",
       "               96,\n",
       "               97,\n",
       "               98,\n",
       "               99,\n",
       "               100,\n",
       "               101,\n",
       "               102,\n",
       "               103,\n",
       "               104,\n",
       "               105,\n",
       "               106,\n",
       "               107,\n",
       "               108,\n",
       "               109,\n",
       "               110,\n",
       "               111,\n",
       "               112,\n",
       "               113,\n",
       "               114,\n",
       "               115,\n",
       "               116,\n",
       "               117,\n",
       "               118,\n",
       "               119,\n",
       "               120,\n",
       "               121,\n",
       "               122,\n",
       "               123,\n",
       "               124,\n",
       "               125,\n",
       "               126,\n",
       "               127,\n",
       "               128,\n",
       "               129,\n",
       "               130,\n",
       "               131,\n",
       "               132,\n",
       "               133,\n",
       "               134,\n",
       "               135,\n",
       "               136,\n",
       "               137,\n",
       "               138,\n",
       "               139,\n",
       "               140,\n",
       "               141,\n",
       "               142,\n",
       "               143,\n",
       "               144,\n",
       "               145,\n",
       "               146,\n",
       "               147,\n",
       "               148,\n",
       "               149,\n",
       "               150,\n",
       "               151,\n",
       "               152,\n",
       "               153,\n",
       "               154,\n",
       "               155,\n",
       "               156,\n",
       "               157,\n",
       "               158,\n",
       "               159,\n",
       "               160,\n",
       "               161,\n",
       "               162,\n",
       "               163,\n",
       "               164,\n",
       "               165,\n",
       "               166,\n",
       "               167,\n",
       "               168,\n",
       "               169,\n",
       "               170,\n",
       "               171,\n",
       "               172,\n",
       "               173,\n",
       "               174,\n",
       "               175,\n",
       "               176,\n",
       "               177,\n",
       "               178,\n",
       "               179,\n",
       "               180,\n",
       "               181,\n",
       "               182,\n",
       "               183,\n",
       "               184,\n",
       "               185,\n",
       "               186,\n",
       "               187,\n",
       "               188,\n",
       "               189,\n",
       "               190,\n",
       "               191,\n",
       "               192,\n",
       "               193,\n",
       "               194,\n",
       "               195,\n",
       "               196,\n",
       "               197,\n",
       "               198,\n",
       "               199,\n",
       "               200,\n",
       "               201,\n",
       "               202,\n",
       "               203,\n",
       "               204,\n",
       "               205,\n",
       "               206,\n",
       "               207,\n",
       "               208,\n",
       "               209,\n",
       "               210,\n",
       "               211,\n",
       "               212,\n",
       "               213,\n",
       "               214,\n",
       "               215,\n",
       "               216,\n",
       "               217,\n",
       "               218,\n",
       "               219,\n",
       "               220,\n",
       "               221,\n",
       "               222,\n",
       "               223,\n",
       "               224,\n",
       "               225,\n",
       "               226,\n",
       "               227,\n",
       "               228,\n",
       "               229,\n",
       "               230,\n",
       "               231,\n",
       "               232,\n",
       "               233,\n",
       "               234,\n",
       "               235,\n",
       "               236,\n",
       "               237,\n",
       "               238,\n",
       "               239,\n",
       "               240,\n",
       "               241,\n",
       "               242,\n",
       "               243,\n",
       "               244,\n",
       "               245,\n",
       "               246,\n",
       "               247,\n",
       "               248,\n",
       "               249,\n",
       "               250,\n",
       "               251,\n",
       "               252,\n",
       "               253,\n",
       "               254,\n",
       "               255,\n",
       "               256,\n",
       "               257,\n",
       "               258,\n",
       "               259,\n",
       "               260,\n",
       "               261,\n",
       "               262,\n",
       "               263,\n",
       "               264,\n",
       "               265,\n",
       "               266,\n",
       "               267,\n",
       "               268,\n",
       "               269,\n",
       "               270,\n",
       "               271,\n",
       "               272,\n",
       "               273,\n",
       "               274,\n",
       "               275,\n",
       "               276,\n",
       "               277,\n",
       "               278,\n",
       "               279,\n",
       "               280,\n",
       "               281,\n",
       "               282,\n",
       "               283,\n",
       "               284,\n",
       "               285,\n",
       "               286,\n",
       "               287,\n",
       "               288,\n",
       "               289,\n",
       "               290,\n",
       "               291,\n",
       "               292,\n",
       "               293,\n",
       "               294,\n",
       "               295,\n",
       "               296,\n",
       "               297,\n",
       "               298,\n",
       "               299,\n",
       "               300,\n",
       "               301,\n",
       "               302,\n",
       "               303,\n",
       "               304,\n",
       "               305,\n",
       "               306,\n",
       "               307,\n",
       "               308,\n",
       "               309,\n",
       "               310,\n",
       "               311,\n",
       "               312,\n",
       "               313,\n",
       "               314,\n",
       "               315,\n",
       "               316,\n",
       "               317,\n",
       "               318,\n",
       "               319,\n",
       "               320,\n",
       "               321,\n",
       "               322,\n",
       "               323,\n",
       "               324,\n",
       "               325,\n",
       "               326,\n",
       "               327,\n",
       "               328,\n",
       "               329,\n",
       "               330,\n",
       "               331,\n",
       "               332,\n",
       "               333,\n",
       "               334,\n",
       "               335,\n",
       "               336,\n",
       "               337,\n",
       "               338,\n",
       "               339,\n",
       "               340,\n",
       "               341,\n",
       "               342,\n",
       "               343,\n",
       "               344,\n",
       "               345,\n",
       "               346,\n",
       "               347,\n",
       "               348,\n",
       "               349,\n",
       "               350,\n",
       "               351,\n",
       "               352,\n",
       "               353,\n",
       "               354,\n",
       "               355,\n",
       "               356,\n",
       "               357,\n",
       "               358,\n",
       "               359,\n",
       "               360,\n",
       "               361,\n",
       "               362,\n",
       "               363,\n",
       "               364,\n",
       "               365,\n",
       "               366,\n",
       "               367,\n",
       "               368,\n",
       "               369,\n",
       "               370,\n",
       "               371,\n",
       "               372,\n",
       "               373,\n",
       "               374,\n",
       "               375,\n",
       "               376,\n",
       "               377,\n",
       "               378,\n",
       "               379,\n",
       "               380,\n",
       "               381,\n",
       "               382,\n",
       "               383,\n",
       "               384,\n",
       "               385,\n",
       "               386,\n",
       "               387,\n",
       "               388,\n",
       "               389,\n",
       "               390,\n",
       "               391,\n",
       "               392,\n",
       "               393,\n",
       "               394,\n",
       "               395,\n",
       "               396,\n",
       "               397,\n",
       "               398,\n",
       "               399,\n",
       "               400,\n",
       "               401,\n",
       "               402,\n",
       "               403,\n",
       "               404,\n",
       "               405,\n",
       "               406,\n",
       "               407,\n",
       "               408,\n",
       "               409,\n",
       "               410,\n",
       "               411,\n",
       "               412,\n",
       "               413,\n",
       "               414,\n",
       "               415,\n",
       "               416,\n",
       "               417,\n",
       "               418,\n",
       "               419,\n",
       "               420,\n",
       "               421,\n",
       "               422,\n",
       "               423,\n",
       "               424,\n",
       "               425,\n",
       "               426,\n",
       "               427,\n",
       "               428,\n",
       "               429,\n",
       "               430,\n",
       "               431,\n",
       "               432,\n",
       "               433,\n",
       "               434,\n",
       "               435,\n",
       "               436,\n",
       "               437,\n",
       "               438,\n",
       "               439,\n",
       "               440,\n",
       "               441,\n",
       "               442,\n",
       "               443,\n",
       "               444,\n",
       "               445,\n",
       "               446,\n",
       "               447,\n",
       "               448,\n",
       "               449,\n",
       "               450,\n",
       "               451,\n",
       "               452,\n",
       "               453,\n",
       "               454,\n",
       "               455,\n",
       "               456,\n",
       "               457,\n",
       "               458,\n",
       "               459,\n",
       "               460,\n",
       "               461,\n",
       "               462,\n",
       "               463,\n",
       "               464,\n",
       "               465,\n",
       "               466,\n",
       "               467,\n",
       "               468,\n",
       "               469,\n",
       "               470,\n",
       "               471,\n",
       "               472,\n",
       "               473,\n",
       "               474,\n",
       "               475,\n",
       "               476,\n",
       "               477,\n",
       "               478,\n",
       "               479,\n",
       "               480,\n",
       "               481,\n",
       "               482,\n",
       "               483,\n",
       "               484,\n",
       "               485,\n",
       "               486,\n",
       "               487,\n",
       "               488,\n",
       "               489,\n",
       "               490,\n",
       "               491,\n",
       "               492,\n",
       "               493,\n",
       "               494,\n",
       "               495,\n",
       "               496,\n",
       "               497,\n",
       "               498,\n",
       "               499],\n",
       "              'test-AUC-mean': [0.873812003566048,\n",
       "               0.8800194539723746,\n",
       "               0.8884779268276083,\n",
       "               0.8903931120923447,\n",
       "               0.894527798191989,\n",
       "               0.8962897423138895,\n",
       "               0.8963203820360718,\n",
       "               0.8971098743216231,\n",
       "               0.8991788049693783,\n",
       "               0.900198700954034,\n",
       "               0.9003363363413693,\n",
       "               0.9007033680542228,\n",
       "               0.9010449876828237,\n",
       "               0.9014078825847909,\n",
       "               0.9015439243981739,\n",
       "               0.901997412007043,\n",
       "               0.9024182471902926,\n",
       "               0.9027460678649978,\n",
       "               0.9031964555213857,\n",
       "               0.9037817282610042,\n",
       "               0.9041371648213344,\n",
       "               0.9043971369218208,\n",
       "               0.9047007966758298,\n",
       "               0.9050788596813736,\n",
       "               0.9054845653343344,\n",
       "               0.90585037877077,\n",
       "               0.9060422855089533,\n",
       "               0.9061968022113257,\n",
       "               0.9063451049485461,\n",
       "               0.9064697410501005,\n",
       "               0.9068643638016899,\n",
       "               0.907086518848886,\n",
       "               0.9071752731436455,\n",
       "               0.9074335481073144,\n",
       "               0.9076728245409761,\n",
       "               0.9078931872683856,\n",
       "               0.9080784672539496,\n",
       "               0.9082594873243837,\n",
       "               0.9083832584578797,\n",
       "               0.9086464821102508,\n",
       "               0.9088136174543674,\n",
       "               0.9090379398729337,\n",
       "               0.9092436633964471,\n",
       "               0.9094484685337255,\n",
       "               0.9096130204279481,\n",
       "               0.9098275158227573,\n",
       "               0.9099598850398675,\n",
       "               0.9101586682761642,\n",
       "               0.910307938537081,\n",
       "               0.9105117890396576,\n",
       "               0.9106473638744083,\n",
       "               0.9108731321734567,\n",
       "               0.9110948651280459,\n",
       "               0.9111983268721993,\n",
       "               0.911289485465101,\n",
       "               0.9115274062588092,\n",
       "               0.9115789598881809,\n",
       "               0.9117196224089859,\n",
       "               0.9118675853065824,\n",
       "               0.9119990475917388,\n",
       "               0.912040742258882,\n",
       "               0.9121105463002679,\n",
       "               0.9122404498427933,\n",
       "               0.9124530751270835,\n",
       "               0.9125377161929563,\n",
       "               0.912648505198669,\n",
       "               0.9127892096716573,\n",
       "               0.9128768777655919,\n",
       "               0.9130962020007803,\n",
       "               0.913165944958522,\n",
       "               0.9132904042390013,\n",
       "               0.9133632639968562,\n",
       "               0.9134761968095079,\n",
       "               0.9135238216379751,\n",
       "               0.9135932464583254,\n",
       "               0.9136835318028242,\n",
       "               0.9137862929794777,\n",
       "               0.9138858401527387,\n",
       "               0.9140082561440387,\n",
       "               0.9141311799008162,\n",
       "               0.9142062579594299,\n",
       "               0.9142652865086953,\n",
       "               0.9144493398613694,\n",
       "               0.9145417893681659,\n",
       "               0.9145797288991108,\n",
       "               0.9146588882891319,\n",
       "               0.9147378416777697,\n",
       "               0.9147873712196944,\n",
       "               0.9148914476652302,\n",
       "               0.9149445248252731,\n",
       "               0.9151641875824917,\n",
       "               0.9153852000358521,\n",
       "               0.9154745902540368,\n",
       "               0.9155325746776359,\n",
       "               0.9156199534514172,\n",
       "               0.9157216986110702,\n",
       "               0.9157561044786782,\n",
       "               0.9158781876633767,\n",
       "               0.9159570131575857,\n",
       "               0.9160421498260817,\n",
       "               0.9160925044568954,\n",
       "               0.916150297355074,\n",
       "               0.9161946615958915,\n",
       "               0.916263218801284,\n",
       "               0.9163644821725514,\n",
       "               0.9164763769497477,\n",
       "               0.9166226518107075,\n",
       "               0.9166680078716491,\n",
       "               0.9167455417141106,\n",
       "               0.9167748094171859,\n",
       "               0.9168504953608304,\n",
       "               0.9169754794242418,\n",
       "               0.9171087506718573,\n",
       "               0.9171554658277757,\n",
       "               0.9174067113060621,\n",
       "               0.917428364418455,\n",
       "               0.917449875406407,\n",
       "               0.9175190974930061,\n",
       "               0.9176104488879302,\n",
       "               0.9176752181226893,\n",
       "               0.9177424816033204,\n",
       "               0.9177752371818872,\n",
       "               0.917814224205682,\n",
       "               0.9178606831335451,\n",
       "               0.9179861368166322,\n",
       "               0.9180579889783743,\n",
       "               0.9181163189394583,\n",
       "               0.9181380242051379,\n",
       "               0.9181857792411431,\n",
       "               0.9182745022064523,\n",
       "               0.9183294161623893,\n",
       "               0.9183800100506515,\n",
       "               0.918399289526772,\n",
       "               0.9185018825081972,\n",
       "               0.9185255632743239,\n",
       "               0.9185761671762984,\n",
       "               0.9186018783133303,\n",
       "               0.9186196246491294,\n",
       "               0.918707700119613,\n",
       "               0.9187655055320039,\n",
       "               0.9187914645640429,\n",
       "               0.9188296767256209,\n",
       "               0.9188933985670813,\n",
       "               0.9189053579142162,\n",
       "               0.9189361618612777,\n",
       "               0.9189502091318106,\n",
       "               0.9189668935222207,\n",
       "               0.9190456902050471,\n",
       "               0.919093766482109,\n",
       "               0.9191357419723903,\n",
       "               0.9191578698401462,\n",
       "               0.9191912615998007,\n",
       "               0.9192332373711686,\n",
       "               0.9192885986530958,\n",
       "               0.9193467298214978,\n",
       "               0.9194547034281214,\n",
       "               0.919512688806244,\n",
       "               0.91966941904847,\n",
       "               0.9196724713216273,\n",
       "               0.9197340480268433,\n",
       "               0.9197460548893351,\n",
       "               0.9197560685897681,\n",
       "               0.9197700206539078,\n",
       "               0.9198333320737139,\n",
       "               0.9198469177765324,\n",
       "               0.9198610549830833,\n",
       "               0.9198795999973376,\n",
       "               0.9199278213502501,\n",
       "               0.9199453728812843,\n",
       "               0.919972899703431,\n",
       "               0.920011491437403,\n",
       "               0.9200670102215535,\n",
       "               0.9201039826387202,\n",
       "               0.9201264668189494,\n",
       "               0.9201424834645827,\n",
       "               0.9201394600555113,\n",
       "               0.9201757311263337,\n",
       "               0.9202552977640727,\n",
       "               0.9203240289796737,\n",
       "               0.9203485426992598,\n",
       "               0.9203644280891362,\n",
       "               0.9203963225821541,\n",
       "               0.9204103498135506,\n",
       "               0.92042631787804,\n",
       "               0.9204665393758714,\n",
       "               0.9204654471551071,\n",
       "               0.9205722846563119,\n",
       "               0.9205926512819249,\n",
       "               0.920615221492239,\n",
       "               0.9206086136485535,\n",
       "               0.9206081135134077,\n",
       "               0.9206156635771343,\n",
       "               0.9206252917555057,\n",
       "               0.9206690999073648,\n",
       "               0.9206798412474564,\n",
       "               0.9206830485281929,\n",
       "               0.9207142100526174,\n",
       "               0.9207225365245377,\n",
       "               0.9207240566236093,\n",
       "               0.9207501356679387,\n",
       "               0.9207603686393879,\n",
       "               0.920766822119651,\n",
       "               0.9208341679176809,\n",
       "               0.9208301597273638,\n",
       "               0.920840804725004,\n",
       "               0.9209038765184349,\n",
       "               0.9210036534858937,\n",
       "               0.9210373300507472,\n",
       "               0.9210425788170236,\n",
       "               0.9210511091880332,\n",
       "               0.9211814503941952,\n",
       "               0.9211960841637491,\n",
       "               0.9211978129052475,\n",
       "               0.9212065114597735,\n",
       "               0.92120937895359,\n",
       "               0.9212207321256377,\n",
       "               0.9212452539616011,\n",
       "               0.9212903123049255,\n",
       "               0.9213439743243174,\n",
       "               0.9213729835213639,\n",
       "               0.9213828281598847,\n",
       "               0.9214055604927841,\n",
       "               0.921410181604268,\n",
       "               0.9214182521175074,\n",
       "               0.9214462101910011,\n",
       "               0.9214587034036809,\n",
       "               0.9214679269870897,\n",
       "               0.9214683662669745,\n",
       "               0.9214912199590378,\n",
       "               0.9215280639078903,\n",
       "               0.9215314567175322,\n",
       "               0.9215544463501301,\n",
       "               0.9215620542650041,\n",
       "               0.9215760082381909,\n",
       "               0.921594386714457,\n",
       "               0.9215914474615595,\n",
       "               0.9216454212880373,\n",
       "               0.9216630400222062,\n",
       "               0.9216839413449117,\n",
       "               0.921691816046159,\n",
       "               0.9217025164998541,\n",
       "               0.9217087864890902,\n",
       "               0.9217300123849007,\n",
       "               0.9217315182598161,\n",
       "               0.9217469771592507,\n",
       "               0.9217467581224735,\n",
       "               0.9217454687662673,\n",
       "               0.9217929022801289,\n",
       "               0.9218016041139993,\n",
       "               0.9218129293647724,\n",
       "               0.9218213399694427,\n",
       "               0.9218582179414927,\n",
       "               0.9218810141396228,\n",
       "               0.9218972515671129,\n",
       "               0.9219188111830565,\n",
       "               0.9219089898513042,\n",
       "               0.9219222673191799,\n",
       "               0.921915365142629,\n",
       "               0.9219206025190397,\n",
       "               0.9219224498322597,\n",
       "               0.9219469491110188,\n",
       "               0.9219357916924036,\n",
       "               0.9219704253046191,\n",
       "               0.9219809721093206,\n",
       "               0.9219875092479999,\n",
       "               0.9220166497827867,\n",
       "               0.9220421460524933,\n",
       "               0.9220688410513832,\n",
       "               0.9220650964500785,\n",
       "               0.922089230936917,\n",
       "               0.9220949694615568,\n",
       "               0.9220946057002873,\n",
       "               0.9221227848894283,\n",
       "               0.9221345964903893,\n",
       "               0.922135034282857,\n",
       "               0.9221370262502976,\n",
       "               0.9221642465064533,\n",
       "               0.9221822801362395,\n",
       "               0.9223687204416665,\n",
       "               0.9224298173788071,\n",
       "               0.9224422913487628,\n",
       "               0.9224577712008654,\n",
       "               0.922463021817629,\n",
       "               0.922473706799846,\n",
       "               0.922497129885636,\n",
       "               0.9224948206650557,\n",
       "               0.9225848879507247,\n",
       "               0.9225978702776109,\n",
       "               0.9226063172537232,\n",
       "               0.9226222130555178,\n",
       "               0.9226545608593293,\n",
       "               0.9226667347927027,\n",
       "               0.9226646897935797,\n",
       "               0.9226783476068375,\n",
       "               0.9226938412790341,\n",
       "               0.9227001355119944,\n",
       "               0.9227155175810763,\n",
       "               0.922756309842932,\n",
       "               0.9227650124732145,\n",
       "               0.9227658135233384,\n",
       "               0.9228034073294075,\n",
       "               0.9228196735682799,\n",
       "               0.922838258596391,\n",
       "               0.9229054085824284,\n",
       "               0.9229109297333872,\n",
       "               0.9229036155189334,\n",
       "               0.9229131667615444,\n",
       "               0.9229018762132615,\n",
       "               0.9229288820939937,\n",
       "               0.9229271332782233,\n",
       "               0.9229410369837461,\n",
       "               0.9230707422547711,\n",
       "               0.9230971470668239,\n",
       "               0.9231017191052623,\n",
       "               0.9231035909784286,\n",
       "               0.923102763295344,\n",
       "               0.9231157194577473,\n",
       "               0.9231257094649176,\n",
       "               0.9231378634762741,\n",
       "               0.9232123087034161,\n",
       "               0.9232152493266109,\n",
       "               0.9232461141523575,\n",
       "               0.9232482030009991,\n",
       "               0.9232651924289913,\n",
       "               0.9232880651412518,\n",
       "               0.9232929252935134,\n",
       "               0.9232851716586316,\n",
       "               0.9233038639213023,\n",
       "               0.9233070511980385,\n",
       "               0.923331605604918,\n",
       "               0.9233706286663647,\n",
       "               0.9233776278295242,\n",
       "               0.9234148844370127,\n",
       "               0.9234217173608384,\n",
       "               0.9234746189705523,\n",
       "               0.9234871108129344,\n",
       "               0.9235383072221574,\n",
       "               0.9235446986056931,\n",
       "               0.9235582556610966,\n",
       "               0.9235644064344545,\n",
       "               0.9236477890929328,\n",
       "               0.9237608936436758,\n",
       "               0.9237551093253348,\n",
       "               0.9237446339869159,\n",
       "               0.9237752719405946,\n",
       "               0.9238356154952237,\n",
       "               0.9238412168554312,\n",
       "               0.9238422996305126,\n",
       "               0.9238526825382692,\n",
       "               0.9239274492641307,\n",
       "               0.9240223965186706,\n",
       "               0.9240743312956928,\n",
       "               0.9241072118524144,\n",
       "               0.9241649069090124,\n",
       "               0.924247121500177,\n",
       "               0.924244739197066,\n",
       "               0.9242901368119849,\n",
       "               0.9243215984666873,\n",
       "               0.924326862446779,\n",
       "               0.924403509601382,\n",
       "               0.9244573004053104,\n",
       "               0.9244727121173227,\n",
       "               0.9244826866588708,\n",
       "               0.9245710840965518,\n",
       "               0.9245747896912269,\n",
       "               0.9245919756573521,\n",
       "               0.9246042257534975,\n",
       "               0.9246240325013381,\n",
       "               0.9247130061022496,\n",
       "               0.9247195195008183,\n",
       "               0.9247305272525009,\n",
       "               0.9247277552344523,\n",
       "               0.9247280682244444,\n",
       "               0.9247773065137452,\n",
       "               0.9248378555017286,\n",
       "               0.9250511071993452,\n",
       "               0.9250866091116673,\n",
       "               0.9251222349597811,\n",
       "               0.925153706569636,\n",
       "               0.9251621673365623,\n",
       "               0.9251677540275599,\n",
       "               0.9251672195061462,\n",
       "               0.9252081716711739,\n",
       "               0.9252260619233411,\n",
       "               0.9253031519768197,\n",
       "               0.9253157666423588,\n",
       "               0.925340748664027,\n",
       "               0.9254308109604077,\n",
       "               0.925503768817506,\n",
       "               0.9255578634995341,\n",
       "               0.9255597972410446,\n",
       "               0.9255865536456572,\n",
       "               0.9256142717882656,\n",
       "               0.9256201776882976,\n",
       "               0.9256274159156584,\n",
       "               0.9257281513300569,\n",
       "               0.9257992239975081,\n",
       "               0.9258111108008618,\n",
       "               0.9258268834632769,\n",
       "               0.9258974803095782,\n",
       "               0.9259390973909482,\n",
       "               0.9259750118096509,\n",
       "               0.9259806724967108,\n",
       "               0.9259896902485595,\n",
       "               0.9260009899672946,\n",
       "               0.9260098090377248,\n",
       "               0.9260580767113759,\n",
       "               0.926081535782114,\n",
       "               0.9261081236869879,\n",
       "               0.9261116002136056,\n",
       "               0.9261211289458604,\n",
       "               0.9261378978613705,\n",
       "               0.9261433194725169,\n",
       "               0.9261812308362365,\n",
       "               0.9261978057668175,\n",
       "               0.926202375322324,\n",
       "               0.9262349688310092,\n",
       "               0.926291449481987,\n",
       "               0.9263016323965872,\n",
       "               0.9262950215546443,\n",
       "               0.9263141808545069,\n",
       "               0.9263663465559295,\n",
       "               0.9264245266334098,\n",
       "               0.9264204798288134,\n",
       "               0.92643147667082,\n",
       "               0.9264391084077883,\n",
       "               0.9264440429894542,\n",
       "               0.9264758541988379,\n",
       "               0.9264814895880988,\n",
       "               0.9264963159722841,\n",
       "               0.9265042168028784,\n",
       "               0.9264943992540841,\n",
       "               0.9265423488196235,\n",
       "               0.9265548918432011,\n",
       "               0.9266690626024806,\n",
       "               0.9266789308991285,\n",
       "               0.9266781015178122,\n",
       "               0.9266957432073913,\n",
       "               0.9266998491573052,\n",
       "               0.926707414452415,\n",
       "               0.9267148038926852,\n",
       "               0.9267188883863177,\n",
       "               0.9267584039935706,\n",
       "               0.9267645048740466,\n",
       "               0.9267885384214956,\n",
       "               0.9267978714705895,\n",
       "               0.9268237782556462,\n",
       "               0.9268229026355748,\n",
       "               0.9268284691234688,\n",
       "               0.926824798190292,\n",
       "               0.9268266459719895,\n",
       "               0.9268521504634809,\n",
       "               0.9268442757505216,\n",
       "               0.9268762954325093,\n",
       "               0.9268925999811506,\n",
       "               0.9268812019757812,\n",
       "               0.9268905884313395,\n",
       "               0.9268859224748219,\n",
       "               0.9269205777307102,\n",
       "               0.9269283304286365,\n",
       "               0.9269698157272123,\n",
       "               0.9269844464985088,\n",
       "               0.9269902802061175,\n",
       "               0.926993876721602,\n",
       "               0.9270173770652311,\n",
       "               0.9270255684457328,\n",
       "               0.9270258108244146,\n",
       "               0.9270185932217871,\n",
       "               0.9270664324373898,\n",
       "               0.9270665533046523,\n",
       "               0.9270703218568825,\n",
       "               0.927073239770618,\n",
       "               0.9271031336059328,\n",
       "               0.9271169655875106,\n",
       "               0.9271205378709827,\n",
       "               0.9271294562001384,\n",
       "               0.9271797125150382,\n",
       "               0.9271751450325457,\n",
       "               0.9271853301607035,\n",
       "               0.927186740618411,\n",
       "               0.9272290189092932,\n",
       "               0.92723069733628,\n",
       "               0.9272466468256262,\n",
       "               0.9272554437370583,\n",
       "               0.9272493675336482,\n",
       "               0.9272533047378725,\n",
       "               0.9272515535797131,\n",
       "               0.9272572887781609,\n",
       "               0.9272629283837216,\n",
       "               0.9272597933188318,\n",
       "               0.9272719432661439,\n",
       "               0.9272647496964256,\n",
       "               0.9272739621124959,\n",
       "               0.9272730393284259,\n",
       "               0.9272735756300549,\n",
       "               0.9272752516443812,\n",
       "               0.9272761016972789,\n",
       "               0.9272732576507744,\n",
       "               0.9272773394389479,\n",
       "               0.9272873773011213],\n",
       "              'test-AUC-std': [0.010421559019781323,\n",
       "               0.00809415034843304,\n",
       "               0.006357763348549722,\n",
       "               0.009103239662340477,\n",
       "               0.0037762070461536826,\n",
       "               0.00515660177378723,\n",
       "               0.0050307696124620264,\n",
       "               0.003875603296191615,\n",
       "               0.0027289647835829793,\n",
       "               0.0026637383115576774,\n",
       "               0.002951462313642657,\n",
       "               0.0031619483925655477,\n",
       "               0.003035152283748897,\n",
       "               0.0030716594183843645,\n",
       "               0.0031638202583973984,\n",
       "               0.0032632492096619312,\n",
       "               0.0032936079498115645,\n",
       "               0.003338654818123191,\n",
       "               0.003250079510703463,\n",
       "               0.0030146808298705894,\n",
       "               0.002838558802284085,\n",
       "               0.002583196005516306,\n",
       "               0.0027920426100138075,\n",
       "               0.0028155610599031053,\n",
       "               0.003071104388643789,\n",
       "               0.0029747357448213375,\n",
       "               0.003085660305000965,\n",
       "               0.0030975315485259978,\n",
       "               0.0030242275994720497,\n",
       "               0.0030568700029515194,\n",
       "               0.0029957940362006687,\n",
       "               0.003177589564909814,\n",
       "               0.0032429758572669228,\n",
       "               0.0032894703976713603,\n",
       "               0.0033233548075283638,\n",
       "               0.0032703181598667834,\n",
       "               0.0033690038029120166,\n",
       "               0.003497989606002467,\n",
       "               0.00358519246792055,\n",
       "               0.003454054133551803,\n",
       "               0.003366367818587663,\n",
       "               0.003372238695270391,\n",
       "               0.003414591161942359,\n",
       "               0.0034355480215860056,\n",
       "               0.0034846114510863275,\n",
       "               0.0035335728319524423,\n",
       "               0.0034633575273900685,\n",
       "               0.003560253854359237,\n",
       "               0.0035921771772430035,\n",
       "               0.0036188206130511823,\n",
       "               0.0035946514747686874,\n",
       "               0.003657607833960845,\n",
       "               0.0035912000707658724,\n",
       "               0.003539515163655677,\n",
       "               0.0035407550706142788,\n",
       "               0.003394346369970418,\n",
       "               0.0034552269981209887,\n",
       "               0.003399338537292479,\n",
       "               0.0034585911146777578,\n",
       "               0.0035291183656246034,\n",
       "               0.003515585580490118,\n",
       "               0.0034963308460330923,\n",
       "               0.0034252635221622765,\n",
       "               0.0034040357571892377,\n",
       "               0.003371012110074739,\n",
       "               0.003382520015248338,\n",
       "               0.0033546379968510216,\n",
       "               0.0033946652857314583,\n",
       "               0.003380892144719627,\n",
       "               0.00336114462191337,\n",
       "               0.0032924651524957973,\n",
       "               0.003239627706375538,\n",
       "               0.003209070234778852,\n",
       "               0.0031887549968014806,\n",
       "               0.0032216559265516925,\n",
       "               0.003223186018120901,\n",
       "               0.0033252793925049903,\n",
       "               0.003267499866976857,\n",
       "               0.0033216898804156593,\n",
       "               0.003360888984154273,\n",
       "               0.0034058254340327905,\n",
       "               0.003410850363970489,\n",
       "               0.0033152283435433673,\n",
       "               0.0032546342737354086,\n",
       "               0.00324154338915566,\n",
       "               0.0032102582386800325,\n",
       "               0.0032478529068121235,\n",
       "               0.0032784746188280187,\n",
       "               0.0032647516012332236,\n",
       "               0.0032256310507327132,\n",
       "               0.0031372687194431265,\n",
       "               0.0030679722305392257,\n",
       "               0.0030238727072219736,\n",
       "               0.0030356605284578885,\n",
       "               0.0030221749112035916,\n",
       "               0.0030201186434089975,\n",
       "               0.003021296837548805,\n",
       "               0.002975734489071607,\n",
       "               0.002978809791388516,\n",
       "               0.003006339043051485,\n",
       "               0.0030281804060585025,\n",
       "               0.003054957727328503,\n",
       "               0.003022414709702548,\n",
       "               0.0030275623833756564,\n",
       "               0.0030538805263693024,\n",
       "               0.0029937119074711803,\n",
       "               0.00300296267102928,\n",
       "               0.0030010397933389527,\n",
       "               0.0029803354276055232,\n",
       "               0.002995251717229459,\n",
       "               0.0029799071561667826,\n",
       "               0.0030501804804056653,\n",
       "               0.0029973339812424684,\n",
       "               0.003057113121420053,\n",
       "               0.0031544971953116284,\n",
       "               0.0031382717534702465,\n",
       "               0.0031381982701066662,\n",
       "               0.0031342851603801203,\n",
       "               0.0031047169809505465,\n",
       "               0.0030723819291731255,\n",
       "               0.0030509286415243463,\n",
       "               0.0030630763913158986,\n",
       "               0.003061297744112532,\n",
       "               0.003113515680531197,\n",
       "               0.003052313924837073,\n",
       "               0.003071432689592003,\n",
       "               0.0031068142043654537,\n",
       "               0.0031096428381674744,\n",
       "               0.003136538504530925,\n",
       "               0.0030877764264953963,\n",
       "               0.0031230592602159955,\n",
       "               0.0031232693832920666,\n",
       "               0.003148160236005838,\n",
       "               0.0030632142822770536,\n",
       "               0.003099098683721773,\n",
       "               0.0030926077166874306,\n",
       "               0.0030688490085656415,\n",
       "               0.0030826151213060524,\n",
       "               0.003094501808308996,\n",
       "               0.003117253290028549,\n",
       "               0.003116631752887505,\n",
       "               0.003131575165370126,\n",
       "               0.0032139987024663915,\n",
       "               0.003217713606052878,\n",
       "               0.0031963203277162243,\n",
       "               0.003187591652041104,\n",
       "               0.0031762230235994194,\n",
       "               0.0031476700468489635,\n",
       "               0.003143773301218359,\n",
       "               0.0031351049708537504,\n",
       "               0.0031170950030157086,\n",
       "               0.0030913649956030003,\n",
       "               0.0030836899854046317,\n",
       "               0.0031005106673142307,\n",
       "               0.0031133711037134447,\n",
       "               0.003026139888574244,\n",
       "               0.0029823515539753437,\n",
       "               0.0029090902564366064,\n",
       "               0.0029179623578436827,\n",
       "               0.0029716704117482597,\n",
       "               0.0029726029321405084,\n",
       "               0.0029718963826750582,\n",
       "               0.0029744033329760448,\n",
       "               0.0029475933008300714,\n",
       "               0.002938676340247155,\n",
       "               0.002955906380912601,\n",
       "               0.002953923192139605,\n",
       "               0.002949762527768582,\n",
       "               0.0029685343006953355,\n",
       "               0.0029686722847365454,\n",
       "               0.0029367990023661306,\n",
       "               0.002951623849654346,\n",
       "               0.0029656245275900377,\n",
       "               0.0029685074009854827,\n",
       "               0.0029671025896102826,\n",
       "               0.002976689978213022,\n",
       "               0.0030110500279274368,\n",
       "               0.002971745819257207,\n",
       "               0.0029464763791825863,\n",
       "               0.0029450064305679997,\n",
       "               0.0029468150597629764,\n",
       "               0.0029705264131030073,\n",
       "               0.0029877366637263525,\n",
       "               0.002978308249124343,\n",
       "               0.0029470179553284515,\n",
       "               0.002951194833424132,\n",
       "               0.0029262204952795936,\n",
       "               0.002908117750441778,\n",
       "               0.002919076400688451,\n",
       "               0.0029297447092100333,\n",
       "               0.0029256746736400657,\n",
       "               0.0029412434338517163,\n",
       "               0.0029553721708574787,\n",
       "               0.0029910034057034573,\n",
       "               0.0029720127994635475,\n",
       "               0.00297089602793202,\n",
       "               0.0029764454970129476,\n",
       "               0.002983490755539718,\n",
       "               0.0029902140412559125,\n",
       "               0.0029864106529618835,\n",
       "               0.0029881874249070746,\n",
       "               0.0029857231698507004,\n",
       "               0.003078187372027768,\n",
       "               0.0030895907505084845,\n",
       "               0.003076554831809592,\n",
       "               0.0030707385184139467,\n",
       "               0.0031933721183594233,\n",
       "               0.0031924651798399617,\n",
       "               0.0031846944911889307,\n",
       "               0.0031807084112079782,\n",
       "               0.0033694837468761785,\n",
       "               0.0033741574634965576,\n",
       "               0.0033900801751395324,\n",
       "               0.0033761198356481777,\n",
       "               0.0033728836020267424,\n",
       "               0.003382504865614401,\n",
       "               0.003373990733438991,\n",
       "               0.003331495345079427,\n",
       "               0.003289914800190174,\n",
       "               0.0032861914558331953,\n",
       "               0.003286525858760713,\n",
       "               0.0033174800790900954,\n",
       "               0.0033270451104514156,\n",
       "               0.003336977720887827,\n",
       "               0.003295738589908975,\n",
       "               0.00329560503673622,\n",
       "               0.003294862759248365,\n",
       "               0.00330414351866323,\n",
       "               0.003335666578501569,\n",
       "               0.003310443444089185,\n",
       "               0.003321469767954019,\n",
       "               0.0032940471800055526,\n",
       "               0.0032951281536332047,\n",
       "               0.0033075547803778278,\n",
       "               0.0033210017686116397,\n",
       "               0.003335604932332863,\n",
       "               0.003409742348241532,\n",
       "               0.0033899324116002773,\n",
       "               0.003380339837127886,\n",
       "               0.003378246900266731,\n",
       "               0.0034100403121685315,\n",
       "               0.003405802184426154,\n",
       "               0.0034415068725330822,\n",
       "               0.00343690570140036,\n",
       "               0.003436406494008432,\n",
       "               0.003437272799541177,\n",
       "               0.0034266163961245615,\n",
       "               0.0034888051768443605,\n",
       "               0.0034926338756773308,\n",
       "               0.0034817789293307725,\n",
       "               0.003484800260573041,\n",
       "               0.0034505466783660292,\n",
       "               0.003436891035207471,\n",
       "               0.0034403922952818164,\n",
       "               0.0034390667210409715,\n",
       "               0.0034300916918384304,\n",
       "               0.003465011743629113,\n",
       "               0.003468347308931164,\n",
       "               0.003463020411803585,\n",
       "               0.003462226434213409,\n",
       "               0.003458499249086993,\n",
       "               0.003453191113411205,\n",
       "               0.0034323127159490226,\n",
       "               0.0034237800668423463,\n",
       "               0.003419718681702331,\n",
       "               0.003408467683036584,\n",
       "               0.003402780748865847,\n",
       "               0.003439647240199402,\n",
       "               0.003432727837219447,\n",
       "               0.003422922231254289,\n",
       "               0.003433573794255171,\n",
       "               0.0034401211786561883,\n",
       "               0.0034163251900193948,\n",
       "               0.0034070978558988223,\n",
       "               0.003408175242362023,\n",
       "               0.0033993899140150044,\n",
       "               0.003386208290365473,\n",
       "               0.003375489062228355,\n",
       "               0.003301610988568821,\n",
       "               0.0032483527507253815,\n",
       "               0.003272962148802975,\n",
       "               0.003260125929464184,\n",
       "               0.003261713730514367,\n",
       "               0.003272656976923062,\n",
       "               0.0032928370095389402,\n",
       "               0.003291815459696427,\n",
       "               0.0032106816448432707,\n",
       "               0.003225787601934603,\n",
       "               0.0032300219902292515,\n",
       "               0.003225588131622899,\n",
       "               0.003210606062686748,\n",
       "               0.003186773229601672,\n",
       "               0.003170391004382409,\n",
       "               0.0031580790589764572,\n",
       "               0.0031538800573988695,\n",
       "               0.0031499745221102693,\n",
       "               0.0031318876906925187,\n",
       "               0.003111808016598528,\n",
       "               0.0031173780039357867,\n",
       "               0.0031123712365475884,\n",
       "               0.0030766548185279545,\n",
       "               0.0031021550910556458,\n",
       "               0.0031144591785300306,\n",
       "               0.003085354886533877,\n",
       "               0.0031046309882661327,\n",
       "               0.003112946930646438,\n",
       "               0.0031060030589580147,\n",
       "               0.0031041877300768163,\n",
       "               0.003112162314873538,\n",
       "               0.003116105070677229,\n",
       "               0.003118972653230741,\n",
       "               0.0030009693469230997,\n",
       "               0.0030454564556482724,\n",
       "               0.0030581133477627165,\n",
       "               0.0030600350326391687,\n",
       "               0.0030536705637625805,\n",
       "               0.003058601050118479,\n",
       "               0.003059964922562912,\n",
       "               0.003065138222359723,\n",
       "               0.0031716056050950553,\n",
       "               0.0031673071059570633,\n",
       "               0.003151369959436007,\n",
       "               0.003142652146114177,\n",
       "               0.00313865941929633,\n",
       "               0.0031381127364873257,\n",
       "               0.003133440830371163,\n",
       "               0.0031316644224897543,\n",
       "               0.003138883881529773,\n",
       "               0.0031559918466140713,\n",
       "               0.0031822334998064424,\n",
       "               0.0031069308509462257,\n",
       "               0.003100620344310277,\n",
       "               0.0030703429029326486,\n",
       "               0.003085771717360364,\n",
       "               0.003148306028102482,\n",
       "               0.0031397726702972004,\n",
       "               0.0031801524004552457,\n",
       "               0.0031734764219451803,\n",
       "               0.003207516677500176,\n",
       "               0.0032146721012510406,\n",
       "               0.003142080629176808,\n",
       "               0.003065612124166647,\n",
       "               0.003068126895561536,\n",
       "               0.003071430038905403,\n",
       "               0.003135773037093337,\n",
       "               0.003080761150402742,\n",
       "               0.003074598877235283,\n",
       "               0.003080720957287585,\n",
       "               0.003102840629036751,\n",
       "               0.003037610859150406,\n",
       "               0.002947919501115914,\n",
       "               0.002910877939303283,\n",
       "               0.0028774793352257053,\n",
       "               0.0028986921431720454,\n",
       "               0.0028285517605039293,\n",
       "               0.002826624423356736,\n",
       "               0.0029231634605137165,\n",
       "               0.0029745192625844044,\n",
       "               0.002983054797406873,\n",
       "               0.0029108587085749007,\n",
       "               0.0029129649312387377,\n",
       "               0.0029213360498424076,\n",
       "               0.002903850832129005,\n",
       "               0.0029504664358028904,\n",
       "               0.0029438550497847514,\n",
       "               0.0029518573055983353,\n",
       "               0.002952171923777935,\n",
       "               0.002937774926223063,\n",
       "               0.0028890798203992855,\n",
       "               0.002884501001814937,\n",
       "               0.0028714582972348053,\n",
       "               0.0028649815063302602,\n",
       "               0.0028501971890624728,\n",
       "               0.0028192363809539027,\n",
       "               0.0027546901996459002,\n",
       "               0.0026931047431997934,\n",
       "               0.0026381373992704093,\n",
       "               0.002605269741093448,\n",
       "               0.0025772665908564843,\n",
       "               0.0025887291517039854,\n",
       "               0.0025670105861349177,\n",
       "               0.0025688270162342033,\n",
       "               0.002613541309528958,\n",
       "               0.0026185825812958204,\n",
       "               0.002562663814977834,\n",
       "               0.002561546911375396,\n",
       "               0.0025349805169716227,\n",
       "               0.0024470108525962322,\n",
       "               0.002400572725442272,\n",
       "               0.002471919943055183,\n",
       "               0.002479388027679676,\n",
       "               0.002454922144398599,\n",
       "               0.0025039773482214774,\n",
       "               0.002501654360354311,\n",
       "               0.00247428539006717,\n",
       "               0.0023964022327771484,\n",
       "               0.0024062218872579876,\n",
       "               0.0024125353962750253,\n",
       "               0.002402184183251416,\n",
       "               0.002332449564319351,\n",
       "               0.0022905425697018985,\n",
       "               0.002366638698561268,\n",
       "               0.0023522993101071418,\n",
       "               0.0023531577684436328,\n",
       "               0.0023388096930110603,\n",
       "               0.0023168453855827715,\n",
       "               0.0022939602585510563,\n",
       "               0.002313105028820782,\n",
       "               0.002297569414080141,\n",
       "               0.0023020365958824856,\n",
       "               0.0023057556388129835,\n",
       "               0.002293142674045541,\n",
       "               0.002300673345710028,\n",
       "               0.0022694390335505723,\n",
       "               0.002260849856462269,\n",
       "               0.0022614345491499053,\n",
       "               0.0022529300057199863,\n",
       "               0.0022116470749021706,\n",
       "               0.0022040202128903413,\n",
       "               0.0022068530971637527,\n",
       "               0.0022392297800106526,\n",
       "               0.002263421521349173,\n",
       "               0.0022159895498602743,\n",
       "               0.002216892420941172,\n",
       "               0.0022081009407040417,\n",
       "               0.002205630798377941,\n",
       "               0.0022078148709054595,\n",
       "               0.002176851140008957,\n",
       "               0.002157237519926936,\n",
       "               0.0021550383817779727,\n",
       "               0.002162155476017279,\n",
       "               0.002173770344653525,\n",
       "               0.0021391200953272235,\n",
       "               0.0021450399458691474,\n",
       "               0.002173233894524062,\n",
       "               0.0021734584596142035,\n",
       "               0.0021583029104823327,\n",
       "               0.002135691767609559,\n",
       "               0.0021273070869372206,\n",
       "               0.0021604298576353917,\n",
       "               0.002164218512217317,\n",
       "               0.002171248821870039,\n",
       "               0.002132596198251884,\n",
       "               0.002133875492898898,\n",
       "               0.002171428316976001,\n",
       "               0.0021686042412085273,\n",
       "               0.0021530677699591206,\n",
       "               0.0021501381367773826,\n",
       "               0.0021519282050488846,\n",
       "               0.002148259108023277,\n",
       "               0.0021505216914163108,\n",
       "               0.002189572460984876,\n",
       "               0.002193665643155781,\n",
       "               0.002241083362887875,\n",
       "               0.0022197130383309676,\n",
       "               0.002228524537235886,\n",
       "               0.0022521995764243027,\n",
       "               0.002257812826289586,\n",
       "               0.0022323264590202022,\n",
       "               0.002225308435780774,\n",
       "               0.0021900101083508765,\n",
       "               0.0021809479761115704,\n",
       "               0.0021826850469610416,\n",
       "               0.002176972390320238,\n",
       "               0.00216160143035515,\n",
       "               0.002161601008654932,\n",
       "               0.0021583096224668916,\n",
       "               0.002164638873252561,\n",
       "               0.002184660935051557,\n",
       "               0.002180961561436533,\n",
       "               0.002186496456819691,\n",
       "               0.0021928887572168023,\n",
       "               0.002180488420346474,\n",
       "               0.0021887283750646035,\n",
       "               0.0021854366939715957,\n",
       "               0.002174760604013676,\n",
       "               0.002126276454585129,\n",
       "               0.0021388243099429395,\n",
       "               0.0021416757646129645,\n",
       "               0.0021458765128924,\n",
       "               0.002197570978846239,\n",
       "               0.002204905943168785,\n",
       "               0.0022303513191425863,\n",
       "               0.00222136184106108,\n",
       "               0.0022237372859127123,\n",
       "               0.0022218762465279927,\n",
       "               0.00221566957134851,\n",
       "               0.0022088785256816155,\n",
       "               0.002212372462263318,\n",
       "               0.002214568128186754,\n",
       "               0.00219676499276662,\n",
       "               0.0022023679158531006,\n",
       "               0.0022038194347520127,\n",
       "               0.0022085321778157895,\n",
       "               0.002217162149161315,\n",
       "               0.002209560176969971,\n",
       "               0.002206759986619456,\n",
       "               0.0022059654350767145,\n",
       "               0.00219750229562853,\n",
       "               0.002194530449103351],\n",
       "              'test-Logloss-mean': [0.6623476644160272,\n",
       "               0.6348938469640015,\n",
       "               0.6080842749892027,\n",
       "               0.5847534954392144,\n",
       "               0.5618103914121414,\n",
       "               0.5417086604890367,\n",
       "               0.5246756591224152,\n",
       "               0.5087767330471799,\n",
       "               0.4932691145617573,\n",
       "               0.47934758914966186,\n",
       "               0.4661931002618427,\n",
       "               0.4538341388681644,\n",
       "               0.4432823384789755,\n",
       "               0.4335536023506246,\n",
       "               0.4247700885889843,\n",
       "               0.4169664621885099,\n",
       "               0.4095036304614718,\n",
       "               0.40316074819557857,\n",
       "               0.3966097351630906,\n",
       "               0.3912411119646279,\n",
       "               0.386560984763997,\n",
       "               0.38210646216059024,\n",
       "               0.3773523661472325,\n",
       "               0.3728634635363039,\n",
       "               0.368864804854436,\n",
       "               0.36562500414621973,\n",
       "               0.3621565438963339,\n",
       "               0.35913209926519224,\n",
       "               0.35625182436065367,\n",
       "               0.35369791032156006,\n",
       "               0.3508584546151692,\n",
       "               0.34849448114171716,\n",
       "               0.34629233621084315,\n",
       "               0.3442940074555434,\n",
       "               0.3424656175258889,\n",
       "               0.34050120789952437,\n",
       "               0.3387179231576934,\n",
       "               0.33718637318913586,\n",
       "               0.3357976685381902,\n",
       "               0.33410130284539913,\n",
       "               0.332843973184968,\n",
       "               0.3315849558322876,\n",
       "               0.3303637671687439,\n",
       "               0.3291478589845825,\n",
       "               0.3280508090825627,\n",
       "               0.3268067841594436,\n",
       "               0.32593798845017763,\n",
       "               0.325026738697007,\n",
       "               0.323994436213605,\n",
       "               0.3229515645478061,\n",
       "               0.32215358070817973,\n",
       "               0.32119262666510073,\n",
       "               0.3201547340139119,\n",
       "               0.31967956911223205,\n",
       "               0.31920307270823534,\n",
       "               0.3183213925062488,\n",
       "               0.3177370766188113,\n",
       "               0.31715685252876896,\n",
       "               0.3165574560189341,\n",
       "               0.3159426535202141,\n",
       "               0.31540580838600446,\n",
       "               0.3149153060918577,\n",
       "               0.3144321467208704,\n",
       "               0.3137741356793149,\n",
       "               0.3133798356964939,\n",
       "               0.3128567889774832,\n",
       "               0.3124134263879636,\n",
       "               0.3119580476992654,\n",
       "               0.3113282475793167,\n",
       "               0.31104679194908114,\n",
       "               0.31067220096133347,\n",
       "               0.3104054266757341,\n",
       "               0.3100345199034058,\n",
       "               0.3097420888389469,\n",
       "               0.30946832368472194,\n",
       "               0.30916497981289087,\n",
       "               0.3089162495779592,\n",
       "               0.3085627778896247,\n",
       "               0.3081734611759203,\n",
       "               0.3078529260367169,\n",
       "               0.3075599651119775,\n",
       "               0.3072984356678788,\n",
       "               0.3068761065677242,\n",
       "               0.306540130738691,\n",
       "               0.30630800133745795,\n",
       "               0.3060070046266258,\n",
       "               0.3057292776191597,\n",
       "               0.30555870260877416,\n",
       "               0.3052874900672742,\n",
       "               0.30507960740456125,\n",
       "               0.30469702266678683,\n",
       "               0.30429176692112087,\n",
       "               0.3040237538982166,\n",
       "               0.3038199769173627,\n",
       "               0.30360735378351683,\n",
       "               0.3033266635900363,\n",
       "               0.3032084990695398,\n",
       "               0.3029111134767928,\n",
       "               0.3027347298888717,\n",
       "               0.302460598660934,\n",
       "               0.3022791291579187,\n",
       "               0.3020846467118096,\n",
       "               0.30196904123078044,\n",
       "               0.3018136437330044,\n",
       "               0.30158060355296756,\n",
       "               0.3013178151083891,\n",
       "               0.3010283911140456,\n",
       "               0.30091949334318496,\n",
       "               0.30074992890718283,\n",
       "               0.3006528893468978,\n",
       "               0.3005033348779354,\n",
       "               0.30026510898148323,\n",
       "               0.30000353306839783,\n",
       "               0.2998880751059336,\n",
       "               0.29946241834599824,\n",
       "               0.2993785541017128,\n",
       "               0.2993209936082634,\n",
       "               0.29913052520915845,\n",
       "               0.29898065021026793,\n",
       "               0.2988273192324376,\n",
       "               0.29868239415875514,\n",
       "               0.2985931723794218,\n",
       "               0.2984781419575735,\n",
       "               0.29836489551311696,\n",
       "               0.298114145437797,\n",
       "               0.2979645828332367,\n",
       "               0.2978194740475712,\n",
       "               0.29774361865742643,\n",
       "               0.2976269919811377,\n",
       "               0.29745006880822755,\n",
       "               0.29733777162761177,\n",
       "               0.29723708947536953,\n",
       "               0.2971724848371609,\n",
       "               0.2969518326265921,\n",
       "               0.2968914523470039,\n",
       "               0.2967547842090854,\n",
       "               0.2966683956986213,\n",
       "               0.29660447605544016,\n",
       "               0.2963679150202987,\n",
       "               0.29622760241716056,\n",
       "               0.2961768343497451,\n",
       "               0.2960792838565114,\n",
       "               0.29595115432998137,\n",
       "               0.2958897023572809,\n",
       "               0.29581871668416887,\n",
       "               0.29575909911897125,\n",
       "               0.29571664583407514,\n",
       "               0.2955806601220948,\n",
       "               0.2954639571457495,\n",
       "               0.295368534407704,\n",
       "               0.2953226151768504,\n",
       "               0.29525535808756614,\n",
       "               0.2951504414621186,\n",
       "               0.29502305669377,\n",
       "               0.2949248769176262,\n",
       "               0.2947585881899712,\n",
       "               0.294628129163248,\n",
       "               0.29439511252348266,\n",
       "               0.2943662028293295,\n",
       "               0.29420202822768504,\n",
       "               0.2941591174995873,\n",
       "               0.29412509373042034,\n",
       "               0.29408942923905146,\n",
       "               0.2939895882798269,\n",
       "               0.29389011269807114,\n",
       "               0.2938199832302798,\n",
       "               0.2937707684980024,\n",
       "               0.2936789128410387,\n",
       "               0.2936426004104799,\n",
       "               0.2935890457185426,\n",
       "               0.29348896302624045,\n",
       "               0.29338207308574776,\n",
       "               0.2933151519398231,\n",
       "               0.2932633156300317,\n",
       "               0.2932298106659734,\n",
       "               0.29322187808464834,\n",
       "               0.293148465210777,\n",
       "               0.2929915792494604,\n",
       "               0.2928539809322613,\n",
       "               0.29280654352899127,\n",
       "               0.2927688685533518,\n",
       "               0.2926855055221081,\n",
       "               0.2926416255106139,\n",
       "               0.29261719271632025,\n",
       "               0.2925192189632377,\n",
       "               0.29250150575546785,\n",
       "               0.29234395896229554,\n",
       "               0.2923006533636441,\n",
       "               0.2922582589420626,\n",
       "               0.29225868630019486,\n",
       "               0.2922255367413357,\n",
       "               0.29217120561325954,\n",
       "               0.2921424185885981,\n",
       "               0.29206647742564157,\n",
       "               0.29204225040156356,\n",
       "               0.29202744490092286,\n",
       "               0.29196383166498246,\n",
       "               0.29190891221247767,\n",
       "               0.29190246943328213,\n",
       "               0.291862928791844,\n",
       "               0.29181432800977497,\n",
       "               0.2918015561920322,\n",
       "               0.291688357802166,\n",
       "               0.2916806213950602,\n",
       "               0.2916405732477403,\n",
       "               0.2915300448390449,\n",
       "               0.2913741877657761,\n",
       "               0.2913085561915069,\n",
       "               0.2912962143344025,\n",
       "               0.2912819449833261,\n",
       "               0.2910550998429905,\n",
       "               0.2910230715076478,\n",
       "               0.291010391736271,\n",
       "               0.29099490416775603,\n",
       "               0.29099372269614443,\n",
       "               0.290974479864154,\n",
       "               0.29092764657447884,\n",
       "               0.2908530546278481,\n",
       "               0.29075723947468707,\n",
       "               0.2906978187311415,\n",
       "               0.29066270844394754,\n",
       "               0.2906287238655252,\n",
       "               0.29062416229738214,\n",
       "               0.29059439063649734,\n",
       "               0.2905408129146529,\n",
       "               0.2905124074891571,\n",
       "               0.2904927505157671,\n",
       "               0.29048357438646527,\n",
       "               0.2904410983957615,\n",
       "               0.290360370343469,\n",
       "               0.2903441666107304,\n",
       "               0.2903065916742442,\n",
       "               0.29028747220570766,\n",
       "               0.29025860379758944,\n",
       "               0.290241012951402,\n",
       "               0.29022782569320776,\n",
       "               0.29013784000672166,\n",
       "               0.2901083369649026,\n",
       "               0.2900714637446948,\n",
       "               0.290055508418749,\n",
       "               0.2900341112994176,\n",
       "               0.290021156835891,\n",
       "               0.28997865770965753,\n",
       "               0.28996999672466267,\n",
       "               0.28993539611823654,\n",
       "               0.28991791998067323,\n",
       "               0.2899113941987905,\n",
       "               0.2898187144322468,\n",
       "               0.28978412621071453,\n",
       "               0.28976410710577055,\n",
       "               0.28973856254594527,\n",
       "               0.2896604238188049,\n",
       "               0.2896104788987694,\n",
       "               0.28958092645122524,\n",
       "               0.2895483641535856,\n",
       "               0.28955763737342516,\n",
       "               0.2895266556703404,\n",
       "               0.2895283685699081,\n",
       "               0.28950902091751624,\n",
       "               0.2894848019593664,\n",
       "               0.28942524791247815,\n",
       "               0.2894287053167383,\n",
       "               0.2893532740742937,\n",
       "               0.28933701115624605,\n",
       "               0.28931931784955583,\n",
       "               0.28927455230383736,\n",
       "               0.28922049609726747,\n",
       "               0.2891730714788968,\n",
       "               0.28917175909608256,\n",
       "               0.2891202687367418,\n",
       "               0.2891072380678968,\n",
       "               0.289111429755865,\n",
       "               0.28906716208693833,\n",
       "               0.2890197936694154,\n",
       "               0.2890175029035597,\n",
       "               0.28900613636357303,\n",
       "               0.28894539769982375,\n",
       "               0.28891367028610276,\n",
       "               0.28859982000408274,\n",
       "               0.2885006163019707,\n",
       "               0.2884669997352691,\n",
       "               0.28844253533528513,\n",
       "               0.28842736829788757,\n",
       "               0.28840321173474653,\n",
       "               0.28835066566685036,\n",
       "               0.2883488915763223,\n",
       "               0.2882121564263957,\n",
       "               0.28818568911946246,\n",
       "               0.28816077982017746,\n",
       "               0.28811468168577786,\n",
       "               0.28804846064260264,\n",
       "               0.28802317164504104,\n",
       "               0.28802159555028717,\n",
       "               0.2880007434401088,\n",
       "               0.287943960962233,\n",
       "               0.2879331351605809,\n",
       "               0.2879052807874573,\n",
       "               0.2878444445812205,\n",
       "               0.2878309435063411,\n",
       "               0.28783176913516134,\n",
       "               0.2877672297761062,\n",
       "               0.28773506641015323,\n",
       "               0.2876955999465347,\n",
       "               0.287593966345541,\n",
       "               0.28758108304197455,\n",
       "               0.287581101186301,\n",
       "               0.287562242497578,\n",
       "               0.2875811933566232,\n",
       "               0.28753005954837374,\n",
       "               0.28752531276936005,\n",
       "               0.28749524702802853,\n",
       "               0.2872985159546347,\n",
       "               0.28725171987546505,\n",
       "               0.28724554563240345,\n",
       "               0.28724000067742667,\n",
       "               0.28723772860899793,\n",
       "               0.2872054150197172,\n",
       "               0.2871829412479517,\n",
       "               0.28715990426964466,\n",
       "               0.28703754667659154,\n",
       "               0.2870331206092544,\n",
       "               0.2869745375888599,\n",
       "               0.2869734520941443,\n",
       "               0.2869450041977277,\n",
       "               0.28690554182194333,\n",
       "               0.2868956832343954,\n",
       "               0.2869023849885442,\n",
       "               0.2868718638443422,\n",
       "               0.28687047076096706,\n",
       "               0.2868245942311331,\n",
       "               0.2867692620123517,\n",
       "               0.2867389692376882,\n",
       "               0.28667102366731156,\n",
       "               0.28663706688686724,\n",
       "               0.28653984848729475,\n",
       "               0.2865195999080263,\n",
       "               0.2864376540569591,\n",
       "               0.2864135281163554,\n",
       "               0.2863812587711983,\n",
       "               0.28637333369582796,\n",
       "               0.28624707466792837,\n",
       "               0.28606030927338294,\n",
       "               0.286062522619462,\n",
       "               0.2860666516870456,\n",
       "               0.286014237236671,\n",
       "               0.28591457737444365,\n",
       "               0.28590532121218715,\n",
       "               0.2859009902271821,\n",
       "               0.2858769362012942,\n",
       "               0.28573586869280015,\n",
       "               0.2855483519052912,\n",
       "               0.2854655819665574,\n",
       "               0.2854048826886903,\n",
       "               0.2852953877546512,\n",
       "               0.2851359733726161,\n",
       "               0.2851411796061023,\n",
       "               0.28505189923107993,\n",
       "               0.28499909479989766,\n",
       "               0.2849930560867972,\n",
       "               0.28487134319726054,\n",
       "               0.284793811776685,\n",
       "               0.28477086404339774,\n",
       "               0.28475139866357974,\n",
       "               0.2845914439982384,\n",
       "               0.28458295391477906,\n",
       "               0.2845565416196207,\n",
       "               0.2845264697275911,\n",
       "               0.2844907809925438,\n",
       "               0.2843322095927676,\n",
       "               0.2843243319763024,\n",
       "               0.2843046891526344,\n",
       "               0.28430577579561217,\n",
       "               0.28430692547210695,\n",
       "               0.2842349202732419,\n",
       "               0.284132515654235,\n",
       "               0.28379760913861524,\n",
       "               0.2837279632779064,\n",
       "               0.2836651078890813,\n",
       "               0.2835997507979261,\n",
       "               0.2835892053120931,\n",
       "               0.28357636215423926,\n",
       "               0.28357774382273954,\n",
       "               0.28351052829410794,\n",
       "               0.2834799815155873,\n",
       "               0.28332206852250647,\n",
       "               0.2833025690331093,\n",
       "               0.2832652105292177,\n",
       "               0.283115553034722,\n",
       "               0.2830044661662335,\n",
       "               0.2829192146769138,\n",
       "               0.2829091207247317,\n",
       "               0.2828543510885431,\n",
       "               0.28280470565356547,\n",
       "               0.2827921481979315,\n",
       "               0.28276884631086197,\n",
       "               0.2826029066931639,\n",
       "               0.2824861756520816,\n",
       "               0.28247234557912493,\n",
       "               0.2824321902270935,\n",
       "               0.2823101727282078,\n",
       "               0.2822353196602803,\n",
       "               0.28216985007459544,\n",
       "               0.2821610552972119,\n",
       "               0.28214335591656764,\n",
       "               0.28212341850188727,\n",
       "               0.28210789600928127,\n",
       "               0.28201813660568187,\n",
       "               0.281956791960994,\n",
       "               0.28191518165499474,\n",
       "               0.2819209709832619,\n",
       "               0.2819103034799308,\n",
       "               0.2818789473134857,\n",
       "               0.2818725443170881,\n",
       "               0.2817981019886385,\n",
       "               0.28175037839055317,\n",
       "               0.28174307136830135,\n",
       "               0.2816923525125696,\n",
       "               0.28159384831167916,\n",
       "               0.2815726389720256,\n",
       "               0.28157798076188983,\n",
       "               0.2815473280424219,\n",
       "               0.2814483800070922,\n",
       "               0.281333302388417,\n",
       "               0.2813373626916758,\n",
       "               0.28130762906511064,\n",
       "               0.2812973165229525,\n",
       "               0.28128969806436976,\n",
       "               0.2812325502663505,\n",
       "               0.2812205952398161,\n",
       "               0.28119032366031305,\n",
       "               0.28117344789607657,\n",
       "               0.28118846289814214,\n",
       "               0.28111768648195173,\n",
       "               0.28109136224743536,\n",
       "               0.28089746395469795,\n",
       "               0.28088149580412447,\n",
       "               0.2808778504303408,\n",
       "               0.2808400665114121,\n",
       "               0.2808303301512369,\n",
       "               0.28081359626225294,\n",
       "               0.2807879639829531,\n",
       "               0.28078285069181425,\n",
       "               0.280705442902567,\n",
       "               0.280701641751768,\n",
       "               0.28066287633453285,\n",
       "               0.28064647567024625,\n",
       "               0.2806014812669525,\n",
       "               0.28059288308728153,\n",
       "               0.2805824787790144,\n",
       "               0.280582112884701,\n",
       "               0.2805786140126964,\n",
       "               0.2805316848034523,\n",
       "               0.28054865958887276,\n",
       "               0.28048725466858687,\n",
       "               0.2804528354940586,\n",
       "               0.280464600187975,\n",
       "               0.2804468700284534,\n",
       "               0.2804488011661865,\n",
       "               0.2803759612328907,\n",
       "               0.280365710186536,\n",
       "               0.28027965463138826,\n",
       "               0.28025447740868253,\n",
       "               0.2802469165805419,\n",
       "               0.2802317446946131,\n",
       "               0.28019391245018127,\n",
       "               0.28018970026272755,\n",
       "               0.2801865226012254,\n",
       "               0.2801926515252524,\n",
       "               0.2800937552976415,\n",
       "               0.2800965109309176,\n",
       "               0.2800944559067962,\n",
       "               0.28008290182511886,\n",
       "               0.2800295990671255,\n",
       "               0.2800089872710258,\n",
       "               0.28000035829935604,\n",
       "               0.2799818656632936,\n",
       "               0.2798885121070523,\n",
       "               0.2798945532715338,\n",
       "               0.2798730077606629,\n",
       "               0.27987452941706514,\n",
       "               0.27979572843567363,\n",
       "               0.27979546749251233,\n",
       "               0.2797488141441684,\n",
       "               0.2797397640946531,\n",
       "               0.27974856998245373,\n",
       "               0.2797384866111774,\n",
       "               0.2797392244903171,\n",
       "               0.27972720894171627,\n",
       "               0.27971806230211066,\n",
       "               0.2797271882090566,\n",
       "               0.2796963383471858,\n",
       "               0.27970272672094537,\n",
       "               0.27968569291122497,\n",
       "               0.2796925916884061,\n",
       "               0.2796863605970234,\n",
       "               0.27968658038658073,\n",
       "               0.27968246425434723,\n",
       "               0.2796799716755937,\n",
       "               0.27967282859091175,\n",
       "               0.2796607074212706],\n",
       "              'test-Logloss-std': [0.0013115109543640942,\n",
       "               0.0010016591881311068,\n",
       "               0.0021299803593698772,\n",
       "               0.0029412610680211435,\n",
       "               0.0019152497268923262,\n",
       "               0.003477155040052285,\n",
       "               0.003771123036838129,\n",
       "               0.0025760119590875863,\n",
       "               0.001570387383754351,\n",
       "               0.0021221383184058906,\n",
       "               0.0031127254794988996,\n",
       "               0.0037472020532248636,\n",
       "               0.0029489852243778053,\n",
       "               0.0035006379727523865,\n",
       "               0.004269235173107009,\n",
       "               0.003546925858203257,\n",
       "               0.0032618542008208255,\n",
       "               0.0031040129495752693,\n",
       "               0.0029755906966806387,\n",
       "               0.003496370833843901,\n",
       "               0.003771764063870052,\n",
       "               0.003071862133368449,\n",
       "               0.002827518765699058,\n",
       "               0.002558015903648784,\n",
       "               0.0027653025307017623,\n",
       "               0.003209747135489345,\n",
       "               0.003059755366581759,\n",
       "               0.0030307060934657475,\n",
       "               0.0028937594601092242,\n",
       "               0.0030059553471650092,\n",
       "               0.0034438702342226312,\n",
       "               0.003708262760057726,\n",
       "               0.0037226078049878795,\n",
       "               0.003858164197923095,\n",
       "               0.0038788694509287076,\n",
       "               0.003822403976934698,\n",
       "               0.003788988768669499,\n",
       "               0.0040632717541773215,\n",
       "               0.004047037271427117,\n",
       "               0.0038865564458841887,\n",
       "               0.00406105460114762,\n",
       "               0.003975394193591689,\n",
       "               0.004061984521582763,\n",
       "               0.003935945527668687,\n",
       "               0.00408224290281271,\n",
       "               0.004193709164428239,\n",
       "               0.003887077100975582,\n",
       "               0.0040671321756405275,\n",
       "               0.004002203232085603,\n",
       "               0.004027535039507649,\n",
       "               0.003937528022702588,\n",
       "               0.003765364107706861,\n",
       "               0.0037701949993520917,\n",
       "               0.0035134606800809004,\n",
       "               0.0034093095643964446,\n",
       "               0.0032775721166122865,\n",
       "               0.003392673080677933,\n",
       "               0.003309416151177236,\n",
       "               0.00343813173473622,\n",
       "               0.0035739043340607584,\n",
       "               0.0037146482649042982,\n",
       "               0.003869878039403615,\n",
       "               0.003837123633296596,\n",
       "               0.0037504490650341,\n",
       "               0.0037593598933300474,\n",
       "               0.003834877817912252,\n",
       "               0.003795551415438128,\n",
       "               0.0038141694594868527,\n",
       "               0.0036256048125299788,\n",
       "               0.0036146986707440267,\n",
       "               0.003371833118470517,\n",
       "               0.0031948990897014955,\n",
       "               0.0031473313220663954,\n",
       "               0.003173908963245855,\n",
       "               0.0032505535684444666,\n",
       "               0.0032387918998732093,\n",
       "               0.003405610701853971,\n",
       "               0.0033481925861997045,\n",
       "               0.0034375034144286916,\n",
       "               0.003488631595875118,\n",
       "               0.0035594625029322304,\n",
       "               0.003630112878238892,\n",
       "               0.0035600930150223365,\n",
       "               0.0035879346049835356,\n",
       "               0.0035887066667705755,\n",
       "               0.003561952589044398,\n",
       "               0.003682961917710416,\n",
       "               0.0037415050183555796,\n",
       "               0.003751688835072692,\n",
       "               0.0037112732164908345,\n",
       "               0.003656683290661708,\n",
       "               0.0035971811153463103,\n",
       "               0.0035144701784039353,\n",
       "               0.0035021287263436642,\n",
       "               0.0034713253157577606,\n",
       "               0.0035409833819998664,\n",
       "               0.003557032783973793,\n",
       "               0.0035290628791797333,\n",
       "               0.0035269565453114483,\n",
       "               0.0035069818231779895,\n",
       "               0.0035804665717686004,\n",
       "               0.003676258116961196,\n",
       "               0.003603443409973585,\n",
       "               0.003594430749084681,\n",
       "               0.0036180255334622596,\n",
       "               0.0034941060508842914,\n",
       "               0.0035459611165020136,\n",
       "               0.0035289894145639172,\n",
       "               0.003467539550243919,\n",
       "               0.003478942553863963,\n",
       "               0.003477333779514954,\n",
       "               0.0035546733952621394,\n",
       "               0.003519505739273079,\n",
       "               0.0035872742266548903,\n",
       "               0.0036551898991436685,\n",
       "               0.0036504905381645647,\n",
       "               0.0036424576696213904,\n",
       "               0.0037289605508572265,\n",
       "               0.003668808259208684,\n",
       "               0.0036407223720687472,\n",
       "               0.003626696010583635,\n",
       "               0.0036581748953965747,\n",
       "               0.0036781510104487445,\n",
       "               0.0037481595617349117,\n",
       "               0.0036654329118477073,\n",
       "               0.003740994156211775,\n",
       "               0.003819228996863813,\n",
       "               0.003846240628761313,\n",
       "               0.003912852066529538,\n",
       "               0.0037867963954638533,\n",
       "               0.0038346846974379456,\n",
       "               0.003828848848658511,\n",
       "               0.003884729929720748,\n",
       "               0.0037800542409861236,\n",
       "               0.0038424671587246875,\n",
       "               0.003850059648138456,\n",
       "               0.003823974297433693,\n",
       "               0.0038510363814351464,\n",
       "               0.0039324887832347605,\n",
       "               0.003957970172759448,\n",
       "               0.003967142741341166,\n",
       "               0.003984147087612099,\n",
       "               0.0041040402486098165,\n",
       "               0.004135983337577306,\n",
       "               0.004127232976646837,\n",
       "               0.00414616683270686,\n",
       "               0.004146441911880916,\n",
       "               0.004093769090529603,\n",
       "               0.004103126434750946,\n",
       "               0.0040955112213506934,\n",
       "               0.0040579372210606205,\n",
       "               0.004019306549718463,\n",
       "               0.004060492896213125,\n",
       "               0.004063459595740729,\n",
       "               0.00406640177559306,\n",
       "               0.003974257775945214,\n",
       "               0.003909871387719529,\n",
       "               0.00387356062837171,\n",
       "               0.0038675648810937344,\n",
       "               0.003963034165691314,\n",
       "               0.003958304497376716,\n",
       "               0.003963038328634771,\n",
       "               0.003971451158461612,\n",
       "               0.003938278596296367,\n",
       "               0.0039361284011982176,\n",
       "               0.003981228909502946,\n",
       "               0.0039821938592957675,\n",
       "               0.004009425918132735,\n",
       "               0.004037937007053526,\n",
       "               0.004043293589116527,\n",
       "               0.003984977351911522,\n",
       "               0.004028995811959972,\n",
       "               0.004043754828606963,\n",
       "               0.004043924415319705,\n",
       "               0.0040623184331884925,\n",
       "               0.004066143565716721,\n",
       "               0.004125521826931405,\n",
       "               0.004065777239041166,\n",
       "               0.004049404286570558,\n",
       "               0.004061026291143564,\n",
       "               0.004047880539721067,\n",
       "               0.0041267853926395285,\n",
       "               0.0041648138155631655,\n",
       "               0.004159704228920546,\n",
       "               0.004109059437867022,\n",
       "               0.004120507005336557,\n",
       "               0.004112384017614347,\n",
       "               0.0040861698776962704,\n",
       "               0.004101927654769563,\n",
       "               0.004104501301310964,\n",
       "               0.004105241012707494,\n",
       "               0.004178903928344085,\n",
       "               0.0042109321706569796,\n",
       "               0.00424921157383655,\n",
       "               0.004217920565633203,\n",
       "               0.004213036096137226,\n",
       "               0.004213389638655508,\n",
       "               0.0042566759534442234,\n",
       "               0.004277141689985283,\n",
       "               0.004277298828080457,\n",
       "               0.004303609347683418,\n",
       "               0.004301165099092365,\n",
       "               0.004420511068213563,\n",
       "               0.004451383890214468,\n",
       "               0.004415793114702382,\n",
       "               0.004416842127582102,\n",
       "               0.0046056858151356135,\n",
       "               0.004631512512576749,\n",
       "               0.0046219353954866284,\n",
       "               0.004619597594155617,\n",
       "               0.004907805024977484,\n",
       "               0.004915745700143516,\n",
       "               0.004932422665999605,\n",
       "               0.004916304452724176,\n",
       "               0.0049065402702571015,\n",
       "               0.004920423602966462,\n",
       "               0.004912749281474992,\n",
       "               0.004829681551063697,\n",
       "               0.004752456396807883,\n",
       "               0.004762326235067734,\n",
       "               0.004763336252716415,\n",
       "               0.004810801813814512,\n",
       "               0.0048299398286055575,\n",
       "               0.004859754024579651,\n",
       "               0.004788585501328364,\n",
       "               0.004794480789104243,\n",
       "               0.004798519503518437,\n",
       "               0.004811002684935053,\n",
       "               0.0048648640316882145,\n",
       "               0.004823373184254342,\n",
       "               0.004842262178369746,\n",
       "               0.004804541275915224,\n",
       "               0.004806754801104985,\n",
       "               0.004834139473228555,\n",
       "               0.004857188674192249,\n",
       "               0.004895879608367383,\n",
       "               0.005012523409115831,\n",
       "               0.004984413218178696,\n",
       "               0.004977654537314329,\n",
       "               0.004969959493679721,\n",
       "               0.005033815470892743,\n",
       "               0.005029307612990321,\n",
       "               0.005085312836991653,\n",
       "               0.005076534273622813,\n",
       "               0.005090070899902747,\n",
       "               0.005109767965162544,\n",
       "               0.005094868720981372,\n",
       "               0.0052098645308500694,\n",
       "               0.0052113976413667405,\n",
       "               0.0051940094590229155,\n",
       "               0.005216468837483145,\n",
       "               0.005179162879826114,\n",
       "               0.005150670919332266,\n",
       "               0.005156099302302962,\n",
       "               0.005154556257261197,\n",
       "               0.005141154734109208,\n",
       "               0.005197412960143254,\n",
       "               0.00520059195858842,\n",
       "               0.005187139268273629,\n",
       "               0.005181390666712566,\n",
       "               0.005173460164949304,\n",
       "               0.005165450636631543,\n",
       "               0.00510895991258753,\n",
       "               0.005103706139416311,\n",
       "               0.005092436493622861,\n",
       "               0.005083509923598994,\n",
       "               0.0050921205948487,\n",
       "               0.005148811059719851,\n",
       "               0.005133867136231719,\n",
       "               0.005107498473906355,\n",
       "               0.005120692197162879,\n",
       "               0.005139956442421676,\n",
       "               0.005109938967127971,\n",
       "               0.005128475132075595,\n",
       "               0.00512931117281788,\n",
       "               0.0051131785705056864,\n",
       "               0.005092336614419071,\n",
       "               0.005073621786776645,\n",
       "               0.00494490070552179,\n",
       "               0.0048621068955624226,\n",
       "               0.0049254122375845,\n",
       "               0.004916614927541803,\n",
       "               0.004910917951961016,\n",
       "               0.004929354851188511,\n",
       "               0.00499390306551877,\n",
       "               0.004999217047154098,\n",
       "               0.004854368182865477,\n",
       "               0.004870201195951345,\n",
       "               0.004879809452763899,\n",
       "               0.00485752083314852,\n",
       "               0.004850473975840023,\n",
       "               0.0048187246678502715,\n",
       "               0.0048010586811774855,\n",
       "               0.0047859373043427494,\n",
       "               0.004778901443335668,\n",
       "               0.0047792313645004655,\n",
       "               0.004748560920176525,\n",
       "               0.00473306492416936,\n",
       "               0.004736956654943771,\n",
       "               0.004734153814815781,\n",
       "               0.004699681333800666,\n",
       "               0.004726121991219411,\n",
       "               0.0047553298644316,\n",
       "               0.004745017843270141,\n",
       "               0.004776655290719953,\n",
       "               0.004774259060101467,\n",
       "               0.004770563368092102,\n",
       "               0.004771138499238872,\n",
       "               0.004806244108916322,\n",
       "               0.004810613223535356,\n",
       "               0.0048123773013252335,\n",
       "               0.004595508226549713,\n",
       "               0.004656021339517965,\n",
       "               0.004674639010955494,\n",
       "               0.004685598880471205,\n",
       "               0.0046739792330891435,\n",
       "               0.0046829332310692525,\n",
       "               0.004692891819772455,\n",
       "               0.004702572439362752,\n",
       "               0.0048608489676915225,\n",
       "               0.0048513016292817766,\n",
       "               0.004830912037636818,\n",
       "               0.004809217506393632,\n",
       "               0.004811653539920573,\n",
       "               0.004800018045531452,\n",
       "               0.0047974900764475355,\n",
       "               0.004800360439547819,\n",
       "               0.004807340442947099,\n",
       "               0.004825415258392693,\n",
       "               0.004880887897958872,\n",
       "               0.004770976433520883,\n",
       "               0.004763777518388843,\n",
       "               0.0047010811544368316,\n",
       "               0.004757416239693105,\n",
       "               0.004859252928267222,\n",
       "               0.004850375518807077,\n",
       "               0.004929578539321152,\n",
       "               0.004913641791934993,\n",
       "               0.004978317388833455,\n",
       "               0.00498684668948585,\n",
       "               0.004851367117451772,\n",
       "               0.00479054989440878,\n",
       "               0.004801091234986268,\n",
       "               0.004798735835205313,\n",
       "               0.004894214115743522,\n",
       "               0.004788903339179957,\n",
       "               0.004780377531274143,\n",
       "               0.004794996290550351,\n",
       "               0.00483499388733219,\n",
       "               0.004679854619404893,\n",
       "               0.004547208098470943,\n",
       "               0.0045275117612462315,\n",
       "               0.004459790587809998,\n",
       "               0.0044990036016315455,\n",
       "               0.004391517131391616,\n",
       "               0.004388796444983709,\n",
       "               0.00456105208552634,\n",
       "               0.004650090108419381,\n",
       "               0.004660206698843068,\n",
       "               0.004591243091185584,\n",
       "               0.004582699001577719,\n",
       "               0.004601674139403734,\n",
       "               0.004578968653511963,\n",
       "               0.004690042607166511,\n",
       "               0.004672760772214724,\n",
       "               0.0047007981085545525,\n",
       "               0.004700737972916256,\n",
       "               0.00468975013606089,\n",
       "               0.004686648016351255,\n",
       "               0.004682560213565385,\n",
       "               0.004662037061095778,\n",
       "               0.004655771503935003,\n",
       "               0.004642471425675061,\n",
       "               0.004607193121444811,\n",
       "               0.004463652614256006,\n",
       "               0.004366039955907685,\n",
       "               0.004264596626144911,\n",
       "               0.004230922088481882,\n",
       "               0.004178547013922308,\n",
       "               0.004193475725929785,\n",
       "               0.004163852259271207,\n",
       "               0.004171387197197928,\n",
       "               0.004252573274577386,\n",
       "               0.004262306441452188,\n",
       "               0.004108785500571321,\n",
       "               0.004106806323409784,\n",
       "               0.00406147491438417,\n",
       "               0.003929640344849016,\n",
       "               0.003883851603733953,\n",
       "               0.003990693311005233,\n",
       "               0.004005746781485223,\n",
       "               0.003963427754460655,\n",
       "               0.004042771699682168,\n",
       "               0.004040452926973823,\n",
       "               0.004003302902947269,\n",
       "               0.0038416513046462077,\n",
       "               0.0038900447616896663,\n",
       "               0.0038902002788860795,\n",
       "               0.0038781497235902806,\n",
       "               0.0037627902562074418,\n",
       "               0.0036670963923623443,\n",
       "               0.0037779890070155984,\n",
       "               0.003754420257707381,\n",
       "               0.0037509775540600075,\n",
       "               0.0037210065722388247,\n",
       "               0.003689864028029636,\n",
       "               0.003630904168012064,\n",
       "               0.003682491943676681,\n",
       "               0.00363518750111484,\n",
       "               0.003643262833609423,\n",
       "               0.0036471752245550667,\n",
       "               0.0036295109090081234,\n",
       "               0.003637398878683389,\n",
       "               0.003563853070477974,\n",
       "               0.003554328517952701,\n",
       "               0.0035710339818066433,\n",
       "               0.0035652937485120043,\n",
       "               0.003529243833609189,\n",
       "               0.0035210353350137997,\n",
       "               0.00352307553587007,\n",
       "               0.0035787903535761784,\n",
       "               0.003643803102656307,\n",
       "               0.003605344171925726,\n",
       "               0.0036075809102214915,\n",
       "               0.003596053005407819,\n",
       "               0.003594147686180247,\n",
       "               0.0035974352388052234,\n",
       "               0.0035207022727856826,\n",
       "               0.0034978798852164906,\n",
       "               0.003470683002943343,\n",
       "               0.0034856856937341067,\n",
       "               0.003506291680985404,\n",
       "               0.0034337161704330035,\n",
       "               0.003424918305053081,\n",
       "               0.0034313879412304843,\n",
       "               0.003431919440068389,\n",
       "               0.0034029666716085165,\n",
       "               0.0033532928603559257,\n",
       "               0.0033374391216816446,\n",
       "               0.003391419481161279,\n",
       "               0.0033889581548833345,\n",
       "               0.0033933419943147536,\n",
       "               0.0033510769384842427,\n",
       "               0.003352602744171213,\n",
       "               0.003413268705641128,\n",
       "               0.003411459032792053,\n",
       "               0.0033701455320395176,\n",
       "               0.0033703707384579173,\n",
       "               0.0033800614636586355,\n",
       "               0.0033814056490175225,\n",
       "               0.0033909796421920085,\n",
       "               0.0034594758802344795,\n",
       "               0.0034556134561181317,\n",
       "               0.0035273175930561397,\n",
       "               0.003473654146852363,\n",
       "               0.003485684044979254,\n",
       "               0.003519162651895951,\n",
       "               0.0035232614006825277,\n",
       "               0.003466026789659378,\n",
       "               0.0034568898848858537,\n",
       "               0.0034269406199632724,\n",
       "               0.00341429753123705,\n",
       "               0.003420921535053618,\n",
       "               0.003418094615376551,\n",
       "               0.0033839765799683146,\n",
       "               0.003384115131089798,\n",
       "               0.0033791295669679195,\n",
       "               0.0033988979049626206,\n",
       "               0.003460619518584093,\n",
       "               0.0034477184426783213,\n",
       "               0.0034605035188751566,\n",
       "               0.003474697033134856,\n",
       "               0.003452761729390193,\n",
       "               0.0034664425631993944,\n",
       "               0.0034565970276963726,\n",
       "               0.0034329970376126306,\n",
       "               0.0033544922969373802,\n",
       "               0.003372707948179716,\n",
       "               0.003394675445897311,\n",
       "               0.003396536283112787,\n",
       "               0.003485929266538266,\n",
       "               0.003492139405523891,\n",
       "               0.003545862621097546,\n",
       "               0.0035325886965974773,\n",
       "               0.0035318578254541874,\n",
       "               0.0035299067345652482,\n",
       "               0.0035250767432926594,\n",
       "               0.0035170015572434286,\n",
       "               0.003522538718068428,\n",
       "               0.0035302531151566517,\n",
       "               0.003492570852175334,\n",
       "               0.003494972216204033,\n",
       "               0.0035048847745962606,\n",
       "               0.0035135908420893735,\n",
       "               0.003524195682755957,\n",
       "               0.003519421857816812,\n",
       "               0.003512462667804089,\n",
       "               0.0035107496603030263,\n",
       "               0.0034982648245310906,\n",
       "               0.003497892805823179],\n",
       "              'train-Logloss-mean': [0.6624581100410833,\n",
       "               0.6349476298197837,\n",
       "               0.6081552939236555,\n",
       "               0.5846520390070179,\n",
       "               0.561725590744441,\n",
       "               0.5416871733066443,\n",
       "               0.5246727062164057,\n",
       "               0.5087779034488662,\n",
       "               0.492936097899992,\n",
       "               0.47888486025391713,\n",
       "               0.46566814531477624,\n",
       "               0.4533273680256514,\n",
       "               0.44268527279195197,\n",
       "               0.4328445176201327,\n",
       "               0.4239176838099353,\n",
       "               0.4161236325073611,\n",
       "               0.40874135122516764,\n",
       "               0.40220591207235573,\n",
       "               0.3955875336842412,\n",
       "               0.39008927785411857,\n",
       "               0.3852682810476349,\n",
       "               0.38080772848989164,\n",
       "               0.376105393115767,\n",
       "               0.37168143062969206,\n",
       "               0.3675647521573719,\n",
       "               0.36430121554295836,\n",
       "               0.3608572355312228,\n",
       "               0.3577424917827087,\n",
       "               0.35477546942816596,\n",
       "               0.352046094844177,\n",
       "               0.3492344381979731,\n",
       "               0.34688943874052897,\n",
       "               0.3445457406202892,\n",
       "               0.34250682674817573,\n",
       "               0.3406113180889614,\n",
       "               0.33861623314523137,\n",
       "               0.3367915287714745,\n",
       "               0.3352305146641905,\n",
       "               0.3337909557524706,\n",
       "               0.33200699370240394,\n",
       "               0.33065866056342685,\n",
       "               0.3293388927980624,\n",
       "               0.328044998840114,\n",
       "               0.32676708786279907,\n",
       "               0.32559509599253494,\n",
       "               0.32430486100703715,\n",
       "               0.3233120606367344,\n",
       "               0.32230971696676,\n",
       "               0.3212183954179249,\n",
       "               0.32010243063688365,\n",
       "               0.31921365815101715,\n",
       "               0.318199765092033,\n",
       "               0.3171124331565874,\n",
       "               0.3165784080409126,\n",
       "               0.3160877241314671,\n",
       "               0.31515799824758184,\n",
       "               0.31441172671680534,\n",
       "               0.31375584328260514,\n",
       "               0.31304606455077616,\n",
       "               0.31237739510068624,\n",
       "               0.3117523204268866,\n",
       "               0.31115666530659,\n",
       "               0.3106462039931898,\n",
       "               0.30988979699634983,\n",
       "               0.3093572559014602,\n",
       "               0.3087552032626661,\n",
       "               0.3082772797560392,\n",
       "               0.3077456701731604,\n",
       "               0.3070722975434289,\n",
       "               0.30669279022347257,\n",
       "               0.3062890327115937,\n",
       "               0.3059312550894189,\n",
       "               0.3054537937411713,\n",
       "               0.30508192914955296,\n",
       "               0.3046987885357695,\n",
       "               0.30432219460322835,\n",
       "               0.3039829422201421,\n",
       "               0.3035542699348214,\n",
       "               0.30310969836281115,\n",
       "               0.30271109429858994,\n",
       "               0.30238116715026364,\n",
       "               0.3020180854693707,\n",
       "               0.3015319990404747,\n",
       "               0.3011329684132678,\n",
       "               0.30084781122735044,\n",
       "               0.3004808977210925,\n",
       "               0.3000898148495957,\n",
       "               0.29984620412802593,\n",
       "               0.2995042208968416,\n",
       "               0.29922197514646615,\n",
       "               0.29884576075022,\n",
       "               0.2984276986080389,\n",
       "               0.2980608473157908,\n",
       "               0.29779186079942405,\n",
       "               0.29748700457990845,\n",
       "               0.29714007190171493,\n",
       "               0.29689547630803786,\n",
       "               0.2965064169520288,\n",
       "               0.29623536762073366,\n",
       "               0.29591777461143925,\n",
       "               0.2956057791958871,\n",
       "               0.2953264086595478,\n",
       "               0.2951481092902243,\n",
       "               0.2949021010162201,\n",
       "               0.29462601321882004,\n",
       "               0.2943465190977656,\n",
       "               0.2940117730425285,\n",
       "               0.29379447318628177,\n",
       "               0.2935645789208986,\n",
       "               0.29337279855004184,\n",
       "               0.2931621919588198,\n",
       "               0.2928671900868039,\n",
       "               0.2926103644948395,\n",
       "               0.29241633231520553,\n",
       "               0.29199014168182397,\n",
       "               0.2918384994820526,\n",
       "               0.29172571370394634,\n",
       "               0.2914867796955996,\n",
       "               0.2912911714965157,\n",
       "               0.29104689640033565,\n",
       "               0.29087656018462327,\n",
       "               0.290717488326427,\n",
       "               0.29052380613216044,\n",
       "               0.2903427906199141,\n",
       "               0.2900861789061962,\n",
       "               0.28986832651092814,\n",
       "               0.28964991217328667,\n",
       "               0.28946858965207833,\n",
       "               0.28928805207218783,\n",
       "               0.2890690973289491,\n",
       "               0.28889814472561864,\n",
       "               0.2887031342976271,\n",
       "               0.28858663615103924,\n",
       "               0.28836880999096987,\n",
       "               0.2882064328435934,\n",
       "               0.2879851495225018,\n",
       "               0.2878381965389128,\n",
       "               0.2877197982285889,\n",
       "               0.2874068246417689,\n",
       "               0.28720529296486913,\n",
       "               0.2870822058280668,\n",
       "               0.28693003038167586,\n",
       "               0.28672779547630517,\n",
       "               0.2865959258916891,\n",
       "               0.2864450696700646,\n",
       "               0.2863230816714409,\n",
       "               0.28620799219922943,\n",
       "               0.28598472613596554,\n",
       "               0.28580478518389096,\n",
       "               0.28566232358137517,\n",
       "               0.28553566011098624,\n",
       "               0.285391444408964,\n",
       "               0.28520664696851356,\n",
       "               0.28503676927072363,\n",
       "               0.2849006693218303,\n",
       "               0.28466176231077633,\n",
       "               0.2844981411656754,\n",
       "               0.2842254530454701,\n",
       "               0.28411472038289687,\n",
       "               0.28385895620068524,\n",
       "               0.2837770254830714,\n",
       "               0.2836701114097077,\n",
       "               0.28357532678568553,\n",
       "               0.28344482798610926,\n",
       "               0.2832771768605434,\n",
       "               0.28315664973890103,\n",
       "               0.2830431445160427,\n",
       "               0.2828623162356437,\n",
       "               0.2827518961225851,\n",
       "               0.2826284956848391,\n",
       "               0.2824803570674291,\n",
       "               0.28229921410018116,\n",
       "               0.28217061289818585,\n",
       "               0.2820615076708735,\n",
       "               0.28199557759296745,\n",
       "               0.28192858390922537,\n",
       "               0.28181156873696583,\n",
       "               0.2816293071546254,\n",
       "               0.2814528956140718,\n",
       "               0.2813680652132251,\n",
       "               0.28125916106992094,\n",
       "               0.2811107930748254,\n",
       "               0.2809597925515663,\n",
       "               0.2808511894888088,\n",
       "               0.2807217045062869,\n",
       "               0.28063390568469654,\n",
       "               0.28044998638469215,\n",
       "               0.2803525504693361,\n",
       "               0.28026280236528134,\n",
       "               0.28014904849891026,\n",
       "               0.2800380935741515,\n",
       "               0.2799373809358611,\n",
       "               0.27987715763171306,\n",
       "               0.27974749512426583,\n",
       "               0.27965829233926115,\n",
       "               0.2795845465024472,\n",
       "               0.2795027533904633,\n",
       "               0.2793839021403317,\n",
       "               0.2792822943414491,\n",
       "               0.2791692670072349,\n",
       "               0.27905851470576987,\n",
       "               0.27898614162373264,\n",
       "               0.27880469630398824,\n",
       "               0.2787451396326238,\n",
       "               0.27866099753070483,\n",
       "               0.27852175593144574,\n",
       "               0.2783169865908169,\n",
       "               0.27822253166756994,\n",
       "               0.2781419249326423,\n",
       "               0.2780717438280906,\n",
       "               0.2778039084389888,\n",
       "               0.27772784670778233,\n",
       "               0.27764147716806753,\n",
       "               0.2775750688494114,\n",
       "               0.2774880473759854,\n",
       "               0.27742479087999294,\n",
       "               0.2773354918846115,\n",
       "               0.27724058363573545,\n",
       "               0.27712855069315884,\n",
       "               0.277012046330201,\n",
       "               0.27693876594783395,\n",
       "               0.27688754828820444,\n",
       "               0.27678518076334796,\n",
       "               0.27668436814343716,\n",
       "               0.2765832392454445,\n",
       "               0.27649628863662756,\n",
       "               0.27643513566955075,\n",
       "               0.2763888659853387,\n",
       "               0.2763182760679132,\n",
       "               0.2762254680816177,\n",
       "               0.27612964498533676,\n",
       "               0.2760829813208741,\n",
       "               0.2760079494591054,\n",
       "               0.27592641776757687,\n",
       "               0.2758586574299598,\n",
       "               0.27575229838109944,\n",
       "               0.27563876592937336,\n",
       "               0.275536530784196,\n",
       "               0.27544027816906674,\n",
       "               0.27537522456378544,\n",
       "               0.2752842055910604,\n",
       "               0.27526059492109245,\n",
       "               0.27517703289728324,\n",
       "               0.2751042364198108,\n",
       "               0.274996302697538,\n",
       "               0.27491739913564034,\n",
       "               0.27484343464388883,\n",
       "               0.27469590977732583,\n",
       "               0.27459622767289443,\n",
       "               0.2745515027586125,\n",
       "               0.2744891028190744,\n",
       "               0.27435344940764433,\n",
       "               0.27425067337192016,\n",
       "               0.27418551363831284,\n",
       "               0.2741187797271845,\n",
       "               0.27406386973032565,\n",
       "               0.2739899286448904,\n",
       "               0.2739246463040459,\n",
       "               0.2738506776985765,\n",
       "               0.2737620077876386,\n",
       "               0.27365368876937207,\n",
       "               0.27356647581528665,\n",
       "               0.273467540499845,\n",
       "               0.27340664574864637,\n",
       "               0.2733220723515321,\n",
       "               0.273229247532292,\n",
       "               0.27313679014020414,\n",
       "               0.27306668537429907,\n",
       "               0.2730212559589507,\n",
       "               0.2729098046291862,\n",
       "               0.27285785309807314,\n",
       "               0.2727916692005395,\n",
       "               0.27272003820637297,\n",
       "               0.2726152364327004,\n",
       "               0.27254752066016463,\n",
       "               0.2724890061785314,\n",
       "               0.2723907952518671,\n",
       "               0.2723106037530087,\n",
       "               0.2719862500028738,\n",
       "               0.27183367816668996,\n",
       "               0.27173492521254056,\n",
       "               0.27168204569214643,\n",
       "               0.27162178196459946,\n",
       "               0.27154806228040473,\n",
       "               0.27144966009304006,\n",
       "               0.2714126511624151,\n",
       "               0.2712273161719239,\n",
       "               0.27116587458496905,\n",
       "               0.2711081312627332,\n",
       "               0.27102676726436303,\n",
       "               0.27089387462014747,\n",
       "               0.2707831904665771,\n",
       "               0.2707514029315173,\n",
       "               0.27066904575632084,\n",
       "               0.2705811079487965,\n",
       "               0.27050635574616155,\n",
       "               0.2704171125536489,\n",
       "               0.2702990622116285,\n",
       "               0.27024251156715523,\n",
       "               0.27016764106893293,\n",
       "               0.27004530173600055,\n",
       "               0.26995223851571654,\n",
       "               0.26986033164703277,\n",
       "               0.269701907575701,\n",
       "               0.2696447915291498,\n",
       "               0.2695821781287458,\n",
       "               0.26951865368093797,\n",
       "               0.2694451629035852,\n",
       "               0.2693234756936369,\n",
       "               0.2692479298397679,\n",
       "               0.26918459720358434,\n",
       "               0.26896577790412407,\n",
       "               0.26884803011830716,\n",
       "               0.2688099523047878,\n",
       "               0.2687544189912902,\n",
       "               0.2686768364487081,\n",
       "               0.268567513650281,\n",
       "               0.26849660750903354,\n",
       "               0.2684009086623391,\n",
       "               0.2682200318262602,\n",
       "               0.268136994782185,\n",
       "               0.2680359815301461,\n",
       "               0.26798797171226757,\n",
       "               0.2679189046862148,\n",
       "               0.26780865836055806,\n",
       "               0.26774060456586324,\n",
       "               0.267652381684319,\n",
       "               0.2675808283957047,\n",
       "               0.26751880602017764,\n",
       "               0.2674345219705527,\n",
       "               0.26732570082773593,\n",
       "               0.267257812705559,\n",
       "               0.26713625208963426,\n",
       "               0.26705557592225526,\n",
       "               0.26692070311491245,\n",
       "               0.2668546827562923,\n",
       "               0.26673688283946545,\n",
       "               0.2666597426408785,\n",
       "               0.26658555048824695,\n",
       "               0.2665482873593759,\n",
       "               0.2663795193077265,\n",
       "               0.2661716527713913,\n",
       "               0.2660935765248739,\n",
       "               0.2660197063132878,\n",
       "               0.2659118888766095,\n",
       "               0.26576887064354066,\n",
       "               0.2656832513629422,\n",
       "               0.2656149590096683,\n",
       "               0.26554443583930015,\n",
       "               0.2653997127708671,\n",
       "               0.26521119404720417,\n",
       "               0.26508907884293914,\n",
       "               0.2649559531353565,\n",
       "               0.26482432243736326,\n",
       "               0.26467165899872674,\n",
       "               0.2646054517978042,\n",
       "               0.2644348736734759,\n",
       "               0.2643253679349136,\n",
       "               0.26425984762095467,\n",
       "               0.26412697614114006,\n",
       "               0.2639967301045618,\n",
       "               0.2639321849293063,\n",
       "               0.2638728022907377,\n",
       "               0.2636739290843659,\n",
       "               0.2636280601561782,\n",
       "               0.2635744883411036,\n",
       "               0.2634846314019997,\n",
       "               0.2633980267612878,\n",
       "               0.26321862375223826,\n",
       "               0.26315807529654484,\n",
       "               0.2630861505184834,\n",
       "               0.2630351255210726,\n",
       "               0.2629740443022284,\n",
       "               0.26286157246308656,\n",
       "               0.2627278918354968,\n",
       "               0.2624106247886427,\n",
       "               0.2622861774505862,\n",
       "               0.26217964038037866,\n",
       "               0.26210178410390006,\n",
       "               0.2620410602204286,\n",
       "               0.2619392737714926,\n",
       "               0.2618878844817721,\n",
       "               0.2617630902255608,\n",
       "               0.26166062252815053,\n",
       "               0.26149018434261057,\n",
       "               0.26142294259246496,\n",
       "               0.2613319073282378,\n",
       "               0.26117615863966925,\n",
       "               0.2610397443691961,\n",
       "               0.2609211972427519,\n",
       "               0.26085708711682276,\n",
       "               0.2607532172572113,\n",
       "               0.26065536410487095,\n",
       "               0.26056476450677807,\n",
       "               0.26046240483172217,\n",
       "               0.260283926011742,\n",
       "               0.26016485070647993,\n",
       "               0.2600995125936177,\n",
       "               0.2600154972203339,\n",
       "               0.25983542166718143,\n",
       "               0.2596940337929264,\n",
       "               0.2595360995439787,\n",
       "               0.2594781725438378,\n",
       "               0.25941131005311907,\n",
       "               0.259326478145601,\n",
       "               0.2592296136294758,\n",
       "               0.2591159293772696,\n",
       "               0.2590304992341103,\n",
       "               0.25894580822953167,\n",
       "               0.25886830041663417,\n",
       "               0.2587425601847424,\n",
       "               0.2586800865113516,\n",
       "               0.2586298956847583,\n",
       "               0.2585142963668173,\n",
       "               0.2584087873381416,\n",
       "               0.2583331405100606,\n",
       "               0.2582613006982817,\n",
       "               0.2581111724843332,\n",
       "               0.2580516212092114,\n",
       "               0.2580013440811157,\n",
       "               0.2579207333180526,\n",
       "               0.25779409776110135,\n",
       "               0.25768813765160875,\n",
       "               0.2576380672383041,\n",
       "               0.2575806866480631,\n",
       "               0.2574903951032243,\n",
       "               0.25743551950902943,\n",
       "               0.2573217291250542,\n",
       "               0.25725262408334965,\n",
       "               0.25719242904258593,\n",
       "               0.25714610863982207,\n",
       "               0.2570744074006642,\n",
       "               0.256962472022437,\n",
       "               0.25686527332917736,\n",
       "               0.2566726202944883,\n",
       "               0.2566148243979069,\n",
       "               0.2565197909285259,\n",
       "               0.25642626999979384,\n",
       "               0.2563634779681146,\n",
       "               0.2562800793734379,\n",
       "               0.256224230810621,\n",
       "               0.25616976786945617,\n",
       "               0.25607426334628935,\n",
       "               0.2560074280373617,\n",
       "               0.2559186751660279,\n",
       "               0.2558704365268765,\n",
       "               0.25576290977378746,\n",
       "               0.25566635402701876,\n",
       "               0.255618767651888,\n",
       "               0.2555571529339715,\n",
       "               0.2555040534057076,\n",
       "               0.25541570510429884,\n",
       "               0.2553730098867468,\n",
       "               0.2552534284211108,\n",
       "               0.2551619679523138,\n",
       "               0.2551087268603524,\n",
       "               0.255034283056545,\n",
       "               0.25497041940436244,\n",
       "               0.25486353132058864,\n",
       "               0.25480616303754267,\n",
       "               0.2547214311221419,\n",
       "               0.25465046071099007,\n",
       "               0.25459778643441444,\n",
       "               0.2545503964472385,\n",
       "               0.2544773133549278,\n",
       "               0.25441921204554796,\n",
       "               0.25434633896997566,\n",
       "               0.25427834438436664,\n",
       "               0.2541529074331798,\n",
       "               0.25409521890062,\n",
       "               0.254030944356935,\n",
       "               0.25397625772338045,\n",
       "               0.2538890210398333,\n",
       "               0.2538404405694195,\n",
       "               0.25378650499362976,\n",
       "               0.2537213337576179,\n",
       "               0.2536251553614628,\n",
       "               0.25357364675971156,\n",
       "               0.2535198906088781,\n",
       "               0.2534443592262741,\n",
       "               0.2533347866698124,\n",
       "               0.2532874771646163,\n",
       "               0.25319736200007587,\n",
       "               0.25316610629270236,\n",
       "               0.2531041812010035,\n",
       "               0.25304915676981793,\n",
       "               0.25300922230132117,\n",
       "               0.252961752678072,\n",
       "               0.2529111754074903,\n",
       "               0.25287366204665257,\n",
       "               0.25278443615995383,\n",
       "               0.252723854906196,\n",
       "               0.25266320367794554,\n",
       "               0.2526165400205151,\n",
       "               0.2525578899821679,\n",
       "               0.25250037766384953,\n",
       "               0.25244791529305305,\n",
       "               0.2523768304763508,\n",
       "               0.25232551108497475,\n",
       "               0.2522719985555007],\n",
       "              'train-Logloss-std': [0.0013470976926994664,\n",
       "               0.0009882848946891794,\n",
       "               0.0021780922789852272,\n",
       "               0.0030337475657805286,\n",
       "               0.002383222187697586,\n",
       "               0.003773556516666552,\n",
       "               0.004532218238895576,\n",
       "               0.003253492741197719,\n",
       "               0.0026931354885550967,\n",
       "               0.002697494584611055,\n",
       "               0.0029482583775041577,\n",
       "               0.0038473300181998175,\n",
       "               0.003289932839990434,\n",
       "               0.004139625136924908,\n",
       "               0.004653715777366882,\n",
       "               0.004388867292536228,\n",
       "               0.0037778498577740387,\n",
       "               0.0032337042536281974,\n",
       "               0.0029583076958884643,\n",
       "               0.003882561518655583,\n",
       "               0.003924289045157506,\n",
       "               0.003495317508637808,\n",
       "               0.0027687192399574573,\n",
       "               0.0027009307699848648,\n",
       "               0.0027458550692640105,\n",
       "               0.0029877213783439404,\n",
       "               0.002994297302139945,\n",
       "               0.0028283933974744325,\n",
       "               0.0024331805684171606,\n",
       "               0.0026314088426332787,\n",
       "               0.002676507570760781,\n",
       "               0.003113885828970945,\n",
       "               0.00298287535972373,\n",
       "               0.0027838164580110576,\n",
       "               0.0026678205263908007,\n",
       "               0.002071666165089507,\n",
       "               0.002092561982861765,\n",
       "               0.001874613103740563,\n",
       "               0.001748337484144524,\n",
       "               0.0015507901775296802,\n",
       "               0.0015263439135290821,\n",
       "               0.0015361942302779456,\n",
       "               0.0015794149558196477,\n",
       "               0.0014570375580008504,\n",
       "               0.0014124545672764902,\n",
       "               0.0010359618584065348,\n",
       "               0.0013543958921713797,\n",
       "               0.0013151984289235955,\n",
       "               0.0013874488078244832,\n",
       "               0.0013743828368559584,\n",
       "               0.0016031101056810887,\n",
       "               0.0018706195032015395,\n",
       "               0.001808780606877565,\n",
       "               0.0020134291096514613,\n",
       "               0.002120600431394187,\n",
       "               0.002240818657043768,\n",
       "               0.0021130942374595852,\n",
       "               0.0022410820531714192,\n",
       "               0.002213535162330391,\n",
       "               0.0021998436759199658,\n",
       "               0.002185156596610503,\n",
       "               0.0020964225782568063,\n",
       "               0.0021405442750159456,\n",
       "               0.00207527962351941,\n",
       "               0.0021244638316137497,\n",
       "               0.002085517634110145,\n",
       "               0.0021673812913395553,\n",
       "               0.002296563612170417,\n",
       "               0.002358433060232116,\n",
       "               0.002342807868289019,\n",
       "               0.0024900459948327147,\n",
       "               0.0026781027849490297,\n",
       "               0.002677834460834545,\n",
       "               0.002669330630178536,\n",
       "               0.0026035414479546083,\n",
       "               0.002545961400080741,\n",
       "               0.0023629939220307823,\n",
       "               0.002395961634718865,\n",
       "               0.0023559758333064023,\n",
       "               0.002365166222265386,\n",
       "               0.0023500149810663433,\n",
       "               0.002322047005462021,\n",
       "               0.002360688822799288,\n",
       "               0.0023146898583715006,\n",
       "               0.0022671192776078206,\n",
       "               0.002287570875118762,\n",
       "               0.0021817825301871006,\n",
       "               0.0021531174886757036,\n",
       "               0.0021185296428826474,\n",
       "               0.002166906079342247,\n",
       "               0.002225582154020558,\n",
       "               0.0023194026314189526,\n",
       "               0.002375115657837863,\n",
       "               0.0023829990834059963,\n",
       "               0.0024274981557291264,\n",
       "               0.00235894305109963,\n",
       "               0.0023769184687894847,\n",
       "               0.0024473145889154684,\n",
       "               0.0025214145474606762,\n",
       "               0.0025527621157241712,\n",
       "               0.0025373727145143804,\n",
       "               0.002475947715948177,\n",
       "               0.0025955974189459685,\n",
       "               0.002630888473378936,\n",
       "               0.002621133857508525,\n",
       "               0.002724527666648339,\n",
       "               0.0026574052529374716,\n",
       "               0.0027293699341122395,\n",
       "               0.002763648394514311,\n",
       "               0.0027516583740861173,\n",
       "               0.002761412934052842,\n",
       "               0.002697994340500727,\n",
       "               0.0027394987611988604,\n",
       "               0.002660458192524351,\n",
       "               0.002553456539710299,\n",
       "               0.0026184358300522068,\n",
       "               0.002692606974083692,\n",
       "               0.002627872632741477,\n",
       "               0.002653192909053478,\n",
       "               0.0026595980649169837,\n",
       "               0.00270481759925554,\n",
       "               0.002700184033722572,\n",
       "               0.002738268578354001,\n",
       "               0.0027038016233260787,\n",
       "               0.0028058973580912766,\n",
       "               0.002747898549096846,\n",
       "               0.0027126733969592923,\n",
       "               0.0027031186380267105,\n",
       "               0.0026415614484417284,\n",
       "               0.0027434622569395477,\n",
       "               0.0027351808901829103,\n",
       "               0.0027097560931727913,\n",
       "               0.002662684773939334,\n",
       "               0.0027087466900084147,\n",
       "               0.0026653263168772874,\n",
       "               0.002661680260002805,\n",
       "               0.002660744691961217,\n",
       "               0.0026489356339886258,\n",
       "               0.002534112154726209,\n",
       "               0.002457826866588063,\n",
       "               0.0024416774045475593,\n",
       "               0.0024424364255758455,\n",
       "               0.0023912810383744255,\n",
       "               0.0023505917314496963,\n",
       "               0.0023494201468224367,\n",
       "               0.002333568870744906,\n",
       "               0.0023326632676546255,\n",
       "               0.00239445676909334,\n",
       "               0.0023767194641949665,\n",
       "               0.002369238471794595,\n",
       "               0.0024176839830868943,\n",
       "               0.002436288033343431,\n",
       "               0.002397769132380376,\n",
       "               0.002375200748345416,\n",
       "               0.002365690199574225,\n",
       "               0.002413852418842861,\n",
       "               0.0024458596823680677,\n",
       "               0.002554926195652693,\n",
       "               0.0025428702702060607,\n",
       "               0.002456967119727987,\n",
       "               0.0024491111981260407,\n",
       "               0.0024492799020746523,\n",
       "               0.00248055321627738,\n",
       "               0.0024996123454709474,\n",
       "               0.0024714782160437138,\n",
       "               0.0024236615748212545,\n",
       "               0.002420035296991,\n",
       "               0.0024216639269571626,\n",
       "               0.0023931309693792113,\n",
       "               0.002374055044548122,\n",
       "               0.00241784583699635,\n",
       "               0.002349777655849323,\n",
       "               0.002316093582020288,\n",
       "               0.0023137191657066508,\n",
       "               0.002290599870149617,\n",
       "               0.002317366436779579,\n",
       "               0.0023308276122437394,\n",
       "               0.002448518416453643,\n",
       "               0.0024898531783757397,\n",
       "               0.002474264359802467,\n",
       "               0.0024835315594794603,\n",
       "               0.0024310781131900634,\n",
       "               0.0024143426139074877,\n",
       "               0.0023959677497436224,\n",
       "               0.00243105251932107,\n",
       "               0.0024478660704886556,\n",
       "               0.0025540949819747943,\n",
       "               0.0025896505564412605,\n",
       "               0.002561309921460439,\n",
       "               0.002588763680000571,\n",
       "               0.0025843236843313875,\n",
       "               0.0025019963162276433,\n",
       "               0.0024414400849560192,\n",
       "               0.002387437018909426,\n",
       "               0.0024382298533839747,\n",
       "               0.0024511683425862195,\n",
       "               0.002478292515931891,\n",
       "               0.002423016747614484,\n",
       "               0.0024100089702658025,\n",
       "               0.0024088106566732812,\n",
       "               0.0023637154689739957,\n",
       "               0.002362994556996925,\n",
       "               0.002204055277594495,\n",
       "               0.0021850101895484024,\n",
       "               0.002191702745896306,\n",
       "               0.002231157265009859,\n",
       "               0.002033235526998145,\n",
       "               0.0019788569793889664,\n",
       "               0.0019270872000320177,\n",
       "               0.0019211710064697607,\n",
       "               0.0015967977335774415,\n",
       "               0.0015709340784246838,\n",
       "               0.001573104381114898,\n",
       "               0.0015788205686632067,\n",
       "               0.001534363296270118,\n",
       "               0.0015030439430960226,\n",
       "               0.0015343402462893202,\n",
       "               0.0015693417177341457,\n",
       "               0.001616716810053047,\n",
       "               0.0015839473795463681,\n",
       "               0.0015596122810378763,\n",
       "               0.001497368177040438,\n",
       "               0.0014890002126460458,\n",
       "               0.0014885273730347805,\n",
       "               0.0015119563274069753,\n",
       "               0.0015294943085885184,\n",
       "               0.001509760272442886,\n",
       "               0.0014907571627319127,\n",
       "               0.0014616755358677891,\n",
       "               0.0014827184913728492,\n",
       "               0.0014690088506228139,\n",
       "               0.0014951168105481832,\n",
       "               0.0014740779852317478,\n",
       "               0.0014724309721796515,\n",
       "               0.0014391321014212916,\n",
       "               0.0014286744650811,\n",
       "               0.0013015591597013423,\n",
       "               0.0013069840178457444,\n",
       "               0.0013107060207277694,\n",
       "               0.0013396721494241994,\n",
       "               0.0012760301190466825,\n",
       "               0.001296152259492595,\n",
       "               0.001258187174147187,\n",
       "               0.0013095691630549083,\n",
       "               0.00125675875163898,\n",
       "               0.0012622719163472751,\n",
       "               0.00127947773487479,\n",
       "               0.0011185419830648676,\n",
       "               0.0011532407485512744,\n",
       "               0.0011762156846622958,\n",
       "               0.0011574325252937552,\n",
       "               0.0011572867767019371,\n",
       "               0.0011817349295696919,\n",
       "               0.00118199490379953,\n",
       "               0.0011809564073625416,\n",
       "               0.0011878614452720748,\n",
       "               0.0011455283122426116,\n",
       "               0.0011467585523483774,\n",
       "               0.0011492740511043246,\n",
       "               0.0011155077241800618,\n",
       "               0.0011321702896098097,\n",
       "               0.0011392989132016295,\n",
       "               0.0011291650841185569,\n",
       "               0.001129892607906423,\n",
       "               0.0011661985028832767,\n",
       "               0.0011834130075922653,\n",
       "               0.0011697856536247427,\n",
       "               0.0011312748908746666,\n",
       "               0.0011298027799204094,\n",
       "               0.0011157647692336525,\n",
       "               0.001111607215151933,\n",
       "               0.001090545816928102,\n",
       "               0.001098561043678287,\n",
       "               0.0010946410460432557,\n",
       "               0.0010506211630631262,\n",
       "               0.001066618007307463,\n",
       "               0.0010719447172354742,\n",
       "               0.0011098924208609092,\n",
       "               0.001195388354233075,\n",
       "               0.0012405680712274196,\n",
       "               0.001202015199011384,\n",
       "               0.0012180392620744723,\n",
       "               0.0012051616940942967,\n",
       "               0.0012032043641647494,\n",
       "               0.0011639721379029953,\n",
       "               0.001126826065577753,\n",
       "               0.0012472920075109523,\n",
       "               0.0012241835723453085,\n",
       "               0.0012232296491606765,\n",
       "               0.001228335804082952,\n",
       "               0.0012126415386580927,\n",
       "               0.001228614985540642,\n",
       "               0.0012161330623998337,\n",
       "               0.0012245921223239858,\n",
       "               0.001246690391260269,\n",
       "               0.001248470848443864,\n",
       "               0.0012362149611366375,\n",
       "               0.0012662420409453269,\n",
       "               0.001268585913778124,\n",
       "               0.0012792946837885501,\n",
       "               0.001282858598616281,\n",
       "               0.001276962254093762,\n",
       "               0.001294023189492394,\n",
       "               0.001361293702335235,\n",
       "               0.0013276719664125907,\n",
       "               0.0013350041004729382,\n",
       "               0.0013333965521407645,\n",
       "               0.00133785117332038,\n",
       "               0.0012888506618642453,\n",
       "               0.0012881709317852277,\n",
       "               0.0012899669286038544,\n",
       "               0.0014177479837238476,\n",
       "               0.0013788318701104243,\n",
       "               0.0013543534489111558,\n",
       "               0.0013350209015360168,\n",
       "               0.0013500999788272627,\n",
       "               0.001346718522754888,\n",
       "               0.0013474974000093562,\n",
       "               0.0013483122886161752,\n",
       "               0.0011837122058060002,\n",
       "               0.0012035173227818842,\n",
       "               0.001177711348201239,\n",
       "               0.0011952448993206037,\n",
       "               0.0011577888751537107,\n",
       "               0.001152399783606873,\n",
       "               0.0011783510619672772,\n",
       "               0.0012185397065296137,\n",
       "               0.0012119490763148472,\n",
       "               0.0012072115706087641,\n",
       "               0.001142290903153371,\n",
       "               0.0011636203043245432,\n",
       "               0.0011673495529428391,\n",
       "               0.0011740609948987179,\n",
       "               0.0011254351230089179,\n",
       "               0.001031301967773598,\n",
       "               0.0010594924034427753,\n",
       "               0.0009995527121198257,\n",
       "               0.0010280095614872025,\n",
       "               0.0009948284660441812,\n",
       "               0.0010031267963238855,\n",
       "               0.001108062920761929,\n",
       "               0.0011641353363907813,\n",
       "               0.0011609596035118085,\n",
       "               0.0011740100565600477,\n",
       "               0.0010616172254886028,\n",
       "               0.0011848801977201308,\n",
       "               0.0011719098625904735,\n",
       "               0.0011820308208309916,\n",
       "               0.0011524577806944851,\n",
       "               0.00128611552554852,\n",
       "               0.0013491814609722802,\n",
       "               0.0013351299413375038,\n",
       "               0.0013335889362543324,\n",
       "               0.0012725513100256172,\n",
       "               0.001293797537896761,\n",
       "               0.0013317224252426807,\n",
       "               0.001172238828412062,\n",
       "               0.0010927234935710379,\n",
       "               0.0011009894366751998,\n",
       "               0.0011374351137167162,\n",
       "               0.0011229250041836442,\n",
       "               0.0011296190519753005,\n",
       "               0.0011378528580905632,\n",
       "               0.0010125970213313313,\n",
       "               0.0010339772703603248,\n",
       "               0.001025496584592308,\n",
       "               0.001014136307008384,\n",
       "               0.0010166193552775655,\n",
       "               0.0010241113731991414,\n",
       "               0.001034345506297151,\n",
       "               0.0010592930075190058,\n",
       "               0.0010239457589433577,\n",
       "               0.0010238195084822798,\n",
       "               0.001010623481600411,\n",
       "               0.0010685351066507004,\n",
       "               0.001122075666865772,\n",
       "               0.0011530141009957016,\n",
       "               0.001117448592152243,\n",
       "               0.0011737121669159075,\n",
       "               0.0011894910539756991,\n",
       "               0.0011717000188000302,\n",
       "               0.0011624301105724426,\n",
       "               0.0010577878472155322,\n",
       "               0.0010373046443490047,\n",
       "               0.0011609417066909041,\n",
       "               0.001143133473951304,\n",
       "               0.001163531769412241,\n",
       "               0.001223175444777316,\n",
       "               0.0012315000995497965,\n",
       "               0.0011214117327411875,\n",
       "               0.0011280946931458982,\n",
       "               0.0011363583050582966,\n",
       "               0.0010494255987850535,\n",
       "               0.0010537865719790049,\n",
       "               0.0010606987770592395,\n",
       "               0.00118541575017675,\n",
       "               0.0011241461293978756,\n",
       "               0.001116633225928207,\n",
       "               0.0010966948745680662,\n",
       "               0.001171090382969486,\n",
       "               0.001245088026326403,\n",
       "               0.0011693456101011322,\n",
       "               0.001168768757429097,\n",
       "               0.001205768904452929,\n",
       "               0.0012123321645033758,\n",
       "               0.0011745177253399105,\n",
       "               0.0012455357754959863,\n",
       "               0.0012062749786318108,\n",
       "               0.001207342536027985,\n",
       "               0.0012463823214501919,\n",
       "               0.001282109669335355,\n",
       "               0.0012982806259209084,\n",
       "               0.001294396524287566,\n",
       "               0.0013580567613370909,\n",
       "               0.001348423061690948,\n",
       "               0.0013662373151003802,\n",
       "               0.0013422975458098783,\n",
       "               0.001379182268125363,\n",
       "               0.0013835623296534964,\n",
       "               0.0013832968867688628,\n",
       "               0.001339608690293258,\n",
       "               0.0012556836091697106,\n",
       "               0.0012804292969081507,\n",
       "               0.001296660755068125,\n",
       "               0.0013032616167271186,\n",
       "               0.0012803255412251215,\n",
       "               0.0012669153881971896,\n",
       "               0.0013126200824818775,\n",
       "               0.0013123344367443465,\n",
       "               0.0013305390574050605,\n",
       "               0.0013240064742387491,\n",
       "               0.001339028669957033,\n",
       "               0.0014255956852281281,\n",
       "               0.0014097865269402292,\n",
       "               0.0014125322085242853,\n",
       "               0.0013777243178125249,\n",
       "               0.0013728899637370346,\n",
       "               0.0014041018733503448,\n",
       "               0.001374000127124489,\n",
       "               0.001329006870282698,\n",
       "               0.0013505096772667364,\n",
       "               0.0013465290335069775,\n",
       "               0.0013775816306244193,\n",
       "               0.0013981906790147406,\n",
       "               0.0013504176403545968,\n",
       "               0.0013465611254477768,\n",
       "               0.001362941866223495,\n",
       "               0.0013860770508822594,\n",
       "               0.0013691491118578128,\n",
       "               0.0013892270641909922,\n",
       "               0.0014065501562241067,\n",
       "               0.0013533744562244745,\n",
       "               0.0013299341916981685,\n",
       "               0.001267608470457011,\n",
       "               0.0013199146366978894,\n",
       "               0.001320374321013957,\n",
       "               0.0013169765756839706,\n",
       "               0.0013093123202256223,\n",
       "               0.0013375932127821883,\n",
       "               0.0013241932090551367,\n",
       "               0.0013246131464623436,\n",
       "               0.0013207776858067534,\n",
       "               0.001345679453765121,\n",
       "               0.0013332271753456282,\n",
       "               0.0013666681892206293,\n",
       "               0.0013889195969308515,\n",
       "               0.001410956199225052,\n",
       "               0.0014390773189765403,\n",
       "               0.001343989280320868,\n",
       "               0.0013378470615622454,\n",
       "               0.0013065099370557728,\n",
       "               0.0012905857349531321,\n",
       "               0.0013062186402482921,\n",
       "               0.0012852785202199129,\n",
       "               0.0012892784691567265,\n",
       "               0.0013203732054382108,\n",
       "               0.0013570493454063237,\n",
       "               0.0013448226203046333,\n",
       "               0.0013295359553048727,\n",
       "               0.0013214456282685787,\n",
       "               0.0012668280135750532,\n",
       "               0.0012587159894133582,\n",
       "               0.0012383495921626836,\n",
       "               0.0012596681005645001,\n",
       "               0.00128069630179157,\n",
       "               0.001284456213815807,\n",
       "               0.0012703488726046501,\n",
       "               0.001298020353617868,\n",
       "               0.001306572843978671,\n",
       "               0.0012935075082186318,\n",
       "               0.0013121481373954092,\n",
       "               0.0013116259741954798,\n",
       "               0.0013088037338010944,\n",
       "               0.001314974934023663,\n",
       "               0.0013420870160436458,\n",
       "               0.0013428687814575643,\n",
       "               0.00133628660267121,\n",
       "               0.0013626862611694128,\n",
       "               0.0013693460573951477,\n",
       "               0.0013694934454870492]})}"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_boosting_model = catboost.CatBoostClassifier(n_estimators=500, cat_features=cat_cols,\n",
    "                                            silent=True, eval_metric='AUC',\n",
    "                                            )\n",
    "grid_boosting_model.grid_search({'l2_leaf_reg': np.linspace(0, 1, 20)}, \n",
    "                           x_train_cb, \n",
    "                           y_train, plot=True, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243492400264779"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_boosting = grid_boosting_model.predict_proba(x_test_cb)[:, 1]\n",
    "roc_auc_score(y_test, predict_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educ-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  educ-num  \\\n",
       "0       39         State-gov   77516   Bachelors        13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors        13   \n",
       "2       38           Private  215646     HS-grad         9   \n",
       "3       53           Private  234721        11th         7   \n",
       "4       28           Private  338409   Bachelors        13   \n",
       "...    ...               ...     ...         ...       ...   \n",
       "32556   27           Private  257302  Assoc-acdm        12   \n",
       "32557   40           Private  154374     HS-grad         9   \n",
       "32558   58           Private  151910     HS-grad         9   \n",
       "32559   22           Private  201490     HS-grad         9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad         9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  salary  \n",
       "0              2174             0              40  United-States       0  \n",
       "1                 0             0              13  United-States       0  \n",
       "2                 0             0              40  United-States       0  \n",
       "3                 0             0              40  United-States       0  \n",
       "4                 0             0              40           Cuba       0  \n",
       "...             ...           ...             ...            ...     ...  \n",
       "32556             0             0              38  United-States       0  \n",
       "32557             0             0              40  United-States       1  \n",
       "32558             0             0              40  United-States       0  \n",
       "32559             0             0              20  United-States       0  \n",
       "32560         15024             0              40  United-States       1  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
